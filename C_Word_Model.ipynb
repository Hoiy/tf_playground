{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import Corpus.gutenberg as corpus\n",
    "#from TextPreprocess.Tokenizer.Stanford import tokenize\n",
    "#from Utils.visual import hist, tally\n",
    "#from Utils.debug import dump\n",
    "from DataLoader import GloVe\n",
    "from Utils.generator import sliding_window_random_access, transform\n",
    "#from Utils.FS.file import save, load\n",
    "#from Utils.keras import compact_embedding\n",
    "from Utils.misc import batch\n",
    "#from Utils.indexer import build_index, index_2_one_hot\n",
    "from Utils.indexer import build_index\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "import numpy as np\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "sents = gutenberg.sents(['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt'])\n",
    "words = gutenberg.words(['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt'])\n",
    "\n",
    "def toLower(s):\n",
    "    return s.lower()\n",
    "\n",
    "words = batch(toLower)(words)\n",
    "sents = batch(batch(toLower))(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def words_generator():\n",
    "    for word in words:\n",
    "        yield word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10650\n"
     ]
    }
   ],
   "source": [
    "# build index for all words\n",
    "o2i, i2o, size = build_index(words_generator())\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: Loading Glove Model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-489971f2f7f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mWORD_EMB_DIM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mglove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_glove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGloVe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselective_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/GloVe/glove.840B.{}d.txt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWORD_EMB_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWORD_EMB_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo2i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi2o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/hoiy927/project/tf_playground/DataLoader/GloVe.py\u001b[0m in \u001b[0;36mselective_load\u001b[0;34m(file, dim, o2i, i2o, dict_size, notFound)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0msplitLine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplitLine\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0memb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplitLine\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#WORD_EMB_DIM = 300\n",
    "#glove = GloVe.load2('./data/GloVe/glove.840B.{}d.txt'.format(WORD_EMB_DIM), WORD_EMB_DIM)\n",
    "\n",
    "#WORD_EMB_DIM = 50\n",
    "#glove = GloVe.load2('./data/GloVe/glove.6B.{}d.txt'.format(WORD_EMB_DIM), WORD_EMB_DIM)\n",
    "\n",
    "#WORD_EMB_DIM = 50\n",
    "#glove, orig_glove = GloVe.selective_load('./data/GloVe/glove.6B.{}d.txt'.format(WORD_EMB_DIM), WORD_EMB_DIM, o2i, i2o, size)\n",
    "\n",
    "WORD_EMB_DIM = 300\n",
    "glove, orig_glove = GloVe.selective_load('./data/GloVe/glove.6B.{}d.txt'.format(WORD_EMB_DIM), WORD_EMB_DIM, o2i, i2o, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(np.average([len(sent) for sent in sents]))\n",
    "SEQ_LENGTH = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, dot, add, MaxPooling1D, MaxPooling2D, Bidirectional, Input, GRU, LSTM, SimpleRNN, Conv1D, Conv2D, Conv2DTranspose, Dense, Flatten, Dropout, Reshape, Embedding, Concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.constraints import unit_norm\n",
    "from keras.initializers import Identity\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "POS_EMB_SIZE = 50    \n",
    "\n",
    "def create_encoder(inp):\n",
    "    sem_emb = Embedding(glove.shape[0], glove.shape[1], weights=[glove], input_length=SEQ_LENGTH, trainable=False )(inp)\n",
    "    query_emb = Embedding(glove.shape[0], POS_EMB_SIZE, embeddings_constraint=unit_norm())(inp)\n",
    "    \n",
    "    x = Bidirectional(GRU(POS_EMB_SIZE // 2, activation='selu', return_sequences=True))(sem_emb)\n",
    "    query = Bidirectional(GRU(POS_EMB_SIZE // 2, activation='selu'))(x)\n",
    "    \n",
    "    return query, query_emb, sem_emb\n",
    "\n",
    "def attention(query, query_emb, sem_emb):\n",
    "    att = dot([query, query_emb], (1,2))\n",
    "    att = Activation('softmax')(att)\n",
    "    att = dot([att, sem_emb], (1,1))\n",
    "    return att\n",
    "    \n",
    "\n",
    "def create_baseline():\n",
    "    \n",
    "    GRU_DIM = 128\n",
    "        \n",
    "    inp = Input(shape=(SEQ_LENGTH,))\n",
    "    sem_emb = Embedding(glove.shape[0], glove.shape[1], weights=[glove], input_length=SEQ_LENGTH, trainable=False )(inp)\n",
    "    x = Bidirectional(GRU(GRU_DIM, activation='selu', return_sequences=True))(sem_emb)\n",
    "    x = Bidirectional(GRU(GRU_DIM, activation='selu', return_sequences=True))(x)\n",
    "    x = Bidirectional(GRU(GRU_DIM, activation='selu', return_sequences=True))(x)\n",
    "    predict = Bidirectional(GRU(GRU_DIM, activation='selu'))(x)\n",
    "    \n",
    "    \n",
    "    #query, query_emb, sem_emb = create_encoder(inp)\n",
    "    #att = attention(query, query_emb, sem_emb)\n",
    "    \n",
    "    #x = Dense(GRU_DIM * 2, activation='selu')(predict)\n",
    "    x = Dense(glove.shape[0], activation='softmax')(predict)\n",
    "    model = Model(inp, x)\n",
    "    #opt = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0002)\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = create_baseline()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "def decode_word(one_hot):\n",
    "    return i2s( np.random.choice(list(range(NUM_SYMBOL)), p = one_hot)  )\n",
    "\n",
    "def decode_word_2(one_hot):\n",
    "    return i2s( np.argmax(one_hot) )\n",
    "\n",
    "\n",
    "# last char is used as output\n",
    "# so set it like gen = sliding_window(SEQ_LENGTH + 1)(data)\n",
    "def sample_generator(sliding_window_generator, batch_size = 64):\n",
    "    data = []\n",
    "    label = []\n",
    "    for window in sliding_window_generator:\n",
    "        data.append(batch(o2i)(window[:-1]))\n",
    "        label.append(o2i(window[-1]))\n",
    "        if len(data) == batch_size:\n",
    "            yield (np.array(data), np.array(label))\n",
    "            data = []\n",
    "            label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gen = {}\n",
    "size = {}\n",
    "gen['train'], gen['test'], size['train'], size['test'] = sliding_window_random_access(words, SEQ_LENGTH + 1)\n",
    "print(next(sample_generator(gen['train'], 2))[0].shape)\n",
    "print(next(sample_generator(gen['test'], 3))[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "def testing(model):\n",
    "    seed = \"\"\"Your child comes home and presents you with a drawing of your house . There is a blue house , a yellow sun , and a green sky .\"\"\"\n",
    "    words = seed.lower().split(' ')\n",
    "    for i in range(50):\n",
    "        predict = model.predict(np.array([batch(o2i)(words[-SEQ_LENGTH:])]))[0]\n",
    "        i = np.argmax(predict)\n",
    "        words.append(i2o(i))\n",
    "        \n",
    "    print(' '.join(words))\n",
    "    \n",
    "class testSample(Callback):\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        testing(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "mc = ModelCheckpoint('./model/char_cnn_2.hdf5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "BATCH_SIZE = 2048\n",
    "model.fit_generator(\n",
    "    sample_generator(gen['train'], BATCH_SIZE),\n",
    "    size['train'] // BATCH_SIZE,\n",
    "    validation_data = sample_generator(gen['test'], BATCH_SIZE),\n",
    "    validation_steps = size['test'] // BATCH_SIZE,\n",
    "    epochs=200000,\n",
    "    callbacks = [testSample(), mc]\n",
    "    #verbose=0, callbacks=[TQDMNotebookCallback(), testSample()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
