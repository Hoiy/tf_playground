{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prepare_dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "f-zLlGUTnd5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "b453ea44-ee4d-4935-d3ac-9884b5eb7866"
      },
      "cell_type": "code",
      "source": [
        "!pip install pyarrow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyarrow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/94/23135312f97b20d6457294606fb70fad43ef93b7bffe567088ebe3623703/pyarrow-0.11.1-cp36-cp36m-manylinux1_x86_64.whl (11.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 11.6MB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.14.6)\n",
            "Installing collected packages: pyarrow\n",
            "Successfully installed pyarrow-0.11.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_M-EQPcRnnV8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "291c65f3-fe1c-4463-c34c-e3e77e8ebce5"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
        "if not 'bert_repo' in sys.path:\n",
        "  sys.path += ['bert_repo']  "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert_repo'...\n",
            "remote: Enumerating objects: 299, done.\u001b[K\n",
            "remote: Total 299 (delta 0), reused 0 (delta 0), pack-reused 299\u001b[K\n",
            "Receiving objects: 100% (299/299), 184.80 KiB | 7.39 MiB/s, done.\n",
            "Resolving deltas: 100% (178/178), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nbfc2ujRnxBV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tokenization\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X2DIHh1CnsXJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BERT_PRETRAINED_DIR = 'gs://dev-test-bert-tpu/chinese_bert/'\n",
        "VOCAB_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
        "BERT_MODEL = 'chinese_L-12_H-768_A-12'\n",
        "DO_LOWER_CASE = BERT_MODEL.startswith('uncased')\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=DO_LOWER_CASE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JpGbR2Pzu3Gh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "3aa4a70c-cb1a-4bd8-9232-4129a6c7355f"
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p ./dataset && gsutil rsync gs://dev-test-bert-tpu/dataset ./dataset\n",
        "  \n",
        "article_contents = pd.read_csv('./dataset/article_contents.csv').set_index('article_id')\n",
        "article_contents = article_contents[~article_contents.main_content.isnull()]\n",
        "article_contents.head()\n",
        "\n",
        "train, test = train_test_split(article_contents, test_size=0.2, shuffle=False)\n",
        "\n",
        "class InputExample(object):\n",
        "  \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "  def __init__(self, guid, text_a, text_b=None, label=None):\n",
        "    \"\"\"Constructs a InputExample.\n",
        "    Args:\n",
        "      guid: Unique id for the example.\n",
        "      text_a: string. The untokenized text of the first sequence. For single\n",
        "        sequence tasks, only this sequence must be specified.\n",
        "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "        Only must be specified for sequence pair tasks.\n",
        "      label: (Optional) string. The label of the example. This should be\n",
        "        specified for train and dev examples, but not for test examples.\n",
        "    \"\"\"\n",
        "    self.guid = guid\n",
        "    self.text_a = text_a\n",
        "    self.text_b = text_b\n",
        "    self.label = label\n",
        "\n",
        "def get_train_examples():\n",
        "  examples = []\n",
        "  def append_example(row):\n",
        "    examples.append(InputExample(row.name, row.main_content))\n",
        "  \n",
        "  train.apply(append_example, axis=1)\n",
        "  return examples\n",
        "\n",
        "\n",
        "def get_test_examples():\n",
        "  examples = []\n",
        "  def append_example(row):\n",
        "    examples.append(InputExample(row.name, row.main_content))\n",
        "  \n",
        "  test.apply(append_example, axis=1)\n",
        "  return examples\n",
        "\n",
        "\n",
        "\n",
        "train_examples = get_train_examples()\n",
        "test_examples = get_test_examples()\n",
        "train_examples[:10], len(train_examples)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building synchronization state...\n",
            "Starting synchronization...\n",
            "Copying gs://dev-test-bert-tpu/dataset/article_contents.csv...\n",
            "Copying gs://dev-test-bert-tpu/dataset/article_contents.txt...\n",
            "Copying gs://dev-test-bert-tpu/dataset/train_features.pkl...\n",
            "| [3 files][  1.7 GiB/  1.7 GiB]   75.0 MiB/s                                   \n",
            "Operation completed over 3 objects/1.7 GiB.                                      \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<__main__.InputExample at 0x7fe2a9272f98>,\n",
              "  <__main__.InputExample at 0x7fe2a926f160>,\n",
              "  <__main__.InputExample at 0x7fe2a926f1d0>,\n",
              "  <__main__.InputExample at 0x7fe2a926f278>,\n",
              "  <__main__.InputExample at 0x7fe2a926f9e8>,\n",
              "  <__main__.InputExample at 0x7fe2a926f940>,\n",
              "  <__main__.InputExample at 0x7fe2a926f3c8>,\n",
              "  <__main__.InputExample at 0x7fe2a926f0f0>,\n",
              "  <__main__.InputExample at 0x7fe2a926f438>,\n",
              "  <__main__.InputExample at 0x7fe2a926f048>],\n",
              " 174664)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "k25CdQKJ0LbZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4c72fde0-3a59-49aa-b2f7-b48064d2c3fd"
      },
      "cell_type": "code",
      "source": [
        "# For char count frequency\n",
        "keras_tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True, oov_token='<oov>', split='')\n",
        "keras_tokenizer.fit_on_texts(train.main_content)\n",
        "len(keras_tokenizer.index_word), keras_tokenizer.word_index['<oov>']\n",
        "\n",
        "choice = []\n",
        "p = []\n",
        "\n",
        "for k, v in keras_tokenizer.word_counts.items():\n",
        "  if k in tokenizer.vocab:\n",
        "    choice.append(k)\n",
        "    p.append(v)\n",
        "\n",
        "p = p / np.sum(p)\n",
        "\n",
        "choice[:10], p[:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['英', '超', '曼', '聯', '今', '晨', '主', '場', '出', '擊'],\n",
              " array([0.00076436, 0.00048691, 0.00012413, 0.00073227, 0.00169406,\n",
              "        0.00012515, 0.00210093, 0.00184991, 0.00373265, 0.00049875]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "DvpQOd0NybbA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4678
        },
        "cellView": "both",
        "outputId": "3ad55005-0074-4cea-c741-8c811dac51d2"
      },
      "cell_type": "code",
      "source": [
        "class InputFeatures(object):\n",
        "  \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               input_ids,\n",
        "               input_mask,\n",
        "               segment_ids,\n",
        "               truths,\n",
        "               is_real_example=True):\n",
        "    self.input_ids = input_ids\n",
        "    self.input_mask = input_mask\n",
        "    self.segment_ids = segment_ids\n",
        "    self.is_real_example = is_real_example\n",
        "    self.truths = truths\n",
        "\n",
        "    \n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "  \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "  # This is a simple heuristic which will always truncate the longer sequence\n",
        "  # one token at a time. This makes more sense than truncating an equal percent\n",
        "  # of tokens from each, since if one sequence is very short then each token\n",
        "  # that's truncated likely contains more information than a longer sequence.\n",
        "  while True:\n",
        "    total_length = len(tokens_a) + len(tokens_b)\n",
        "    if total_length <= max_length:\n",
        "      break\n",
        "    if len(tokens_a) > len(tokens_b):\n",
        "      tokens_a.pop()\n",
        "    else:\n",
        "      tokens_b.pop()\n",
        "\n",
        "def convert_single_example(ex_index, example, max_seq_length,\n",
        "                           tokenizer):\n",
        "  \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
        "  tokens_a = tokenizer.tokenize(example.text_a)\n",
        "  \n",
        "  MASK_PROB = 0.15 #@param {type:\"number\"}\n",
        "  assert MASK_PROB >= 0. and MASK_PROB <= 1\n",
        "  MASK_ERROR_PROB = 0.8 #@param {type:\"number\"}\n",
        "\n",
        "  random_tokens = np.random.choice(choice, len(tokens_a), p=p)\n",
        "  random_mask = np.random.choice([0., 1.], len(tokens_a), p=[1-MASK_PROB, MASK_PROB])\n",
        "\n",
        "  aug_tokens_a = np.ma.array(tokens_a, mask=random_mask).filled(random_tokens)\n",
        "  \n",
        "  tokens_a = aug_tokens_a\n",
        "  tokens_a_truth = random_mask\n",
        "  \n",
        "  tokens_b = None\n",
        "  if example.text_b:\n",
        "    tokens_b = tokenizer.tokenize(example.text_b)\n",
        "\n",
        "  if tokens_b:\n",
        "    # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "    # length is less than the specified length.\n",
        "    # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "    _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "  else:\n",
        "    # Account for [CLS] and [SEP] with \"- 2\"\n",
        "    if len(tokens_a) > max_seq_length - 2:\n",
        "      tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
        "\n",
        "  # The convention in BERT is:\n",
        "  # (a) For sequence pairs:\n",
        "  #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "  #  type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n",
        "  # (b) For single sequences:\n",
        "  #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "  #  type_ids: 0     0   0   0  0     0 0\n",
        "  #\n",
        "  # Where \"type_ids\" are used to indicate whether this is the first\n",
        "  # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "  # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "  # embedding vector (and position vector). This is not *strictly* necessary\n",
        "  # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "  # it easier for the model to learn the concept of sequences.\n",
        "  #\n",
        "  # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "  # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "  # the entire model is fine-tuned.\n",
        "  tokens = []\n",
        "  segment_ids = []\n",
        "  truths = []\n",
        "  \n",
        "  tokens.append(\"[CLS]\")\n",
        "  segment_ids.append(0)\n",
        "  truths.append(0.)\n",
        "  \n",
        "  for token, truth in zip(tokens_a, tokens_a_truth):\n",
        "    tokens.append(token)\n",
        "    segment_ids.append(0)\n",
        "    truths.append(truth)\n",
        "    \n",
        "  tokens.append(\"[SEP]\")\n",
        "  segment_ids.append(0)\n",
        "  truths.append(0.)\n",
        "\n",
        "  if tokens_b:\n",
        "    for token in tokens_b:\n",
        "      tokens.append(token)\n",
        "      segment_ids.append(1)\n",
        "    tokens.append(\"[SEP]\")\n",
        "    segment_ids.append(1)\n",
        "\n",
        "  input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "  # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "  # tokens are attended to.\n",
        "  input_mask = [1] * len(input_ids)\n",
        "\n",
        "  # Zero-pad up to the sequence length.\n",
        "  while len(input_ids) < max_seq_length:\n",
        "    input_ids.append(0)\n",
        "    input_mask.append(0)\n",
        "    segment_ids.append(0)\n",
        "    truths.append(0.)\n",
        "\n",
        "  assert len(input_ids) == max_seq_length\n",
        "  assert len(input_mask) == max_seq_length\n",
        "  assert len(segment_ids) == max_seq_length\n",
        "  assert len(truths) == max_seq_length\n",
        "\n",
        "  if ex_index < 3:\n",
        "    tf.logging.info(\"*** Example ***\")\n",
        "    tf.logging.info(\"guid: %s\" % (example.guid))\n",
        "    tf.logging.info(\"tokens: %s\" % \" \".join(\n",
        "        [tokenization.printable_text(x) for x in tokens]))\n",
        "    tf.logging.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "    tf.logging.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
        "    tf.logging.info(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
        "    tf.logging.info(\"truths: %s\" % \" \".join([str(x) for x in truths]))\n",
        "\n",
        "  feature = InputFeatures(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids,\n",
        "      truths=truths\n",
        "  )\n",
        "  return feature\n",
        "\n",
        "\n",
        "def convert_examples_to_features(examples, max_seq_length,\n",
        "                                 tokenizer):\n",
        "  \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
        "\n",
        "  features = []\n",
        "  for (ex_index, example) in enumerate(examples):\n",
        "    if ex_index % 1000 == 0:\n",
        "      tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
        "\n",
        "    feature = convert_single_example(ex_index, example,\n",
        "                                     max_seq_length, tokenizer)\n",
        "\n",
        "    features.append(feature)\n",
        "  return features  \n",
        "\n",
        "print('MRPC/CoLA on BERT base model normally takes about 2-3 minutes. Please wait...')\n",
        "\n",
        "MAX_SEQ_LENGTH = 128 #@param {'type': 'number'}\n",
        "\n",
        "train_features = convert_examples_to_features(train_examples, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features = convert_examples_to_features(test_examples, MAX_SEQ_LENGTH, tokenizer)\n",
        "train_features[:10], len(train_features)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MRPC/CoLA on BERT base model normally takes about 2-3 minutes. Please wait...\n",
            "INFO:tensorflow:Writing example 0 of 174664\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: 3\n",
            "INFO:tensorflow:tokens: [CLS] 弟 超 曼 聯 論 晨 主 場 出 擊 ， 只 能 與 剛 剛 上 任 8 車 路 士 的 領 隊 軒 迪 克 飼 和 0 : 0 ， 近 8 場 未 嘗 勝 績 ， 備 受 批 評 的 紅 4 領 也 雲 高 爾 賽 後 卻 表 示 絕 不 辭 職 。 性 ， 曼 聯 有 中 場 舒 韋 恩 史 迪 加 停 賽 復 出 ， 而 兩 路 士 亦 有 中 場 夏 薩 特 能 任 為 選 ， 主 隊 地 段 便 獲 得 宣 金 對 會 ， 但 麼 場 接 馬 達 及 清 鋒 會 籌 尼 馬 迪 爾 先 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2475 6631 3294 5474 6316 3247 712 1842 1139 3080 8024 1372 5543 5645 1190 1190 677 818 129 6722 6662 1894 4638 7526 7386 6726 6832 1046 7615 1469 121 131 121 8024 6818 129 1842 3313 1655 1245 5245 8024 991 1358 2821 6268 4638 5148 125 7526 738 7437 7770 4273 6555 2527 1320 6134 4850 5179 679 6798 5480 511 2595 8024 3294 5474 3300 704 1842 5653 7500 2617 1380 6832 1217 977 6555 2541 1139 8024 5445 1060 6662 1894 771 3300 704 1842 1909 5958 4294 5543 818 4158 6908 8024 712 7386 1765 3667 912 4363 2533 2146 7032 2205 3298 8024 852 7938 1842 2970 7679 6888 1350 3926 7081 3298 5092 2225 7679 6832 4273 1044 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:truths: 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: 6\n",
            "INFO:tensorflow:tokens: [CLS] 港 超 勁 旅 內 華 宣 布 羅 致 前 厄 分 多 爾 國 腳 菲 力 斯 保 耶 （ [UNK] [UNK] ） ， 簽 約 一 年 半 提 足 主 張 廣 勇 期 待 該 32 歲 前 鋒 可 提 高 球 隊 研 進 攻 能 力 ， 增 更 球 隊 的 爭 標 機 亦 。 35 歲 老 將 伊 而 北 上 菲 力 r 是 現 南 華 門 將 摩 拉 的 前 國 家 隊 隊 友 ， 兩 人 曾 一 同 征 戰 2006 年 德 國 看 界 m ， 他 該 屆 只 在 方 幕 持 對 德 國 時 上 陣 。 菲 力 斯 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 3949 6631 1233 3180 1058 5836 2146 2357 5397 5636 1184 1323 1146 1914 4273 1751 5589 5838 1213 3172 924 5456 8020 100 100 8021 8024 5087 5147 671 2399 1288 2990 6639 712 2484 2451 1235 3309 2521 6283 8211 3641 1184 7081 1377 2990 7770 4413 7386 4777 6868 3122 5543 1213 8024 1872 3291 4413 7386 4638 4261 3560 3582 771 511 8198 3641 5439 2200 823 5445 1266 677 5838 1213 160 3221 4412 1298 5836 7271 2200 3040 2861 4638 1184 1751 2157 7386 7386 1351 8024 1060 782 3295 671 1398 2519 2782 8213 2399 2548 1751 4692 4518 155 8024 800 6283 2234 1372 1762 3175 2391 2898 2205 2548 1751 3229 677 7369 511 5838 1213 3172 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:truths: 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: 7\n",
            "INFO:tensorflow:tokens: [CLS] 阿 一 奴 走 負 日 影 慘 法 修 咸 頓 給 球 的 的 學 ， 今 晨 主 場 憑 奧 ， 爾 一 傳 一 射 ， 以 2 ： m 晰 走 般 尼 連 工 ， 以 19 戰 39 分 升 上 榜 ， ， 較 少 踢 一 場 的 為 斯 特 城 多 1 分 ， 要 帥 雲 格 大 讚 奧 斯 爾 有 「 兵 上 廠 」 名 宿 柏 金 的 影 子 埃 的 場 出 擊 的 兵 工 廠 以 哥 林 場 伯 斯 、 基 比 爾 包 列 斯 達 、 阿 歷 士 張 伯 倫 及 包 蘭 基 比 斯 擔 正 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 7350 671 1958 6624 6511 3189 2512 2711 3791 934 1496 7524 5183 4413 4638 4638 2119 8024 791 3247 712 1842 2731 1953 8024 4273 671 1001 671 2198 8024 809 123 8038 155 3251 6624 5663 2225 6865 2339 8024 809 8131 2782 8240 1146 1285 677 3528 8024 8024 6733 2208 6677 671 1842 4638 4158 3172 4294 1814 1914 122 1146 8024 6206 2371 7437 3419 1920 6367 1953 3172 4273 3300 519 1070 677 2449 520 1399 2162 3377 7032 4638 2512 2094 1812 4638 1842 1139 3080 4638 1070 2339 2449 809 1520 3360 1842 843 3172 510 1825 3683 4273 1259 1154 3172 6888 510 7350 3644 1894 2484 843 961 1350 1259 5984 1825 3683 3172 3085 3633 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:truths: 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:Writing example 1000 of 174664\n",
            "INFO:tensorflow:Writing example 2000 of 174664\n",
            "INFO:tensorflow:Writing example 3000 of 174664\n",
            "INFO:tensorflow:Writing example 4000 of 174664\n",
            "INFO:tensorflow:Writing example 5000 of 174664\n",
            "INFO:tensorflow:Writing example 6000 of 174664\n",
            "INFO:tensorflow:Writing example 7000 of 174664\n",
            "INFO:tensorflow:Writing example 8000 of 174664\n",
            "INFO:tensorflow:Writing example 9000 of 174664\n",
            "INFO:tensorflow:Writing example 10000 of 174664\n",
            "INFO:tensorflow:Writing example 11000 of 174664\n",
            "INFO:tensorflow:Writing example 12000 of 174664\n",
            "INFO:tensorflow:Writing example 13000 of 174664\n",
            "INFO:tensorflow:Writing example 14000 of 174664\n",
            "INFO:tensorflow:Writing example 15000 of 174664\n",
            "INFO:tensorflow:Writing example 16000 of 174664\n",
            "INFO:tensorflow:Writing example 17000 of 174664\n",
            "INFO:tensorflow:Writing example 18000 of 174664\n",
            "INFO:tensorflow:Writing example 19000 of 174664\n",
            "INFO:tensorflow:Writing example 20000 of 174664\n",
            "INFO:tensorflow:Writing example 21000 of 174664\n",
            "INFO:tensorflow:Writing example 22000 of 174664\n",
            "INFO:tensorflow:Writing example 23000 of 174664\n",
            "INFO:tensorflow:Writing example 24000 of 174664\n",
            "INFO:tensorflow:Writing example 25000 of 174664\n",
            "INFO:tensorflow:Writing example 26000 of 174664\n",
            "INFO:tensorflow:Writing example 27000 of 174664\n",
            "INFO:tensorflow:Writing example 28000 of 174664\n",
            "INFO:tensorflow:Writing example 29000 of 174664\n",
            "INFO:tensorflow:Writing example 30000 of 174664\n",
            "INFO:tensorflow:Writing example 31000 of 174664\n",
            "INFO:tensorflow:Writing example 32000 of 174664\n",
            "INFO:tensorflow:Writing example 33000 of 174664\n",
            "INFO:tensorflow:Writing example 34000 of 174664\n",
            "INFO:tensorflow:Writing example 35000 of 174664\n",
            "INFO:tensorflow:Writing example 36000 of 174664\n",
            "INFO:tensorflow:Writing example 37000 of 174664\n",
            "INFO:tensorflow:Writing example 38000 of 174664\n",
            "INFO:tensorflow:Writing example 39000 of 174664\n",
            "INFO:tensorflow:Writing example 40000 of 174664\n",
            "INFO:tensorflow:Writing example 41000 of 174664\n",
            "INFO:tensorflow:Writing example 42000 of 174664\n",
            "INFO:tensorflow:Writing example 43000 of 174664\n",
            "INFO:tensorflow:Writing example 44000 of 174664\n",
            "INFO:tensorflow:Writing example 45000 of 174664\n",
            "INFO:tensorflow:Writing example 46000 of 174664\n",
            "INFO:tensorflow:Writing example 47000 of 174664\n",
            "INFO:tensorflow:Writing example 48000 of 174664\n",
            "INFO:tensorflow:Writing example 49000 of 174664\n",
            "INFO:tensorflow:Writing example 50000 of 174664\n",
            "INFO:tensorflow:Writing example 51000 of 174664\n",
            "INFO:tensorflow:Writing example 52000 of 174664\n",
            "INFO:tensorflow:Writing example 53000 of 174664\n",
            "INFO:tensorflow:Writing example 54000 of 174664\n",
            "INFO:tensorflow:Writing example 55000 of 174664\n",
            "INFO:tensorflow:Writing example 56000 of 174664\n",
            "INFO:tensorflow:Writing example 57000 of 174664\n",
            "INFO:tensorflow:Writing example 58000 of 174664\n",
            "INFO:tensorflow:Writing example 59000 of 174664\n",
            "INFO:tensorflow:Writing example 60000 of 174664\n",
            "INFO:tensorflow:Writing example 61000 of 174664\n",
            "INFO:tensorflow:Writing example 62000 of 174664\n",
            "INFO:tensorflow:Writing example 63000 of 174664\n",
            "INFO:tensorflow:Writing example 64000 of 174664\n",
            "INFO:tensorflow:Writing example 65000 of 174664\n",
            "INFO:tensorflow:Writing example 66000 of 174664\n",
            "INFO:tensorflow:Writing example 67000 of 174664\n",
            "INFO:tensorflow:Writing example 68000 of 174664\n",
            "INFO:tensorflow:Writing example 69000 of 174664\n",
            "INFO:tensorflow:Writing example 70000 of 174664\n",
            "INFO:tensorflow:Writing example 71000 of 174664\n",
            "INFO:tensorflow:Writing example 72000 of 174664\n",
            "INFO:tensorflow:Writing example 73000 of 174664\n",
            "INFO:tensorflow:Writing example 74000 of 174664\n",
            "INFO:tensorflow:Writing example 75000 of 174664\n",
            "INFO:tensorflow:Writing example 76000 of 174664\n",
            "INFO:tensorflow:Writing example 77000 of 174664\n",
            "INFO:tensorflow:Writing example 78000 of 174664\n",
            "INFO:tensorflow:Writing example 79000 of 174664\n",
            "INFO:tensorflow:Writing example 80000 of 174664\n",
            "INFO:tensorflow:Writing example 81000 of 174664\n",
            "INFO:tensorflow:Writing example 82000 of 174664\n",
            "INFO:tensorflow:Writing example 83000 of 174664\n",
            "INFO:tensorflow:Writing example 84000 of 174664\n",
            "INFO:tensorflow:Writing example 85000 of 174664\n",
            "INFO:tensorflow:Writing example 86000 of 174664\n",
            "INFO:tensorflow:Writing example 87000 of 174664\n",
            "INFO:tensorflow:Writing example 88000 of 174664\n",
            "INFO:tensorflow:Writing example 89000 of 174664\n",
            "INFO:tensorflow:Writing example 90000 of 174664\n",
            "INFO:tensorflow:Writing example 91000 of 174664\n",
            "INFO:tensorflow:Writing example 92000 of 174664\n",
            "INFO:tensorflow:Writing example 93000 of 174664\n",
            "INFO:tensorflow:Writing example 94000 of 174664\n",
            "INFO:tensorflow:Writing example 95000 of 174664\n",
            "INFO:tensorflow:Writing example 96000 of 174664\n",
            "INFO:tensorflow:Writing example 97000 of 174664\n",
            "INFO:tensorflow:Writing example 98000 of 174664\n",
            "INFO:tensorflow:Writing example 99000 of 174664\n",
            "INFO:tensorflow:Writing example 100000 of 174664\n",
            "INFO:tensorflow:Writing example 101000 of 174664\n",
            "INFO:tensorflow:Writing example 102000 of 174664\n",
            "INFO:tensorflow:Writing example 103000 of 174664\n",
            "INFO:tensorflow:Writing example 104000 of 174664\n",
            "INFO:tensorflow:Writing example 105000 of 174664\n",
            "INFO:tensorflow:Writing example 106000 of 174664\n",
            "INFO:tensorflow:Writing example 107000 of 174664\n",
            "INFO:tensorflow:Writing example 108000 of 174664\n",
            "INFO:tensorflow:Writing example 109000 of 174664\n",
            "INFO:tensorflow:Writing example 110000 of 174664\n",
            "INFO:tensorflow:Writing example 111000 of 174664\n",
            "INFO:tensorflow:Writing example 112000 of 174664\n",
            "INFO:tensorflow:Writing example 113000 of 174664\n",
            "INFO:tensorflow:Writing example 114000 of 174664\n",
            "INFO:tensorflow:Writing example 115000 of 174664\n",
            "INFO:tensorflow:Writing example 116000 of 174664\n",
            "INFO:tensorflow:Writing example 117000 of 174664\n",
            "INFO:tensorflow:Writing example 118000 of 174664\n",
            "INFO:tensorflow:Writing example 119000 of 174664\n",
            "INFO:tensorflow:Writing example 120000 of 174664\n",
            "INFO:tensorflow:Writing example 121000 of 174664\n",
            "INFO:tensorflow:Writing example 122000 of 174664\n",
            "INFO:tensorflow:Writing example 123000 of 174664\n",
            "INFO:tensorflow:Writing example 124000 of 174664\n",
            "INFO:tensorflow:Writing example 125000 of 174664\n",
            "INFO:tensorflow:Writing example 126000 of 174664\n",
            "INFO:tensorflow:Writing example 127000 of 174664\n",
            "INFO:tensorflow:Writing example 128000 of 174664\n",
            "INFO:tensorflow:Writing example 129000 of 174664\n",
            "INFO:tensorflow:Writing example 130000 of 174664\n",
            "INFO:tensorflow:Writing example 131000 of 174664\n",
            "INFO:tensorflow:Writing example 132000 of 174664\n",
            "INFO:tensorflow:Writing example 133000 of 174664\n",
            "INFO:tensorflow:Writing example 134000 of 174664\n",
            "INFO:tensorflow:Writing example 135000 of 174664\n",
            "INFO:tensorflow:Writing example 136000 of 174664\n",
            "INFO:tensorflow:Writing example 137000 of 174664\n",
            "INFO:tensorflow:Writing example 138000 of 174664\n",
            "INFO:tensorflow:Writing example 139000 of 174664\n",
            "INFO:tensorflow:Writing example 140000 of 174664\n",
            "INFO:tensorflow:Writing example 141000 of 174664\n",
            "INFO:tensorflow:Writing example 142000 of 174664\n",
            "INFO:tensorflow:Writing example 143000 of 174664\n",
            "INFO:tensorflow:Writing example 144000 of 174664\n",
            "INFO:tensorflow:Writing example 145000 of 174664\n",
            "INFO:tensorflow:Writing example 146000 of 174664\n",
            "INFO:tensorflow:Writing example 147000 of 174664\n",
            "INFO:tensorflow:Writing example 148000 of 174664\n",
            "INFO:tensorflow:Writing example 149000 of 174664\n",
            "INFO:tensorflow:Writing example 150000 of 174664\n",
            "INFO:tensorflow:Writing example 151000 of 174664\n",
            "INFO:tensorflow:Writing example 152000 of 174664\n",
            "INFO:tensorflow:Writing example 153000 of 174664\n",
            "INFO:tensorflow:Writing example 154000 of 174664\n",
            "INFO:tensorflow:Writing example 155000 of 174664\n",
            "INFO:tensorflow:Writing example 156000 of 174664\n",
            "INFO:tensorflow:Writing example 157000 of 174664\n",
            "INFO:tensorflow:Writing example 158000 of 174664\n",
            "INFO:tensorflow:Writing example 159000 of 174664\n",
            "INFO:tensorflow:Writing example 160000 of 174664\n",
            "INFO:tensorflow:Writing example 161000 of 174664\n",
            "INFO:tensorflow:Writing example 162000 of 174664\n",
            "INFO:tensorflow:Writing example 163000 of 174664\n",
            "INFO:tensorflow:Writing example 164000 of 174664\n",
            "INFO:tensorflow:Writing example 165000 of 174664\n",
            "INFO:tensorflow:Writing example 166000 of 174664\n",
            "INFO:tensorflow:Writing example 167000 of 174664\n",
            "INFO:tensorflow:Writing example 168000 of 174664\n",
            "INFO:tensorflow:Writing example 169000 of 174664\n",
            "INFO:tensorflow:Writing example 170000 of 174664\n",
            "INFO:tensorflow:Writing example 171000 of 174664\n",
            "INFO:tensorflow:Writing example 172000 of 174664\n",
            "INFO:tensorflow:Writing example 173000 of 174664\n",
            "INFO:tensorflow:Writing example 174000 of 174664\n",
            "INFO:tensorflow:Writing example 0 of 43667\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: 184484\n",
            "INFO:tensorflow:tokens: [CLS] 粟 米 」 ， 是 民 多 人 的 [UNK] [UNK] ， 隨 便 開 個 罐 頭 ， 加 兩 車 多 士 ， 已 是 滿 足 的 一 餐 。 但 加 點 雞 述 或 魚 肚 ， 又 可 成 為 席 上 一 道 人 見 她 愛 的 湯 羹 。 更 錄 接 張 間 澄 、 馮 嘉 雯 剪 接 ： 張 芷 澄 毒 肚 ， ： 豐 條 膠 原 蛋 白 ， 對 皮 膚 好 （ 皮 亦 中 的 蛋 白 質 有 建 有 屬 膠 巴 蛋 白 ） ， 加 入 湯 羹 美 味 又 養 顏 及 女 士 最 愛 。 對 法 簡 單 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 5112 5101 520 8024 3221 3696 1914 782 4638 100 100 8024 7401 912 7274 943 5380 7531 8024 1217 1060 6722 1914 1894 8024 2347 3221 4021 6639 4638 671 7623 511 852 1217 7953 7430 6835 2772 7797 5496 8024 1348 1377 2768 4158 2375 677 671 6887 782 6210 1961 2695 4638 3966 5416 511 3291 7087 2970 2484 7279 4067 510 7681 1649 7435 1198 2970 8038 2484 5711 4067 3681 5496 8024 8038 6493 3454 5608 1333 6028 4635 8024 2205 4649 5604 1962 8020 4649 771 704 4638 6028 4635 6549 3300 2456 3300 2253 5608 2349 6028 4635 8021 8024 1217 1057 3966 5416 5401 1456 1348 7621 7542 1350 1957 1894 3297 2695 511 2205 3791 5080 1606 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:truths: 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: 184485\n",
            "INFO:tensorflow:tokens: [CLS] 要 拍 一 張 令 式 驚 豔 的 野 生 動 物 照 片 ， 需 用 耐 性 加 上 一 過 運 氣 . 不 過 巴 西 h 名 逐 影 師 卻 以 2 價 代 替 ， 早 前 該 中 洲 4 逾 拍 都 的 心 蟻 獸 照 片 「 夜 襲 者 （ ， [UNK] [UNK] 胡 」 的 英 國 自 然 歷 史 博 物 館 舉 後 然 「 年 度 野 生 動 物 攝 影 大 賽 」 中 獲 獎 ， 不 咎 近 日 評 審 發 現 有 關 照 片 原 來 是 造 等 身 姐 中 的 撞 蟻 獸 根 本 是 標 本 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 6206 2864 671 2484 808 2466 7711 6494 4638 7029 4495 1240 4289 4212 4275 8024 7444 4500 5447 2595 1217 677 671 6882 6880 3706 119 679 6882 2349 6205 150 1399 6852 2512 2374 1320 809 123 1019 807 3296 8024 3193 1184 6283 704 3828 125 6874 2864 6963 4638 2552 6102 4366 4212 4275 519 1915 6204 5442 8020 8024 100 100 5529 520 4638 5739 1751 5632 4197 3644 1380 1300 4289 7631 5647 2527 4197 519 2399 2428 7029 4495 1240 4289 3109 2512 1920 6555 520 704 4363 4354 8024 679 1470 6818 3189 6268 2182 4634 4412 3300 7302 4212 4275 1333 889 3221 6863 5023 6716 1995 704 4638 3058 6102 4366 3418 3315 3221 3560 3315 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:truths: 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: 184486\n",
            "INFO:tensorflow:tokens: [CLS] 養 兒 一 百 歲 ， 長 憂 九 十 結 ， 若 子 法 為 毒 閉 便 譜 完 學 童 高 是 新 憂 道 建 日 更 有 媽 媽 以 「 一 個 走 投 仲 1 0 自 閉 症 患 者 媽 媽 」 向 特 去 林 鄭 月 娥 發 宣 開 信 深 延 苦 」 ； c 母 親 關 期 間 ， 《 香 港 01 》 中 連 續 報 道 不 同 [UNK] 媽 媽 面 對 的 辛 酸 。 膝 下 育 t 一 跟 姊 弟 作 劉 太 說 ， 們 5 大 的 兒 子 於 幼 時 這 說 話 及 間 法 接 受 主 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 7621 1051 671 4636 3641 8024 7269 2726 736 1282 5178 8024 5735 2094 3791 4158 3681 7273 912 6355 2130 2119 4997 7770 3221 3173 2726 6887 2456 3189 3291 3300 2061 2061 809 519 671 943 6624 2832 815 122 121 5632 7273 4568 2642 5442 2061 2061 520 1403 4294 1343 3360 6972 3299 2029 4634 2146 7274 928 3918 2454 5736 520 8039 145 3678 6217 7302 3309 7279 8024 517 7676 3949 8146 518 704 6865 5265 1841 6887 679 1398 100 2061 2061 7481 2205 4638 6789 7000 511 5607 678 5509 162 671 6656 1992 2475 868 1208 1922 6303 8024 947 126 1920 4638 1051 2094 3176 2405 3229 6857 6303 6282 1350 7279 3791 2970 1358 712 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:truths: 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0\n",
            "INFO:tensorflow:Writing example 1000 of 43667\n",
            "INFO:tensorflow:Writing example 2000 of 43667\n",
            "INFO:tensorflow:Writing example 3000 of 43667\n",
            "INFO:tensorflow:Writing example 4000 of 43667\n",
            "INFO:tensorflow:Writing example 5000 of 43667\n",
            "INFO:tensorflow:Writing example 6000 of 43667\n",
            "INFO:tensorflow:Writing example 7000 of 43667\n",
            "INFO:tensorflow:Writing example 8000 of 43667\n",
            "INFO:tensorflow:Writing example 9000 of 43667\n",
            "INFO:tensorflow:Writing example 10000 of 43667\n",
            "INFO:tensorflow:Writing example 11000 of 43667\n",
            "INFO:tensorflow:Writing example 12000 of 43667\n",
            "INFO:tensorflow:Writing example 13000 of 43667\n",
            "INFO:tensorflow:Writing example 14000 of 43667\n",
            "INFO:tensorflow:Writing example 15000 of 43667\n",
            "INFO:tensorflow:Writing example 16000 of 43667\n",
            "INFO:tensorflow:Writing example 17000 of 43667\n",
            "INFO:tensorflow:Writing example 18000 of 43667\n",
            "INFO:tensorflow:Writing example 19000 of 43667\n",
            "INFO:tensorflow:Writing example 20000 of 43667\n",
            "INFO:tensorflow:Writing example 21000 of 43667\n",
            "INFO:tensorflow:Writing example 22000 of 43667\n",
            "INFO:tensorflow:Writing example 23000 of 43667\n",
            "INFO:tensorflow:Writing example 24000 of 43667\n",
            "INFO:tensorflow:Writing example 25000 of 43667\n",
            "INFO:tensorflow:Writing example 26000 of 43667\n",
            "INFO:tensorflow:Writing example 27000 of 43667\n",
            "INFO:tensorflow:Writing example 28000 of 43667\n",
            "INFO:tensorflow:Writing example 29000 of 43667\n",
            "INFO:tensorflow:Writing example 30000 of 43667\n",
            "INFO:tensorflow:Writing example 31000 of 43667\n",
            "INFO:tensorflow:Writing example 32000 of 43667\n",
            "INFO:tensorflow:Writing example 33000 of 43667\n",
            "INFO:tensorflow:Writing example 34000 of 43667\n",
            "INFO:tensorflow:Writing example 35000 of 43667\n",
            "INFO:tensorflow:Writing example 36000 of 43667\n",
            "INFO:tensorflow:Writing example 37000 of 43667\n",
            "INFO:tensorflow:Writing example 38000 of 43667\n",
            "INFO:tensorflow:Writing example 39000 of 43667\n",
            "INFO:tensorflow:Writing example 40000 of 43667\n",
            "INFO:tensorflow:Writing example 41000 of 43667\n",
            "INFO:tensorflow:Writing example 42000 of 43667\n",
            "INFO:tensorflow:Writing example 43000 of 43667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<__main__.InputFeatures at 0x7fe2a6566e10>,\n",
              "  <__main__.InputFeatures at 0x7fe2a6566f28>,\n",
              "  <__main__.InputFeatures at 0x7fe2a6566dd8>,\n",
              "  <__main__.InputFeatures at 0x7fe2a6566fd0>,\n",
              "  <__main__.InputFeatures at 0x7fe2a6566eb8>,\n",
              "  <__main__.InputFeatures at 0x7fe2a6566d68>,\n",
              "  <__main__.InputFeatures at 0x7fe2a6566da0>,\n",
              "  <__main__.InputFeatures at 0x7fe2a6566f98>,\n",
              "  <__main__.InputFeatures at 0x7fe2a6566b38>,\n",
              "  <__main__.InputFeatures at 0x7fe2a65669e8>],\n",
              " 174664)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "oaLMQIY_1Ks2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "27aa1cad-1cd1-4989-8169-933a67b05f52"
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('./dataset/train_features_%s.pkl'%MAX_SEQ_LENGTH, 'wb') as f:\n",
        "  pickle.dump(train_features, f)\n",
        "\n",
        "  \n",
        "with open('./dataset/test_features_%s.pkl'%MAX_SEQ_LENGTH, 'wb') as f:\n",
        "  pickle.dump(test_features, f)\n",
        "\n",
        "  \n",
        "!gsutil rsync ./dataset gs://dev-test-bert-tpu/dataset"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building synchronization state...\n",
            "Starting synchronization...\n",
            "Copying file://./dataset/test_features_128.pkl [Content-Type=application/octet-stream]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "Copying file://./dataset/train_features_128.pkl [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 2 objects/1009.5 MiB.                                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x3iHB8z8D034",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}