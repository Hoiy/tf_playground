{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT seq prediction",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "QZrG5D5TTdAc",
        "colab_type": "code",
        "outputId": "bb505ebe-3fcb-4289-8d97-40b389140a11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pyarrow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/dist-packages (0.11.1)\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "191zq3ZErihP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1qgmgBOFcLJR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a2c2a607-666b-4e26-ab18-39b643c68568"
      },
      "cell_type": "code",
      "source": [
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.96.191.170:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 14398697125759226736),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 6639692014189080735),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 396955583472844017),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7678346788829680275),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 16360513484565750990),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 11032536774747126552),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 5938213214912642799),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 12609591825908486848),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 9169311859955520836),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 17421505844239283845),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 6221583257447635821),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 15457314318044336166)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7wzwke0sxS6W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
        "if not 'bert_repo' in sys.path:\n",
        "  sys.path += ['bert_repo']  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xliigWmsdqqJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tokenization\n",
        "\n",
        "BERT_PRETRAINED_DIR = 'gs://dev-test-bert-tpu/chinese_bert/'\n",
        "VOCAB_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
        "BERT_MODEL = 'chinese_L-12_H-768_A-12'\n",
        "DO_LOWER_CASE = BERT_MODEL.startswith('uncased')\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=DO_LOWER_CASE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tYkaAlJNfhul",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "dd2163d1-790f-462c-9249-1ab6756988b1"
      },
      "cell_type": "code",
      "source": [
        "# TASK = 'CoLA' #@param {type:\"string\"}\n",
        "# assert TASK in ('MRPC', 'CoLA'), 'Only (MRPC, CoLA) are demonstrated here.'\n",
        "# Download glue data.\n",
        "# ! test -d download_glue_repo || git clone https://gist.github.com/60c2bdb54d156a41194446737ce03e2e.git download_glue_repo\n",
        "# !python download_glue_repo/download_glue_data.py --data_dir='glue_data' --tasks=$TASK\n",
        "TASK = 'seq_prediction'\n",
        "!mkdir -p ./dataset\n",
        "!gsutil rsync gs://kaggle-195702-dataset/hk01 ./dataset\n",
        "\n",
        "# !wget https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip\n",
        "# !unzip -o chinese_L-12_H-768_A-12.zip\n",
        "  \n",
        "TASK_DATA_DIR = 'dataset'\n",
        "print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n",
        "!ls $TASK_DATA_DIR\n",
        "\n",
        "# Available pretrained model checkpoints:\n",
        "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
        "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
        "#   cased_L-12_H-768_A-12: cased BERT large model\n",
        "\n",
        "# BERT_PRETRAINED_DIR = 'gs://cloud-tpu-checkpoints/bert/' + BERT_MODEL\n",
        "# BERT_PRETRAINED_DIR = '/content/' + BERT_MODEL\n",
        "BERT_PRETRAINED_DIR = 'gs://dev-test-bert-tpu/chinese_bert/'\n",
        "\n",
        "print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
        "!gsutil ls $BERT_PRETRAINED_DIR\n",
        "\n",
        "BUCKET = 'dev-test-bert-tpu' #@param {type:\"string\"}\n",
        "assert BUCKET, 'Must specify an existing GCS bucket name'\n",
        "OUTPUT_DIR = 'gs://{}/bert/models/{}'.format(BUCKET, TASK)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building synchronization state...\n",
            "Starting synchronization...\n",
            "***** Task data directory: dataset *****\n",
            "article_contents.csv\t\t article_contents.txt\ttrain_features_128.pkl\n",
            "article_contents.snappy.parquet  test_features_128.pkl\ttrain_features.pkl\n",
            "***** BERT pretrained directory: gs://dev-test-bert-tpu/chinese_bert/ *****\n",
            "gs://dev-test-bert-tpu/chinese_bert/\n",
            "gs://dev-test-bert-tpu/chinese_bert/bert_config.json\n",
            "gs://dev-test-bert-tpu/chinese_bert/bert_model.ckpt.data-00000-of-00001\n",
            "gs://dev-test-bert-tpu/chinese_bert/bert_model.ckpt.index\n",
            "gs://dev-test-bert-tpu/chinese_bert/bert_model.ckpt.meta\n",
            "gs://dev-test-bert-tpu/chinese_bert/vocab.txt\n",
            "***** Model output directory: gs://dev-test-bert-tpu/bert/models/seq_prediction *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XRuLgBmFHvHs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids,\n",
        "                 use_one_hot_embeddings):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "  model = modeling.BertModel(\n",
        "      config=bert_config,\n",
        "      is_training=is_training,\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      token_type_ids=segment_ids,\n",
        "      use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "  final_hidden = model.get_sequence_output()\n",
        "\n",
        "  final_hidden_shape = modeling.get_shape_list(final_hidden, expected_rank=3)\n",
        "  batch_size = final_hidden_shape[0]\n",
        "  seq_length = final_hidden_shape[1]\n",
        "  hidden_size = final_hidden_shape[2]\n",
        "  \n",
        "  print(batch_size)\n",
        "  print(seq_length)\n",
        "  print(hidden_size)\n",
        "\n",
        "  output_weights = tf.get_variable(\n",
        "      \"cls/squad/output_weights\", [1, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"cls/squad/output_bias\", [1], initializer=tf.zeros_initializer())\n",
        "\n",
        "  final_hidden_matrix = tf.reshape(final_hidden,\n",
        "                                   [batch_size * seq_length, hidden_size])\n",
        "  \n",
        "  logits = tf.matmul(final_hidden_matrix, output_weights, transpose_b=True)\n",
        "  logits = tf.nn.bias_add(logits, output_bias)\n",
        "\n",
        "  logits = tf.reshape(logits, [batch_size, seq_length, 1])\n",
        "  logits = tf.transpose(logits, [2, 0, 1])\n",
        "\n",
        "  unstacked_logits = tf.unstack(logits, axis=0)\n",
        "\n",
        "  (pred_logits) = (unstacked_logits[0])\n",
        "  \n",
        "  print(pred_logits)\n",
        "\n",
        "  return (pred_logits)\n",
        "    \n",
        "    \n",
        "\n",
        "# def model_fn_builder(bert_config, init_checkpoint, learning_rate,\n",
        "#                      num_train_steps, num_warmup_steps, use_tpu,\n",
        "#                      use_one_hot_embeddings):\n",
        "#   \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "#   def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "#     \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "#     tf.logging.info(\"*** Features ***\")\n",
        "#     for name in sorted(features.keys()):\n",
        "#       tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "\n",
        "#     input_ids = features[\"input_ids\"]\n",
        "#     input_mask = features[\"input_mask\"]\n",
        "#     segment_ids = features[\"segment_ids\"]    \n",
        "#     truths = features[\"truths\"]\n",
        "\n",
        "#     is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "#     pred = create_model(\n",
        "#         bert_config=bert_config,\n",
        "#         is_training=is_training,\n",
        "#         input_ids=input_ids,\n",
        "#         input_mask=input_mask,\n",
        "#         segment_ids=segment_ids,\n",
        "#         use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "  \n",
        "#     tvars = tf.trainable_variables()\n",
        "\n",
        "#     initialized_variable_names = {}\n",
        "#     scaffold_fn = None\n",
        "#     if init_checkpoint:\n",
        "#       (assignment_map, initialized_variable_names\n",
        "#       ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "#       if use_tpu:\n",
        "\n",
        "#         def tpu_scaffold():\n",
        "#           tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "#           return tf.train.Scaffold()\n",
        "\n",
        "#         scaffold_fn = tpu_scaffold\n",
        "#       else:\n",
        "#         tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "#     tf.logging.info(\"**** Trainable Variables ****\")\n",
        "#     for var in tvars:\n",
        "#       init_string = \"\"\n",
        "#       if var.name in initialized_variable_names:\n",
        "#         init_string = \", *INIT_FROM_CKPT*\"\n",
        "#       tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
        "#                       init_string)\n",
        "\n",
        "#     output_spec = None\n",
        "#     if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "#       seq_length = modeling.get_shape_list(input_ids)[1]\n",
        "#       total_loss = tf.reduce_mean(\n",
        "#           tf.reduce_mean(\n",
        "#               tf.keras.backend.binary_crossentropy(truths, pred), axis=-1))\n",
        "      \n",
        "#       train_op = optimization.create_optimizer(\n",
        "#           total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "      \n",
        "#       print(truths)\n",
        "#       print(pred)\n",
        "#       print(total_loss)\n",
        "\n",
        "#       output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "#           mode=mode,\n",
        "#           loss=total_loss,\n",
        "#           train_op=train_op,\n",
        "#           scaffold_fn=scaffold_fn    \n",
        "#       )\n",
        "    \n",
        "#     elif mode == tf.estimator.ModeKeys.PREDICT:\n",
        "#       predictions = {\n",
        "#           \"predictions\": pred\n",
        "#       }\n",
        "#       output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "#           mode=mode, predictions=predictions, scaffold_fn=scaffold_fn,\n",
        "#           eval_metrics=(tf.metrics.auc, {\n",
        "#             'labels': truths,\n",
        "#             'predictions': pred,\n",
        "#             'weights': input_mask\n",
        "#           })\n",
        "# )\n",
        "#     else:\n",
        "#       raise ValueError(\n",
        "#           \"Only TRAIN and PREDICT modes are supported: %s\" % (mode))\n",
        "\n",
        "#     return output_spec\n",
        "\n",
        "#   return model_fn\n",
        "\n",
        "\n",
        "\n",
        "def model_fn_builder(bert_config, init_checkpoint, learning_rate,\n",
        "                     num_train_steps, num_warmup_steps, use_tpu,\n",
        "                     use_one_hot_embeddings):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    tf.logging.info(\"*** Features ***\")\n",
        "    for name in sorted(features.keys()):\n",
        "      tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    truths = features[\"truths\"]\n",
        "    \n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    \n",
        "    \n",
        "    predictions = create_model(\n",
        "        bert_config=bert_config,\n",
        "        is_training=is_training,\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        segment_ids=segment_ids,\n",
        "        use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "  \n",
        "#     (total_loss, per_example_loss, logits, probabilities) = create_model(\n",
        "#         bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\n",
        "#         num_labels, use_one_hot_embeddings)\n",
        "\n",
        "    tvars = tf.trainable_variables()\n",
        "    initialized_variable_names = {}\n",
        "    scaffold_fn = None\n",
        "    if init_checkpoint:\n",
        "      (assignment_map, initialized_variable_names\n",
        "      ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "      if use_tpu:\n",
        "\n",
        "        def tpu_scaffold():\n",
        "          tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "          return tf.train.Scaffold()\n",
        "\n",
        "        scaffold_fn = tpu_scaffold\n",
        "      else:\n",
        "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "              \n",
        "    tf.logging.info(\"**** Trainable Variables ****\")\n",
        "    for var in tvars:\n",
        "      init_string = \"\"\n",
        "      if var.name in initialized_variable_names:\n",
        "        init_string = \", *INIT_FROM_CKPT*\"\n",
        "      tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
        "                      init_string)\n",
        "\n",
        "    input_mask_f = tf.cast(input_mask, tf.float32)\n",
        "    per_example_loss = tf.reduce_sum(tf.keras.backend.binary_crossentropy(truths, predictions) * input_mask_f, axis=-1) / tf.reduce_sum(input_mask_f, axis=-1)\n",
        "    total_loss = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "\n",
        "    total_loss = tf.reduce_mean(\n",
        "      tf.reduce_mean(\n",
        "        tf.keras.backend.binary_crossentropy(truths, predictions), axis=-1))\n",
        "\n",
        "      \n",
        "    output_spec = None\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      \n",
        "      train_op = optimization.create_optimizer(\n",
        "          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          train_op=train_op,\n",
        "          scaffold_fn=scaffold_fn)\n",
        "      \n",
        "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "\n",
        "      def metric_fn(truths, predictions, masks):\n",
        "        auc = tf.metrics.auc(\n",
        "            labels=truths, predictions=tf.nn.sigmoid(predictions), weights=masks)\n",
        "        return {\n",
        "            \"auc\": auc\n",
        "        }\n",
        "\n",
        "      eval_metrics = (metric_fn, [truths, predictions, input_mask])\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          eval_metrics=eval_metrics,\n",
        "          scaffold_fn=scaffold_fn)\n",
        "    else:\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          predictions={\"predictions\": predictions},\n",
        "          scaffold_fn=scaffold_fn)\n",
        "    return output_spec\n",
        "\n",
        "  return model_fn\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DataProcessor(object):\n",
        "  \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
        "\n",
        "  def get_train_examples(self, data_dir):\n",
        "    \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  def get_dev_examples(self, data_dir):\n",
        "    \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  def get_test_examples(self, data_dir):\n",
        "    \"\"\"Gets a collection of `InputExample`s for prediction.\"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  def get_labels(self):\n",
        "    \"\"\"Gets the list of labels for this data set.\"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  @classmethod\n",
        "  def _read_tsv(cls, input_file, quotechar=None):\n",
        "    \"\"\"Reads a tab separated value file.\"\"\"\n",
        "    with tf.gfile.Open(input_file, \"r\") as f:\n",
        "      reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
        "      lines = []\n",
        "      for line in reader:\n",
        "        lines.append(line)\n",
        "      return lines\n",
        "\n",
        "\n",
        "class DataSetProcessor(DataProcessor):\n",
        "  \"\"\"Processor for the MultiNLI data set (GLUE version).\"\"\"\n",
        "\n",
        "  def get_train_examples(self, data_dir):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
        "\n",
        "  def get_dev_examples(self, data_dir):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_tsv(os.path.join(data_dir, \"dev_matched.tsv\")),\n",
        "        \"dev_matched\")\n",
        "\n",
        "  def get_test_examples(self, data_dir):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_tsv(os.path.join(data_dir, \"test_matched.tsv\")), \"test\")\n",
        "\n",
        "  def get_labels(self):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    return [\"contradiction\", \"entailment\", \"neutral\"]\n",
        "\n",
        "  def _create_examples(self, lines, set_type):\n",
        "    \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "    examples = []\n",
        "    for (i, line) in enumerate(lines):\n",
        "      if i == 0:\n",
        "        continue\n",
        "      guid = \"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))\n",
        "      text_a = tokenization.convert_to_unicode(line[8])\n",
        "      text_b = tokenization.convert_to_unicode(line[9])\n",
        "      if set_type == \"test\":\n",
        "        label = \"contradiction\"\n",
        "      else:\n",
        "        label = tokenization.convert_to_unicode(line[-1])\n",
        "      examples.append(\n",
        "          InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
        "    return examples\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TcizdHx9KGvc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Setup task specific model and TPU running config.\n",
        "\n",
        "import modeling\n",
        "import optimization\n",
        "# import run_classifier\n",
        "\n",
        "\n",
        "# Model Hyper Parameters\n",
        "TRAIN_BATCH_SIZE = 32 #@param {type:\"number\"}\n",
        "EVAL_BATCH_SIZE = 8 #@param {type:\"number\"}\n",
        "LEARNING_RATE = 2e-5 #@param {type:\"number\"}\n",
        "NUM_TRAIN_EPOCHS = 100.0 #@param {type:\"number\"}\n",
        "WARMUP_PROPORTION = 0.1 #@param {type:\"number\"}\n",
        "MAX_SEQ_LENGTH = 128 #@param {type:\"number\"}\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 1000 #@param {type:\"number\"}\n",
        "ITERATIONS_PER_LOOP = 1000 #@param {type:\"number\"}\n",
        "NUM_TPU_CORES = 8 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "CONFIG_FILE = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
        "INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
        "\n",
        "\n",
        "# processors = {\n",
        "#   \"cola\": run_classifier.ColaProcessor,\n",
        "#   \"mnli\": run_classifier.MnliProcessor,\n",
        "#   \"mrpc\": run_classifier.MrpcProcessor,\n",
        "# }\n",
        "# processor = processors[TASK.lower()]()\n",
        "# label_list = processor.get_labels()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DV-8ggqON4bD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c044551d-b1f4-400f-e4d3-67b373a40e7b"
      },
      "cell_type": "code",
      "source": [
        "! ls $BERT_PRETRAINED_DIR"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'gs://dev-test-bert-tpu/chinese_bert/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZOsIe62nKPEY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NOgRa0gp4AFY",
        "colab_type": "code",
        "outputId": "c00d0328-9d9f-471f-d391-0246bb28ef57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p ./dataset\n",
        "!gsutil rsync gs://dev-test-bert-tpu/dataset ./dataset\n",
        "\n",
        "import pickle\n",
        "  \n",
        "MAX_SEQ_LENGTH = 128 #@param {'type': 'number'}\n",
        "\n",
        "def input_fn_builder(features, seq_length, is_training, drop_remainder):\n",
        "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "  all_input_ids = []\n",
        "  all_input_mask = []\n",
        "  all_segment_ids = []\n",
        "  all_truths = []\n",
        "\n",
        "  for feature in features:\n",
        "    all_input_ids.append(feature.input_ids)\n",
        "    all_input_mask.append(feature.input_mask)\n",
        "    all_segment_ids.append(feature.segment_ids)\n",
        "    all_truths.append(feature.truths)\n",
        "\n",
        "  def input_fn(params):\n",
        "    \"\"\"The actual input function.\"\"\"\n",
        "    batch_size = params[\"batch_size\"]\n",
        "\n",
        "    num_examples = len(features)\n",
        "    print(num_examples)\n",
        "\n",
        "    # This is for demo purposes and does NOT scale to large data sets. We do\n",
        "    # not use Dataset.from_generator() because that uses tf.py_func which is\n",
        "    # not TPU compatible. The right way to load data is with TFRecordReader.\n",
        "    d = tf.data.Dataset.from_tensor_slices({\n",
        "        \"input_ids\":\n",
        "            tf.constant(\n",
        "                all_input_ids, \n",
        "                shape=[num_examples, seq_length],\n",
        "                name='input_ids_tf_constant',\n",
        "                dtype=tf.int32),\n",
        "        \"input_mask\":\n",
        "            tf.constant(\n",
        "                all_input_mask,\n",
        "                shape=[num_examples, seq_length],\n",
        "                name='input_mask_tf_constant',\n",
        "                dtype=tf.int32),\n",
        "        \"segment_ids\":\n",
        "            tf.constant(\n",
        "                all_segment_ids,\n",
        "                shape=[num_examples, seq_length],\n",
        "                name='segment_ids_tf_constant',\n",
        "                dtype=tf.int32),\n",
        "        \"truths\":\n",
        "            tf.constant(\n",
        "                all_truths, \n",
        "                shape=[num_examples, seq_length], \n",
        "                name='truths_tf_constant',\n",
        "                dtype=tf.float32),\n",
        "    })\n",
        "\n",
        "    if is_training:\n",
        "      d = d.repeat()\n",
        "      d = d.shuffle(buffer_size=100)\n",
        "\n",
        "    d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
        "    return d\n",
        "\n",
        "  return input_fn\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "  \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               input_ids,\n",
        "               input_mask,\n",
        "               segment_ids,\n",
        "               truths,\n",
        "               is_real_example=True):\n",
        "    self.input_ids = input_ids\n",
        "    self.input_mask = input_mask\n",
        "    self.segment_ids = segment_ids\n",
        "    self.is_real_example = is_real_example\n",
        "    self.truths = truths\n",
        "  \n",
        "with open('./dataset/train_features.pkl', 'rb') as f:\n",
        "  train_features = pickle.load(f)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building synchronization state...\n",
            "Starting synchronization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lX3TblIXLAnD",
        "colab_type": "code",
        "outputId": "3230213e-5540-40c9-e626-233a7a7e20d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "num_train_steps = int(\n",
        "    len(train_features) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "print(num_train_steps)\n",
        "print(num_warmup_steps)\n",
        "\n",
        "model_fn = model_fn_builder(\n",
        "    bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "    init_checkpoint=INIT_CHECKPOINT,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=True,\n",
        "    use_one_hot_embeddings=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "545821\n",
            "54582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uu2dQ_TId-uH",
        "colab_type": "code",
        "outputId": "911415b6-2a17-4c6a-92fe-bf518d65c516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=True,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f2d7084ae18>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://dev-test-bert-tpu/bert/models/seq_prediction', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      value: \"10.96.191.170:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2d70567a20>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': b'grpc://10.96.191.170:8470', '_evaluation_master': b'grpc://10.96.191.170:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': <tensorflow.contrib.cluster_resolver.python.training.tpu_cluster_resolver.TPUClusterResolver object at 0x7f2d8859bdd8>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5U_c8s2AvhgL",
        "colab_type": "code",
        "outputId": "46280a5f-e639-4587-8561-dfd39e1bfb55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4695
        }
      },
      "cell_type": "code",
      "source": [
        "# Train the model.\n",
        "print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
        "print('  Num examples = {}'.format(len(train_features)))\n",
        "print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
        "tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "train_input_fn = input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=True)\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print('***** Finished training at {} *****'.format(datetime.datetime.now()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Started training at 2018-12-21 09:56:30.131608 *****\n",
            "  Num examples = 174663\n",
            "  Batch size = 32\n",
            "INFO:tensorflow:  Num steps = 545821\n",
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.96.191.170:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 14398697125759226736)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 6639692014189080735)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 396955583472844017)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7678346788829680275)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 16360513484565750990)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 11032536774747126552)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 5938213214912642799)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 12609591825908486848)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 9169311859955520836)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 17421505844239283845)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 6221583257447635821)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 15457314318044336166)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "174663\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (4, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (4, 128)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (4, 128)\n",
            "INFO:tensorflow:  name = truths, shape = (4, 128)\n",
            "4\n",
            "128\n",
            "768\n",
            "Tensor(\"unstack:0\", shape=(4, 128), dtype=float32)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (21128, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = cls/squad/output_weights:0, shape = (1, 768)\n",
            "INFO:tensorflow:  name = cls/squad/output_bias:0, shape = (1,)\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into gs://dev-test-bert-tpu/bert/models/seq_prediction/model.ckpt.\n",
            "INFO:tensorflow:Initialized dataset iterators in 1 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:tpu_worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 4 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into gs://dev-test-bert-tpu/bert/models/seq_prediction/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.27451202, step = 1000\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 2000 into gs://dev-test-bert-tpu/bert/models/seq_prediction/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.15267064, step = 2000 (89.595 sec)\n",
            "INFO:tensorflow:global_step/sec: 11.1609\n",
            "INFO:tensorflow:examples/sec: 357.15\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 3000 into gs://dev-test-bert-tpu/bert/models/seq_prediction/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.29442108, step = 3000 (118.826 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.41591\n",
            "INFO:tensorflow:examples/sec: 269.309\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 4000 into gs://dev-test-bert-tpu/bert/models/seq_prediction/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.10939156, step = 4000 (90.879 sec)\n",
            "INFO:tensorflow:global_step/sec: 11.0036\n",
            "INFO:tensorflow:examples/sec: 352.114\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eoXRtSPZvdiS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Eval the model.\n",
        "eval_features = train_features[:10000]\n",
        "print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "print('  Num examples = {}'.format(len(eval_features)))\n",
        "print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
        "# Eval will be slightly WRONG on the TPU because it will truncate\n",
        "# the last batch.\n",
        "eval_steps = int(len(eval_features) / EVAL_BATCH_SIZE)\n",
        "eval_input_fn = input_fn_builder(\n",
        "    features=eval_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=True)\n",
        "result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
        "with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "  print(\"***** Eval results *****\")\n",
        "  for key in sorted(result.keys()):\n",
        "    print('  {} = {}'.format(key, str(result[key])))\n",
        "    writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dla1K-9_oQmA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yOdvlh_y-SAn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "truths = tf.constant([[0., 1., 0., 0., 1., 0., 0., 0.], [0., 1., 0., 0., 1., 0., 0., 0.]], dtype=tf.float32)\n",
        "predictions = tf.constant([[0.1, 0.8, 0., 0., 0., 0., 0., 0.9], [0.1, 0.8, 0., 0., 0., 0., 0., 0.9]], dtype=tf.float32)\n",
        "masks = tf.cast(tf.constant([[1, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0]], dtype=tf.int32), dtype=tf.float32)\n",
        "\n",
        "per_example_loss = tf.reduce_sum(tf.keras.backend.binary_crossentropy(truths, predictions) * masks, axis=-1) / tf.reduce_sum(masks, axis=-1)\n",
        "\n",
        "total_loss = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "# We can just use 'c.eval()' without passing 'sess'\n",
        "print(total_loss.eval())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZOir8ctV-d-s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "-np.log(0.9), -np.log(0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zqwdU8FH_lJl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}