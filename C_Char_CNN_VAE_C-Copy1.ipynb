{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Character Level CNN Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import Corpus.gutenberg as corpus\n",
    "from TextPreprocess.Tokenizer.Stanford import tokenize\n",
    "from Utils.visual import hist, tally\n",
    "from Utils.debug import dump\n",
    "from Utils.generator import sliding_window, random_window, transform\n",
    "from Utils.FS.file import save, load\n",
    "from Utils.keras import compact_embedding\n",
    "from Utils.misc import batch\n",
    "from Utils.indexer import build_index, index_2_one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras_tqdm import TQDMNotebookCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#data = tokenize(corpus.raw())\n",
    "data = corpus.gutenberg.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def char_generator():\n",
    "    for word in data:\n",
    "        for char in word:\n",
    "            yield char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "s2i, i2s, size = build_index(char_generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = max([len(word) for word in data])\n",
    "MAX_SEQ_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NUM_SYMBOL = size\n",
    "NUM_SYMBOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def word_generator():\n",
    "    for word in data:\n",
    "            yield word\n",
    "\n",
    "NUM_SAMPLE = len(list(word_generator()))\n",
    "NUM_SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, Conv2DTranspose, Dense, Flatten, Dropout, Reshape, Embedding\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    print(y_true, y_pred)\n",
    "    '''Just another crossentropy'''\n",
    "    #y_pred = T.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "    #y_pred /= y_pred.sum(axis=-1, keepdims=True)\n",
    "    #cce = T.nnet.categorical_crossentropy(y_pred, y_true)\n",
    "    '''\n",
    "    [np.average\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=y_true[i],\n",
    "            logits=y_pred[i],\n",
    "        )\n",
    "     for i in y_true]\n",
    "    '''\n",
    "    return y_true - y_pred\n",
    "\n",
    "def create_baseline(dropout=0, branching=5):\n",
    "    \n",
    "    activation = 'selu'\n",
    "    padding = 'same'\n",
    "    layer = 3\n",
    "    dim = [NUM_SYMBOL, 200, 400, 1000]\n",
    "    kernel = [5, 2, 2]\n",
    "    strides = [1, 5, 5]\n",
    "    \n",
    "    inp = Input(shape=(MAX_SEQ_LENGTH,NUM_SYMBOL))\n",
    "    #x = Embedding(NUM_SYMBOL, NUM_SYMBOL, weights=[np.eye(NUM_SYMBOL)], input_length=10, trainable=False)(inp)\n",
    "    x = Reshape((1, MAX_SEQ_LENGTH, NUM_SYMBOL))(inp)\n",
    "    for i in range(layer):\n",
    "        x = Conv2D(dim[i+1], (1, kernel[i]), strides=(1, strides[i]), activation=activation, padding=padding)(x)\n",
    "        \n",
    "    for i in reversed(range(layer)):\n",
    "        x = Conv2DTranspose(dim[i], (1, kernel[i]), strides=(1, strides[i]), activation=activation, padding=padding)(x)\n",
    "        \n",
    "    x = Reshape((MAX_SEQ_LENGTH, NUM_SYMBOL))(x)\n",
    "    model = Model(inp, x)\n",
    "    model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "DROPOUT = 0.5\n",
    "BRANCHING = 2\n",
    "\n",
    "model = create_baseline(DROPOUT, BRANCHING)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "def sample_generator(word_generator, batch_size = 64):\n",
    "    sample = []\n",
    "    for word in word_generator:\n",
    "        unpad = batch(s2i, word)\n",
    "        padded = pad_sequences([unpad], maxlen=MAX_SEQ_LENGTH, dtype='float32', padding='pre', truncating='pre', value=0.)\n",
    "        one_hot = to_categorical(padded, num_classes=NUM_SYMBOL)\n",
    "        sample.append(one_hot)\n",
    "        if len(sample) == batch_size:\n",
    "            train = np.array(sample)\n",
    "            yield(train, train)\n",
    "            sample = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word_gen = word_generator()\n",
    "next(sample_generator(word_gen, 2))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word_gen = word_generator()\n",
    "BATCH_SIZE = 128\n",
    "model.fit_generator(\n",
    "    sample_generator(word_gen, BATCH_SIZE),\n",
    "    NUM_SAMPLE // BATCH_SIZE,\n",
    "    epochs=200,\n",
    "    #class_weight=class_weight\n",
    "    verbose=0, callbacks=[TQDMNotebookCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
