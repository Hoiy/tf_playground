{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from Utils.FS import file\n",
    "from Utils.tensorflow_helper import show_graph\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import brown\n",
    "from scipy.sparse import coo_matrix, dok_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import TextPreprocess.words2dict as words2dict\n",
    "from tensorflow.python.layers import core as layers_core\n",
    "from tensorflow.python.client import timeline\n",
    "import time\n",
    "from DataLoader import GloVe\n",
    "from TextPreprocess.sequences import Sequences\n",
    "from TextPreprocess.Tokenizer.RegExp import tokenize\n",
    "import Utils.pandas_helper as ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "WORD_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = file.read('data/Quora/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: Loading Glove Model\n",
      "End: Loaded 400000 rows.\n"
     ]
    }
   ],
   "source": [
    "glove = GloVe.load2('./data/GloVe/glove.6B.{}d.txt'.format(WORD_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Dimension: 300\n",
      "Embedding Symbols: 400003\n",
      "Index to symbol: [(0, '65-35'), (1, 'sawley'), (2, 'miamisburg'), (3, 'atea'), (4, 'run-down'), (5, 'beyk'), (6, 'ca-125'), (7, 'foxes'), (8, '4-to-3'), (9, 'shenandoah')]\n"
     ]
    }
   ],
   "source": [
    "# emb: Symbol to float32 of fixed DIMENSION\n",
    "# Create an index mapping, index to symbol, symbol to index\n",
    "\n",
    "class Embedding:\n",
    "    def __init__(self, emb, verbose = False):\n",
    "        # assert emb is dictionary and each entry has same dimension\n",
    "        self.emb = emb\n",
    "        self.dim = len(self.emb[list(self.emb.keys())[0]])\n",
    "        self.emb['<UNK>'] = [0. for i in range(self.dim)]\n",
    "        self.emb['<PAD>'] = [1. for i in range(self.dim)]\n",
    "        self.emb['<GO>'] = [-1. for i in range(self.dim)]\n",
    "        \n",
    "        self.build_dicts()\n",
    "        \n",
    "        if verbose:\n",
    "            self.describe()\n",
    "        \n",
    "    def describe(self):\n",
    "        print('Embedding Dimension: {}'.format(self.dim))\n",
    "        print('Embedding Symbols: {}'.format(len(self.emb)))\n",
    "        print('Index to symbol: {}'.format([(i, self.idx2Sym[i]) for i in range(10)]))\n",
    "        \n",
    "    def getIndex(self, symbol):\n",
    "        if symbol in self.sym2Idx:\n",
    "            return self.sym2Idx[symbol]\n",
    "        else:\n",
    "            return self.sym2Idx['<UNK>']\n",
    "\n",
    "    def getEmb(self, symbol):\n",
    "        return self.emb[self.idx2Sym[self.getIndex(symbol)]]\n",
    "    \n",
    "    def getSymbols(self, indices):\n",
    "        return [self.idx2Sym[idx] for idx in indices]\n",
    "\n",
    "    def getNumpyArray(self):\n",
    "        return np.array([self.emb[self.idx2Sym[idx]] for idx in range(len(self.emb))])\n",
    "    \n",
    "    def build_dicts(self):\n",
    "        self.sym2Idx = {}\n",
    "        index = 0\n",
    "        for key in self.emb.keys():\n",
    "            self.sym2Idx[key] = index\n",
    "            index += 1\n",
    "            \n",
    "        self.idx2Sym = { v:k for k, v in self.sym2Idx.items()}\n",
    "\n",
    "glove_emb = Embedding(glove, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  404290\n"
     ]
    }
   ],
   "source": [
    "# print(train['is_duplicate'].describe())\n",
    "# print(train.sample(15))\n",
    "# print(train.iloc[261849]['question1'])\n",
    "# print(train.iloc[261849]['question2'])\n",
    "# print(train.iloc[261849]['is_duplicate'])\n",
    "print('Number of training samples: ', len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess(string):\n",
    "    return [glove_emb.getIndex(token.lower()) for token in tokenize(string)]\n",
    "\n",
    "def preprocessLabels(val):\n",
    "    return [1., 0.] if val == 0 else [0., 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "q1 = ph.parallel_apply(train['question1'].astype(str), preprocess)\n",
    "q2 = ph.parallel_apply(train['question2'].astype(str), preprocess)\n",
    "#labels = ph.parallel_apply(train['is_duplicate'].astype('float32'), preprocessLabels)\n",
    "labels = train['is_duplicate'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 404290\n",
      "Longest sequence length: 140\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEICAYAAACj2qi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAH1xJREFUeJzt3X+UHXV9//Hny8QgoJBA1gDZ4EaJPwJHC0aIX38hKCTA\n13D8gg36bYJGUyv4o+UcDfqtoMA50NpGOUJsNDGB0gSaoqQSjClgqW0TWASB8EPWgGRjQhaSgEIF\ng+/vH/NeHS53d4e9m9y75PU4556deX8+M/Oe2d373vnM3B1FBGZmZlW8rNkJmJnZ8OGiYWZmlblo\nmJlZZS4aZmZWmYuGmZlV5qJhZmaVuWiYlUgKSYc1YbvHSupuYPnzJf1jTh8q6TeSRgxRbt+S9NdD\nkWeddb9L0gNDtT7b9Vw07AUkvVPSf0l6QtI2Sf8p6W3NzuulZFcWp4h4JCJeGRHPDZDDmZJ+UmF9\nn4yIC4Yit9r9joj/iIg3DMW6bfcY2ewErLVI2g/4AfAXwDXAKOBdwDPNzMuaQ9KIgYqP7Vl8pmG1\nXg8QEcsi4rmI+J+I+FFE3NXbQdLHJN0nabuk1ZJeU2p7v6T78yzlm5L+XdLHs+0PQyg535F/eY7M\n+f0lLZK0WdImSRf2DrH0/lUs6Wu53YckTS+t6wBJ35X0q2z/fqntFEl3StqRZ1BvrnIgJO2V23tE\n0qM5TLN3th0rqVvSOZK2Zs4fLS17oKR/lfSkpNtyX36Sbbdkt5/lMNKflparu746uU3MY/trSWuA\nsf0c1zMlbci+D0n6iKQ3Ad8C3p457Mi+SyQtkLRK0lPAezN2Yc32vyjpMUkPS/pIKf7j3u93+fvW\n137XDndJelOuY4ek9ZI+UGpbIukySdfnvqyT9LqBvo82tFw0rNbPgeckLZU0XdKYcqOkGcAXgQ8C\nbcB/AMuybSxwLfD/KN7EfgG840VsewmwEzgMOBI4Afh4qf0Y4IFc998AiyQp264E9gEOB14NzM+c\njgQWA38OHAj8A7BS0l4V8rmYooj+SeY0Hvhyqf0gYP+MzwEuKx2vy4Cnss/sfAEQEe/OybfkMNLV\nFdZX65+A2/NYXFBef5mkfYFLgekR8SrgfwF3RsR9wCeB/84cRpcW+zBwEfAqoN7w1UG53fG53YWS\nBhxi6me/e3N9OfCvwI8ovoefBq6qWfdM4CvAGKAr87TdKSL88ut5L+BNFG/g3RRv4iuBcdl2AzCn\n1PdlwNPAa4BZwNpSm3IdH8/584F/LLV3AEExTDqOYghs71L7GcDNOX0m0FVq2yeXPQg4GPg9MKbO\nviwALqiJPQC8p499D4oCIYo3/deV2t4OPJTTxwL/A4wstW8FpgIjgN8Bbyi1XQj8pHY7pfk+11cn\nx0Pz+7JvKfZPvce25rjuC+wA/k/52JaO6U9qYkuAK+rELizlWbvta4C/zukf936/622jj/3uzul3\nAVuAl5XalwHnl/L4TqntJOD+Zv++7Gkvn2nYC0TEfRFxZkS0A0cAhwBfz+bXAN/I4YMdwDaKN9jx\n2W9jaT1Rnh/Aa4CXA5tL6/4Hir84e20prfvpnHwlMAHYFhHb+1jvOb3rzPVOyFz700ZRmG4vLffD\njPd6PCJ2luafznzaKN6wy/te5Tj0tb5ahwDbI+KpUuyX9VaYff6U4qxicw7tvHGAPAbKtd62Bzqe\nVRwCbIyI39ese3xpfktpuq/jY7uQi4b1KyLup/gL74gMbQT+PCJGl157R8R/AZsp3pAByKGjCaXV\nPUXxRtzroNL0RoozjbGl9e4XEYdXSHMjcICk0X20XVST7z4RsWyAdT5G8Zf/4aXl9o+IKm9SPRR/\njbeXYhP66DsYm4ExOfTU69C+OkfE6oh4P8UZ2f3At3ub+lpkgO3X2/avcrq/7/FAfgVMkFR+XzoU\n2PQi1mG7mIuGPY+kN+bF2Pacn0AxTLQ2u3wLOFfS4dm+v6TTs+164HBJH8yLsJ/h+W8adwLvVvE5\ngv2Bc3sbImIzxVj230naT9LLJL1O0nsGyjmXvQG4XNIYSS+X1Dt+/m3gk5KOUWFfSSdLetUA6/x9\nLjtf0qtzX8dLOrFCPs9RXNs5X9I++Zf9rJpujwKvHWhdfaz/l0An8BVJoyS9E/jf9fpKGidpRr7J\nPwP8hmIorzeHdkmjBpFG77bfBZwC/HPG7wQ+mPt9GMW1mbL+9nsdxdnD5/N7eGzu1/JB5Ge7iIuG\n1fo1xQXndXn3zFrgHuAcgIj4HnAJsFzSk9k2PdseA06nuID8ODAJ+M/eFUfEGuBq4C6Ki7g/qNn2\nLIpbfO8FtgMrKP46ruLPKK4j3E9xLeBzuc1O4BPAN3OdXRTj7FV8IfuvzX39N6DqZwrOpriovYXi\nIv0ynn/b8vnA0hz6+lDFdZZ9mOL7tA04D7iij34vA/6K4q/4bcB7KG6nBrgJWA9skfTYi9j2Fopj\n+SvgKuCTeUYKxQ0Iz1IUh6XZXnY+fex3RDxLUSSmU5zpXQ7MKq3bWoCKYWezXUPSjyku0H6n2bk0\nk6RLgIMiou5dTmbDhc80zHaBHOZ7cw6JHU0xTPO9Zudl1ih/Itxs13gVxZDUIRRDNX8HXNfUjMyG\ngIenzMysMg9PmZlZZS+54amxY8dGR0dHs9MwMxtWbr/99sciom2gfi+5otHR0UFnZ2ez0zAzG1Yk\n1f2vArU8PGVmZpW5aJiZWWUuGmZmVpmLhpmZVeaiYWZmlblomJlZZS4aZmZWmYuGmZlV5qJhZmaV\nveQ+Ed4KOuZd32/7wxefvJsyMTMbWj7TMDOzylw0zMysMhcNMzOrzEXDzMwqc9EwM7PKXDTMzKwy\nFw0zM6tswKIhabGkrZLuqYl/WtL9ktZL+ptS/FxJXZIekHRiKT4tY12S5pXiEyWty/jVkkZlfK+c\n78r2jqHYYTMzG7wqZxpLgGnlgKT3AjOAt0TE4cDXMj4ZmAkcnstcLmmEpBHAZcB0YDJwRvYFuASY\nHxGHAduBORmfA2zP+PzsZ2ZmTTRg0YiIW4BtNeG/AC6OiGeyz9aMzwCWR8QzEfEQ0AUcna+uiNgQ\nEc8Cy4EZkgQcB6zI5ZcCp5bWtTSnVwDHZ38zM2uSwV7TeD3wrhw2+ndJb8v4eGBjqV93xvqKHwjs\niIidNfHnrSvbn8j+ZmbWJIP931MjgQOAqcDbgGskvXbIsnqRJM0F5gIceuihzUrDzOwlb7BnGt3A\ntVG4Ffg9MBbYBEwo9WvPWF/xx4HRkkbWxCkvk+37Z/8XiIiFETElIqa0tbUNcpfMzGwggy0a3wfe\nCyDp9cAo4DFgJTAz73yaCEwCbgVuAyblnVKjKC6Wr4yIAG4GTsv1zgauy+mVOU+235T9zcysSQYc\nnpK0DDgWGCupGzgPWAwszttwnwVm5xv6eknXAPcCO4GzIuK5XM/ZwGpgBLA4ItbnJr4ALJd0IXAH\nsCjji4ArJXVRXIifOQT7a2ZmDRiwaETEGX00/d8++l8EXFQnvgpYVSe+geLuqtr4b4HTB8rPzMx2\nH38i3MzMKnPRMDOzylw0zMysMhcNMzOrzEXDzMwqc9EwM7PKXDTMzKwyFw0zM6vMRcPMzCpz0TAz\ns8pcNMzMrDIXDTMzq8xFw8zMKnPRMDOzylw0zMysMhcNMzOrbMCiIWmxpK35lL7atnMkhaSxOS9J\nl0rqknSXpKNKfWdLejBfs0vxt0q6O5e5VJIyfoCkNdl/jaQxQ7PLZmY2WFXONJYA02qDkiYAJwCP\nlMLTKZ4LPgmYCyzIvgdQPCb2GIqn9J1XKgILgE+Uluvd1jzgxoiYBNyY82Zm1kQDFo2IuIXiGd21\n5gOfB6IUmwFcEYW1wGhJBwMnAmsiYltEbAfWANOybb+IWJvPGL8COLW0rqU5vbQUNzOzJhnUNQ1J\nM4BNEfGzmqbxwMbSfHfG+ot314kDjIuIzTm9BRjXTz5zJXVK6uzp6Xmxu2NmZhW96KIhaR/gi8CX\nhz6d+vIsJPppXxgRUyJiSltb2+5Ky8xsjzOYM43XAROBn0l6GGgHfirpIGATMKHUtz1j/cXb68QB\nHs3hK/Lr1kHkamZmQ+hFF42IuDsiXh0RHRHRQTGkdFREbAFWArPyLqqpwBM5xLQaOEHSmLwAfgKw\nOtuelDQ175qaBVyXm1oJ9N5lNbsUNzOzJqlyy+0y4L+BN0jqljSnn+6rgA1AF/Bt4FMAEbENuAC4\nLV9fzRjZ5zu5zC+AGzJ+MfB+SQ8C78t5MzNropEDdYiIMwZo7yhNB3BWH/0WA4vrxDuBI+rEHweO\nHyg/MzPbffyJcDMzq8xFw8zMKnPRMDOzylw0zMysMhcNMzOrzEXDzMwqc9EwM7PKXDTMzKwyFw0z\nM6vMRcPMzCpz0TAzs8pcNMzMrDIXDTMzq8xFw8zMKnPRMDOzyqo8hGmxpK2S7inF/lbS/ZLukvQ9\nSaNLbedK6pL0gKQTS/FpGeuSNK8UnyhpXcavljQq43vlfFe2dwzVTpuZ2eBUOdNYAkyria0BjoiI\nNwM/B84FkDQZmAkcnstcLmmEpBHAZcB0YDJwRvYFuASYHxGHAduB3icDzgG2Z3x+9jMzsyYasGhE\nxC3AtprYjyJiZ86uBdpzegawPCKeiYiHKB7henS+uiJiQ0Q8CywHZuRzwY8DVuTyS4FTS+tamtMr\ngOOzv5mZNclQXNP4GH98rvd4YGOprTtjfcUPBHaUClBv/HnryvYnsv8LSJorqVNSZ09PT8M7ZGZm\n9TVUNCR9CdgJXDU06QxORCyMiCkRMaWtra2ZqZiZvaSNHOyCks4ETgGOj4jI8CZgQqlbe8boI/44\nMFrSyDybKPfvXVe3pJHA/tnfzMyaZFBnGpKmAZ8HPhART5eaVgIz886nicAk4FbgNmBS3ik1iuJi\n+cosNjcDp+Xys4HrSuuandOnATeVipOZmTXBgGcakpYBxwJjJXUD51HcLbUXsCavTa+NiE9GxHpJ\n1wD3UgxbnRURz+V6zgZWAyOAxRGxPjfxBWC5pAuBO4BFGV8EXCmpi+JC/Mwh2F8zM2vAgEUjIs6o\nE15UJ9bb/yLgojrxVcCqOvENFHdX1cZ/C5w+UH5mZrb7+BPhZmZWmYuGmZlV5qJhZmaVuWiYmVll\nLhpmZlaZi4aZmVXmomFmZpW5aJiZWWUuGmZmVpmLhpmZVeaiYWZmlblomJlZZS4aZmZWmYuGmZlV\n5qJhZmaVuWiYmVllAxYNSYslbZV0Tyl2gKQ1kh7Mr2MyLkmXSuqSdJeko0rLzM7+D0qaXYq/VdLd\nucylykcB9rUNMzNrnipnGkuAaTWxecCNETEJuDHnAaZTPBd8EjAXWABFAaB4TOwxFE/pO69UBBYA\nnygtN22AbZiZWZMMWDQi4haKZ3SXzQCW5vRS4NRS/IoorAVGSzoYOBFYExHbImI7sAaYlm37RcTa\niAjgipp11duGmZk1yWCvaYyLiM05vQUYl9PjgY2lft0Z6y/eXSfe3zZeQNJcSZ2SOnt6egaxO2Zm\nVkXDF8LzDCGGIJdBbyMiFkbElIiY0tbWtitTMTPbow22aDyaQ0vk160Z3wRMKPVrz1h/8fY68f62\nYWZmTTLYorES6L0DajZwXSk+K++imgo8kUNMq4ETJI3JC+AnAKuz7UlJU/OuqVk166q3DTMza5KR\nA3WQtAw4FhgrqZviLqiLgWskzQF+CXwou68CTgK6gKeBjwJExDZJFwC3Zb+vRkTvxfVPUdyhtTdw\nQ77oZxtmZtYkAxaNiDijj6bj6/QN4Kw+1rMYWFwn3gkcUSf+eL1tmJlZ8/gT4WZmVpmLhpmZVeai\nYWZmlblomJlZZS4aZmZWmYuGmZlVNuAttzb0OuZdP2Cfhy8+eTdkYmb24vhMw8zMKnPRMDOzylw0\nzMysMhcNMzOrzEXDzMwqc9EwM7PKXDTMzKwyFw0zM6usoaIh6S8lrZd0j6Rlkl4haaKkdZK6JF0t\naVT23Svnu7K9o7SeczP+gKQTS/FpGeuSNK+RXM3MrHGDLhqSxgOfAaZExBHACGAmcAkwPyIOA7YD\nc3KROcD2jM/PfkianMsdDkwDLpc0QtII4DJgOjAZOCP7mplZkzQ6PDUS2FvSSGAfYDNwHLAi25cC\np+b0jJwn24/P54LPAJZHxDMR8RDFo2KPzldXRGyIiGeB5dnXzMyaZNBFIyI2AV8DHqEoFk8AtwM7\nImJndusGxuf0eGBjLrsz+x9Yjtcs01f8BSTNldQpqbOnp2ewu2RmZgNoZHhqDMVf/hOBQ4B9KYaX\ndruIWBgRUyJiSltbWzNSMDPbIzQyPPU+4KGI6ImI3wHXAu8ARudwFUA7sCmnNwETALJ9f+Dxcrxm\nmb7iZmbWJI0UjUeAqZL2yWsTxwP3AjcDp2Wf2cB1Ob0y58n2myIiMj4z766aCEwCbgVuAybl3Vij\nKC6Wr2wgXzMza9Cgn6cREeskrQB+CuwE7gAWAtcDyyVdmLFFucgi4EpJXcA2iiJARKyXdA1FwdkJ\nnBURzwFIOhtYTXFn1uKIWD/YfM3MrHENPYQpIs4DzqsJb6C486m272+B0/tYz0XARXXiq4BVjeRo\nZmZDx58INzOzylw0zMysMhcNMzOrzEXDzMwqc9EwM7PKXDTMzKwyFw0zM6vMRcPMzCpz0TAzs8pc\nNMzMrDIXDTMzq8xFw8zMKnPRMDOzylw0zMysMhcNMzOrrKGiIWm0pBWS7pd0n6S3SzpA0hpJD+bX\nMdlXki6V1CXpLklHldYzO/s/KGl2Kf5WSXfnMpfmEwLNzKxJGj3T+Abww4h4I/AW4D5gHnBjREwC\nbsx5gOkUj3KdBMwFFgBIOoDiQU7HUDy86bzeQpN9PlFablqD+ZqZWQMGXTQk7Q+8m3yca0Q8GxE7\ngBnA0uy2FDg1p2cAV0RhLTBa0sHAicCaiNgWEduBNcC0bNsvItbms8SvKK3LzMyaoJHHvU4EeoDv\nSnoLcDvwWWBcRGzOPluAcTk9HthYWr47Y/3Fu+vEm6pj3vXNTsHMrGkaGZ4aCRwFLIiII4Gn+ONQ\nFAB5hhANbKMSSXMldUrq7Onp2dWbMzPbYzVSNLqB7ohYl/MrKIrIozm0RH7dmu2bgAml5dsz1l+8\nvU78BSJiYURMiYgpbW1tDeySmZn1Z9BFIyK2ABslvSFDxwP3AiuB3jugZgPX5fRKYFbeRTUVeCKH\nsVYDJ0gakxfATwBWZ9uTkqbmXVOzSusyM7MmaOSaBsCngaskjQI2AB+lKETXSJoD/BL4UPZdBZwE\ndAFPZ18iYpukC4Dbst9XI2JbTn8KWALsDdyQLzMza5KGikZE3AlMqdN0fJ2+AZzVx3oWA4vrxDuB\nIxrJ0czMho4/EW5mZpW5aJiZWWUuGmZmVpmLhpmZVeaiYWZmlblomJlZZS4aZmZWmYuGmZlV5qJh\nZmaVuWiYmVllLhpmZlaZi4aZmVXmomFmZpW5aJiZWWUuGmZmVpmLhpmZVdZw0ZA0QtIdkn6Q8xMl\nrZPUJenqfKofkvbK+a5s7yit49yMPyDpxFJ8Wsa6JM1rNFczM2vMUJxpfBa4rzR/CTA/Ig4DtgNz\nMj4H2J7x+dkPSZOBmcDhwDTg8ixEI4DLgOnAZOCM7GtmZk3S0ONeJbUDJwMXAX8lScBxwIezy1Lg\nfGABMCOnAVYA38z+M4DlEfEM8JCkLuDo7NcVERtyW8uz772N5DxcdMy7fsA+D1988m7IxMzsjxo9\n0/g68Hng9zl/ILAjInbmfDcwPqfHAxsBsv2J7P+HeM0yfcVfQNJcSZ2SOnt6ehrcJTMz68ugi4ak\nU4CtEXH7EOYzKBGxMCKmRMSUtra2ZqdjZvaS1cjw1DuAD0g6CXgFsB/wDWC0pJF5NtEObMr+m4AJ\nQLekkcD+wOOleK/yMn3FzcysCQZ9phER50ZEe0R0UFzIvikiPgLcDJyW3WYD1+X0ypwn22+KiMj4\nzLy7aiIwCbgVuA2YlHdjjcptrBxsvmZm1riGLoT34QvAckkXAncAizK+CLgyL3RvoygCRMR6SddQ\nXODeCZwVEc8BSDobWA2MABZHxPpdkK+ZmVU0JEUjIn4M/DinN/DHu5/KfX4LnN7H8hdR3IFVG18F\nrBqKHM3MrHH+RLiZmVXmomFmZpW5aJiZWWUuGmZmVpmLhpmZVeaiYWZmlblomJlZZS4aZmZWmYuG\nmZlV5qJhZmaVuWiYmVllLhpmZlaZi4aZmVXmomFmZpW5aJiZWWWNPCN8gqSbJd0rab2kz2b8AElr\nJD2YX8dkXJIuldQl6S5JR5XWNTv7Pyhpdin+Vkl35zKXSlIjO2tmZo1p5ExjJ3BOREwGpgJnSZoM\nzANujIhJwI05DzCd4lGuk4C5wAIoigxwHnAMxcObzustNNnnE6XlpjWQr5mZNaiRZ4Rvjoif5vSv\ngfuA8cAMYGl2WwqcmtMzgCuisBYYLelg4ERgTURsi4jtwBpgWrbtFxFr81niV5TWZWZmTTAk1zQk\ndQBHAuuAcRGxOZu2AONyejywsbRYd8b6i3fXidfb/lxJnZI6e3p6GtoXMzPrW8PPCJf0SuBfgM9F\nxJPlyw4REZKi0W0MJCIWAgsBpkyZssu31yo65l3fb/vDF5+8mzIxsz1FQ2cakl5OUTCuiohrM/xo\nDi2RX7dmfBMwobR4e8b6i7fXiZuZWZM0cveUgEXAfRHx96WmlUDvHVCzgetK8Vl5F9VU4IkcxloN\nnCBpTF4APwFYnW1PSpqa25pVWpeZmTVBI8NT7wD+DLhb0p0Z+yJwMXCNpDnAL4EPZdsq4CSgC3ga\n+ChARGyTdAFwW/b7akRsy+lPAUuAvYEb8mVmZk0y6KIRET8B+vrcxPF1+gdwVh/rWgwsrhPvBI4Y\nbI5mZja0/IlwMzOrzEXDzMwqc9EwM7PKXDTMzKwyFw0zM6us4U+EW+sa6BPj4E+Nm9mL4zMNMzOr\nzEXDzMwqc9EwM7PKXDTMzKwyFw0zM6vMd0/t4XyHlZm9GD7TMDOzylw0zMysMhcNMzOrzNc0bEB+\nFrmZ9Wr5Mw1J0yQ9IKlL0rxm52Nmtidr6TMNSSOAy4D3A93AbZJWRsS9zc3MynwHltmeo6WLBnA0\n0BURGwAkLQdmAC4aw0yVwlKFi49Zc7V60RgPbCzNdwPH1HaSNBeYm7O/kfTAILc3FnhskMs2w3DK\nd0hy1SVDkEk1e9yx3Y2GU77DKVdoLN/XVOnU6kWjkohYCCxsdD2SOiNiyhCktFsMp3yHU64wvPId\nTrnC8Mp3OOUKuyffVr8QvgmYUJpvz5iZmTVBqxeN24BJkiZKGgXMBFY2OSczsz1WSw9PRcROSWcD\nq4ERwOKIWL8LN9nwENduNpzyHU65wvDKdzjlCsMr3+GUK+yGfBURu3obZmb2EtHqw1NmZtZCXDTM\nzKwyF43Uyv+uRNIESTdLulfSekmfzfgBktZIejC/jml2rr0kjZB0h6Qf5PxESevy+F6dNza0BEmj\nJa2QdL+k+yS9vVWPraS/zJ+BeyQtk/SKVjq2khZL2irpnlKs7rFU4dLM+y5JR7VIvn+bPwt3Sfqe\npNGltnMz3wckndjsXEtt50gKSWNzfpcdWxcNnvfvSqYDk4EzJE1ublbPsxM4JyImA1OBszK/ecCN\nETEJuDHnW8VngftK85cA8yPiMGA7MKcpWdX3DeCHEfFG4C0UebfcsZU0HvgMMCUijqC4OWQmrXVs\nlwDTamJ9HcvpwKR8zQUW7KYcy5bwwnzXAEdExJuBnwPnAuTv3Ezg8Fzm8nzv2F2W8MJckTQBOAF4\npBTeZcfWRaPwh39XEhHPAr3/rqQlRMTmiPhpTv+a4k1tPEWOS7PbUuDU5mT4fJLagZOB7+S8gOOA\nFdmllXLdH3g3sAggIp6NiB206LGluONxb0kjgX2AzbTQsY2IW4BtNeG+juUM4IoorAVGSzp492Ra\nqJdvRPwoInbm7FqKz4dBke/yiHgmIh4CuijeO5qWa5oPfB4o39W0y46ti0ah3r8rGd+kXPolqQM4\nElgHjIuIzdm0BRjXpLRqfZ3ih/j3OX8gsKP0i9hKx3ci0AN8N4fTviNpX1rw2EbEJuBrFH9Rbgae\nAG6ndY9tr76O5XD4vfsYcENOt1y+kmYAmyLiZzVNuyxXF41hRNIrgX8BPhcRT5bborh3uun3T0s6\nBdgaEbc3O5eKRgJHAQsi4kjgKWqGolro2I6h+AtyInAIsC91hitaWascyyokfYliaPiqZudSj6R9\ngC8CX96d23XRKLT8vyuR9HKKgnFVRFyb4Ud7Tznz69Zm5VfyDuADkh6mGOY7juKawegcUoHWOr7d\nQHdErMv5FRRFpBWP7fuAhyKiJyJ+B1xLcbxb9dj26utYtuzvnaQzgVOAj8QfP8zWavm+juIPiJ/l\n71s78FNJB7ELc3XRKLT0vyvJawKLgPsi4u9LTSuB2Tk9G7hud+dWKyLOjYj2iOigOI43RcRHgJuB\n07JbS+QKEBFbgI2S3pCh4yn+9X7LHVuKYampkvbJn4neXFvy2Jb0dSxXArPyTp+pwBOlYaymkTSN\nYnj1AxHxdKlpJTBT0l6SJlJcZL61GTkCRMTdEfHqiOjI37du4Kj8md51xzYi/Cr+kDiJ4k6JXwBf\nanY+Nbm9k+KU/i7gznydRHGt4EbgQeDfgAOanWtN3scCP8jp11L8gnUB/wzs1ez8Snn+CdCZx/f7\nwJhWPbbAV4D7gXuAK4G9WunYAssorrf8Lt/E5vR1LAFR3LX4C+BuirvCWiHfLorrAb2/a98q9f9S\n5vsAML3Zuda0PwyM3dXH1v9GxMzMKvPwlJmZVeaiYWZmlblomJlZZS4aZmZWmYuGmZlV5qJhZmaV\nuWiYmVll/x/L+2mYiJmvigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8023db9860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 404290\n",
      "Longest sequence length: 271\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEICAYAAACj2qi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8023c59c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Turns iteratable of symbols into padded batch\n",
    "from functools import lru_cache\n",
    "\n",
    "class Batcher:\n",
    "    def __init__(self, sequences, verbose = False):\n",
    "        self.seqs = sequences\n",
    "        self.verbose = verbose\n",
    "        self.size = len(self.seqs)\n",
    "        self.seq_lens = [len(seq) for seq in self.seqs]\n",
    "        \n",
    "        if self.verbose:\n",
    "            self.describe()\n",
    "    \n",
    "    @lru_cache(maxsize=None)\n",
    "    def max_length(self):\n",
    "        return max(self.seq_lens)\n",
    "    \n",
    "    @lru_cache(maxsize=None)\n",
    "    def longgest_sequence(self):\n",
    "        for seq in self.seqs:\n",
    "            if len(seq) == self.max_length():\n",
    "                return seq\n",
    "    \n",
    "    def describe(self):\n",
    "        print('Size: {}'.format(self.size))\n",
    "        print(\"Longest sequence length: {}\".format(self.max_length()))\n",
    "        bin_width = max(1, self.max_length() // 30)\n",
    "        plt.hist(self.seq_lens, range(0, self.max_length() + bin_width, bin_width))\n",
    "        plt.title('Sequence length distribution')\n",
    "        plt.show()\n",
    "        \n",
    "    def batchPadding(self, batch, padding_symbol):\n",
    "        size = max([len(record) for record in batch])\n",
    "        result = np.full((len(batch), size), padding_symbol)\n",
    "        for i in range(len(batch)):\n",
    "            result[i][:len(batch[i])] = batch[i]\n",
    "        return result\n",
    "\n",
    "    def batchMask(self, batch):\n",
    "        size = max([len(record) for record in batch])\n",
    "        result = np.full((len(batch), size), 0.0)\n",
    "        for i in range(len(batch)):\n",
    "            result[i][:len(batch[i])] = 1.0\n",
    "        return result\n",
    "        \n",
    "    # Same length within the batch, stuffed with padding symbol\n",
    "    def generator(self, padding_symbol, batch_size=32, epouch=-1):\n",
    "        train = []\n",
    "        length = []\n",
    "        while(epouch < 0 or epouch > 0):\n",
    "            for seq in self.seqs:\n",
    "                train.append([sym for sym in seq])\n",
    "                length.append(len(seq))\n",
    "                if(len(train) == batch_size):\n",
    "                    yield self.batchPadding(train, padding_symbol), length, self.batchMask(train)\n",
    "                    train = []\n",
    "                    length = []\n",
    "            epouch -= 1\n",
    "            if self.verbose:\n",
    "                print('epouch done...')\n",
    "                \n",
    "                \n",
    "\n",
    "class Batcher2:\n",
    "    def __init__(self, sequences, verbose = False):\n",
    "        self.seqs = sequences             \n",
    "\n",
    "    def generator(self, batch_size=32, epouch=-1):\n",
    "        train = []\n",
    "        while(epouch < 0 or epouch > 0):\n",
    "            for sym in self.seqs:\n",
    "                train.append([sym])\n",
    "                if(len(train) == batch_size):\n",
    "                    yield train\n",
    "                    train = []\n",
    "            epouch -= 1\n",
    "            print('epouch done...')\n",
    "    \n",
    "q1_batcher = Batcher(q1, verbose=True)\n",
    "q2_batcher = Batcher(q2, verbose=True)\n",
    "labels_batcher = Batcher2(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING = glove_emb.getNumpyArray()\n",
    "\n",
    "LV1_DIM = 10\n",
    "LV2_STEP = 1\n",
    "LV2_DIM = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#IN (batch, time, dim)\n",
    "def simple_dynamic_rnn(cell, inputs, lengths, scope):\n",
    "     with tf.variable_scope(scope):\n",
    "        outputs, states = tf.nn.dynamic_rnn(\n",
    "            cell, \n",
    "            inputs, \n",
    "            initial_state = cell.zero_state(tf.shape(inputs)[0], dtype=tf.float32),\n",
    "            dtype = tf.float32, \n",
    "            sequence_length = lengths\n",
    "        )\n",
    "        \n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        step_size = tf.shape(inputs)[1]\n",
    "        indices = tf.range(0, batch_size) * step_size + (lengths - 1)\n",
    "        gather = tf.reshape(tf.gather(tf.reshape(outputs, [-1, cell.output_size]), indices), [-1, cell.output_size])\n",
    "        return gather\n",
    "#OUT (batch, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Final_Prediction/concat:0\", shape=(?, 400), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoiy927/project/tf_playground/tf_playground/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    with tf.variable_scope(\"Inputs\"):\n",
    "    \n",
    "        #IN\n",
    "        inputs = [tf.placeholder(tf.int32, (None, None), name = \"Q{}_Word_Indices\".format(i+1)) for i in range(2)]\n",
    "        #OUT: (batch, time) int32\n",
    "        \n",
    "        batch_size = [tf.shape(inputs[i], name= \"Q{}_Batch_Size\".format(i+1))[0] for i in range(2)]\n",
    "        steps = [tf.shape(inputs[i], name= \"Q{}_Steps\".format(i+1))[1] for i in range(2)]\n",
    "        \n",
    "        #IN\n",
    "        input_lengths = [tf.placeholder(tf.int32, (None), name = \"Q{}_Lengths\".format(i+1)) for i in range(2)]\n",
    "        #OUT: (batch) int32\n",
    "        \n",
    "        truth = tf.placeholder(tf.float32, (None, 1), name = \"labels\")\n",
    "        \n",
    "    with tf.variable_scope(\"Embedding\"):\n",
    "        \n",
    "        embeddings = tf.get_variable(\"embeddings\", shape=EMBEDDING.shape, initializer=tf.constant_initializer(EMBEDDING), trainable=False)\n",
    "        encoder_inputs = [tf.nn.embedding_lookup(embeddings, inputs[i]) for i in range(2)] \n",
    "        #OUT: (batch, time, dim) float32\n",
    "        \n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"Level_1_RNN\"):\n",
    "        \n",
    "        rnn_output_1 = [[simple_dynamic_rnn(\n",
    "                    cell = tf.contrib.rnn.GRUCell(\n",
    "                        LV1_DIM, \n",
    "                        reuse = True if i == 1 else None\n",
    "                    ),\n",
    "                    inputs = encoder_inputs[i],\n",
    "                    lengths = input_lengths[i],\n",
    "                    scope = '{}'.format(step)\n",
    "                ) for step in range(LV2_STEP)] for i in range(2)]\n",
    "        # OUT: rnn_output[LV2_STEP][LV1_DIM]\n",
    "        # (time, batch, dim) float32\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.variable_scope(\"Level_2_RNN\"):\n",
    "        \n",
    "        #rnn_input_2 = [tf.transpose(rnn_output_1[i], [1, 0, 2]) for i in range(2)]\n",
    "        # (batch, time, dim)\n",
    "        \n",
    "        rnn_output_2 = [simple_dynamic_rnn(\n",
    "                    cell = tf.contrib.rnn.LSTMCell(\n",
    "                        LV2_DIM,\n",
    "                        reuse = True if i == 1 else None\n",
    "                    ),\n",
    "                    #inputs = rnn_input_2[i],\n",
    "                    #lengths = tf.fill(tf.shape(input_lengths[i]), LV2_STEP),\n",
    "                    inputs = encoder_inputs[i],\n",
    "                    lengths = input_lengths[i],\n",
    "                    scope = 'L2',\n",
    "                ) for i in range(2)]\n",
    "        # OUT: [2](batch, LV2_DIM)\n",
    "\n",
    "\n",
    "    with tf.variable_scope(\"Final_Prediction\"):\n",
    "        final_input = tf.concat([rnn_output_2[0], rnn_output_2[1]], 1)\n",
    "        \n",
    "        print(final_input)\n",
    "        \n",
    "        predict = tf.layers.dense(\n",
    "            inputs=final_input,\n",
    "            units=1,\n",
    "            activation=tf.nn.sigmoid,\n",
    "            use_bias=True,\n",
    "            kernel_initializer=None,\n",
    "            bias_initializer=tf.zeros_initializer(),\n",
    "            kernel_regularizer=None,\n",
    "            bias_regularizer=None,\n",
    "            activity_regularizer=None,\n",
    "            trainable=True,\n",
    "            name=None,\n",
    "            reuse=None\n",
    "        );\n",
    "        \n",
    "    loss = tf.reduce_mean(tf.contrib.keras.losses.binary_crossentropy(truth, predict))\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "    saver = tf.train.Saver()\n",
    "    tvars = tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#show_graph(graph.as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_steps = 2000000\n",
    "MODEL = './model/q.ckpt'\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "q1_gen = q1_batcher.generator(glove_emb.getIndex('<PAD>'), batch_size=BATCH_SIZE)\n",
    "q2_gen = q2_batcher.generator(glove_emb.getIndex('<PAD>'), batch_size=BATCH_SIZE)\n",
    "labels_gen = labels_batcher.generator(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/q.ckpt\n",
      "Restored training...\n",
      "Model saved in file: ./model/q.ckpt\n",
      "Total time for 100 steps: 743.06s, each step: 7.43s\n",
      "Average mean loss at step  100 :  0.669999719262\n",
      "Model saved in file: ./model/q.ckpt\n"
     ]
    }
   ],
   "source": [
    "DEBUG_SIZE = 100\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    try:\n",
    "        saver.restore(session, MODEL)\n",
    "        print('Restored training...')\n",
    "    except:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        print('Restarting training...')\n",
    "    \n",
    "    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "    run_metadata = tf.RunMetadata()\n",
    "    \n",
    "\n",
    "    \n",
    "    #tvars_vals = session.run(tvars)\n",
    "    #for var, val in zip(tvars, tvars_vals):\n",
    "    #    print(var.name, val)  # Prints the name of the variable alongside its value.\n",
    "\n",
    "    for name in session.run( tf.report_uninitialized_variables( tf.global_variables( ) ) ):\n",
    "        print(name)\n",
    "    \n",
    "    \n",
    "    average_loss = 0\n",
    "    average_max_loss = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        \n",
    "        train_q1, train_q1_lengths, _ = next(q1_gen)\n",
    "        train_q2, train_q2_lengths, _ = next(q2_gen)\n",
    "        train_labels = next(labels_gen)\n",
    "        \n",
    "        feed_dict = {\n",
    "            inputs[0]: train_q1,\n",
    "            inputs[1]: train_q2,\n",
    "            input_lengths[0]: train_q1_lengths,\n",
    "            input_lengths[1]: train_q2_lengths,\n",
    "            truth: train_labels\n",
    "        }\n",
    "        \n",
    "        #_, loss_val = session.run([optimizer, loss], feed_dict=feed_dict, options=run_options, run_metadata=run_metadata)\n",
    "        _, loss_val = session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "        average_loss += loss_val\n",
    "        \n",
    "        if step % DEBUG_SIZE == 0:\n",
    "            if step > 0:\n",
    "                average_loss /= DEBUG_SIZE\n",
    "                print('Total time for {0} steps: {1:.2f}s, each step: {2:.2f}s'.format(DEBUG_SIZE, time.time()-start, (time.time()-start) / DEBUG_SIZE))\n",
    "                print('Average mean loss at step ', step, ': ', average_loss)\n",
    "                average_loss = 0\n",
    "                start = time.time()\n",
    "                \n",
    "        if step % DEBUG_SIZE == 0:\n",
    "            save_path = saver.save(session, MODEL)\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "            \n",
    "            # Create the Timeline object, and write it to a json\n",
    "            tl = timeline.Timeline(run_metadata.step_stats)\n",
    "            ctf = tl.generate_chrome_trace_format()\n",
    "            with open('timeline.json', 'w') as f:\n",
    "                f.write(ctf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
