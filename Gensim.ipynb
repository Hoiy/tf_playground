{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-14 16:46:54,522 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from Utils.FS import file\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_FILES = 10\n",
    "VEC_SIZE = 30\n",
    "\n",
    "files = file.ls('./data/Gutenberg')\n",
    "corpus = ''\n",
    "for f in files[0:NUM_FILES]:\n",
    "    corpus += file.read(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Gutenberg2Sentences(corpus):\n",
    "    sent_tokenizer = PunktSentenceTokenizer()\n",
    "    sentences = sent_tokenizer.tokenize(corpus)\n",
    "    return [[word.lower() for word in word_tokenize(sentence)] for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = Gutenberg2Sentences(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-14 16:46:57,864 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2017-04-14 16:46:57,866 : INFO : collecting all words and their counts\n",
      "2017-04-14 16:46:57,868 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-14 16:46:57,918 : INFO : PROGRESS: at sentence #10000, processed 283857 words, keeping 12945 word types\n",
      "2017-04-14 16:46:57,920 : INFO : collected 13039 word types from a corpus of 290705 raw words and 10287 sentences\n",
      "2017-04-14 16:46:57,921 : INFO : Loading a fresh vocabulary\n",
      "2017-04-14 16:46:57,946 : INFO : min_count=5 retains 4312 unique words (33% of original 13039, drops 8727)\n",
      "2017-04-14 16:46:57,949 : INFO : min_count=5 leaves 275408 word corpus (94% of original 290705, drops 15297)\n",
      "2017-04-14 16:46:57,967 : INFO : deleting the raw counts dictionary of 13039 items\n",
      "2017-04-14 16:46:57,972 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2017-04-14 16:46:57,974 : INFO : downsampling leaves estimated 181946 word corpus (66.1% of prior 275408)\n",
      "2017-04-14 16:46:57,977 : INFO : estimated required memory for 4312 words and 30 dimensions: 3190880 bytes\n",
      "2017-04-14 16:46:58,000 : INFO : resetting layer weights\n",
      "2017-04-14 16:46:58,082 : INFO : training model with 3 workers on 4312 vocabulary and 30 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-04-14 16:46:58,679 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-14 16:46:58,683 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-14 16:46:58,684 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-14 16:46:58,685 : INFO : training on 1453525 raw words (910349 effective words) took 0.6s, 1527963 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(sentences, size=VEC_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-14 16:46:58,691 : INFO : saving Word2Vec object under ./model/test.bin, separately None\n",
      "2017-04-14 16:46:58,693 : INFO : not storing attribute syn0norm\n",
      "2017-04-14 16:46:58,694 : INFO : not storing attribute cum_table\n",
      "2017-04-14 16:46:58,731 : INFO : saved ./model/test.bin\n"
     ]
    }
   ],
   "source": [
    "model.save('./model/test.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-14 16:46:58,741 : INFO : loading Word2Vec object from ./model/test.bin\n",
      "2017-04-14 16:46:58,831 : INFO : loading wv recursively from ./model/test.bin.wv.* with mmap=None\n",
      "2017-04-14 16:46:58,831 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-04-14 16:46:58,832 : INFO : setting ignored attribute cum_table to None\n",
      "2017-04-14 16:46:58,833 : INFO : loaded ./model/test.bin\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec.load('./model/test.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4312, 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
