{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Hoiy/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-d926899d2741>:165 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Iter 1280, Minibatch Loss= 0.708975, Training Accuracy= 0.49219\n",
      "Iter 2560, Minibatch Loss= 0.682905, Training Accuracy= 0.56250\n",
      "Iter 3840, Minibatch Loss= 0.676106, Training Accuracy= 0.60156\n",
      "Iter 5120, Minibatch Loss= 0.689394, Training Accuracy= 0.53846\n",
      "Iter 6400, Minibatch Loss= 0.694409, Training Accuracy= 0.46094\n",
      "Iter 7680, Minibatch Loss= 0.678456, Training Accuracy= 0.57812\n",
      "Iter 8960, Minibatch Loss= 0.670560, Training Accuracy= 0.67188\n",
      "Iter 10240, Minibatch Loss= 0.680937, Training Accuracy= 0.52885\n",
      "Iter 11520, Minibatch Loss= 0.687873, Training Accuracy= 0.51562\n",
      "Iter 12800, Minibatch Loss= 0.676031, Training Accuracy= 0.60156\n",
      "Iter 14080, Minibatch Loss= 0.665972, Training Accuracy= 0.71094\n",
      "Iter 15360, Minibatch Loss= 0.675313, Training Accuracy= 0.57692\n",
      "Iter 16640, Minibatch Loss= 0.683037, Training Accuracy= 0.56250\n",
      "Iter 17920, Minibatch Loss= 0.673811, Training Accuracy= 0.65625\n",
      "Iter 19200, Minibatch Loss= 0.661244, Training Accuracy= 0.73438\n",
      "Iter 20480, Minibatch Loss= 0.670486, Training Accuracy= 0.60577\n",
      "Iter 21760, Minibatch Loss= 0.678592, Training Accuracy= 0.58594\n",
      "Iter 23040, Minibatch Loss= 0.671163, Training Accuracy= 0.67188\n",
      "Iter 24320, Minibatch Loss= 0.655962, Training Accuracy= 0.73438\n",
      "Iter 25600, Minibatch Loss= 0.665594, Training Accuracy= 0.72115\n",
      "Iter 26880, Minibatch Loss= 0.673921, Training Accuracy= 0.60938\n",
      "Iter 28160, Minibatch Loss= 0.667790, Training Accuracy= 0.67188\n",
      "Iter 29440, Minibatch Loss= 0.649824, Training Accuracy= 0.76562\n",
      "Iter 30720, Minibatch Loss= 0.660088, Training Accuracy= 0.72115\n",
      "Iter 32000, Minibatch Loss= 0.668626, Training Accuracy= 0.62500\n",
      "Iter 33280, Minibatch Loss= 0.663500, Training Accuracy= 0.67188\n",
      "Iter 34560, Minibatch Loss= 0.642509, Training Accuracy= 0.76562\n",
      "Iter 35840, Minibatch Loss= 0.653447, Training Accuracy= 0.75000\n",
      "Iter 37120, Minibatch Loss= 0.662376, Training Accuracy= 0.64062\n",
      "Iter 38400, Minibatch Loss= 0.658113, Training Accuracy= 0.67969\n",
      "Iter 39680, Minibatch Loss= 0.633644, Training Accuracy= 0.76562\n",
      "Iter 40960, Minibatch Loss= 0.645052, Training Accuracy= 0.75962\n",
      "Iter 42240, Minibatch Loss= 0.654853, Training Accuracy= 0.64844\n",
      "Iter 43520, Minibatch Loss= 0.651420, Training Accuracy= 0.67188\n",
      "Iter 44800, Minibatch Loss= 0.622796, Training Accuracy= 0.76562\n",
      "Iter 46080, Minibatch Loss= 0.634141, Training Accuracy= 0.75000\n",
      "Iter 47360, Minibatch Loss= 0.645751, Training Accuracy= 0.64062\n",
      "Iter 48640, Minibatch Loss= 0.643155, Training Accuracy= 0.67188\n",
      "Iter 49920, Minibatch Loss= 0.609519, Training Accuracy= 0.78125\n",
      "Iter 51200, Minibatch Loss= 0.619900, Training Accuracy= 0.74038\n",
      "Iter 52480, Minibatch Loss= 0.634857, Training Accuracy= 0.64062\n",
      "Iter 53760, Minibatch Loss= 0.633040, Training Accuracy= 0.67188\n",
      "Iter 55040, Minibatch Loss= 0.593430, Training Accuracy= 0.78125\n",
      "Iter 56320, Minibatch Loss= 0.601726, Training Accuracy= 0.73077\n",
      "Iter 57600, Minibatch Loss= 0.622192, Training Accuracy= 0.63281\n",
      "Iter 58880, Minibatch Loss= 0.620936, Training Accuracy= 0.67188\n",
      "Iter 60160, Minibatch Loss= 0.574370, Training Accuracy= 0.80469\n",
      "Iter 61440, Minibatch Loss= 0.579690, Training Accuracy= 0.75000\n",
      "Iter 62720, Minibatch Loss= 0.608173, Training Accuracy= 0.66406\n",
      "Iter 64000, Minibatch Loss= 0.607022, Training Accuracy= 0.70312\n",
      "Iter 65280, Minibatch Loss= 0.552624, Training Accuracy= 0.81250\n",
      "Iter 66560, Minibatch Loss= 0.554972, Training Accuracy= 0.75000\n",
      "Iter 67840, Minibatch Loss= 0.593678, Training Accuracy= 0.66406\n",
      "Iter 69120, Minibatch Loss= 0.591921, Training Accuracy= 0.71094\n",
      "Iter 70400, Minibatch Loss= 0.529152, Training Accuracy= 0.82812\n",
      "Iter 71680, Minibatch Loss= 0.530021, Training Accuracy= 0.76923\n",
      "Iter 72960, Minibatch Loss= 0.579957, Training Accuracy= 0.67188\n",
      "Iter 74240, Minibatch Loss= 0.576906, Training Accuracy= 0.71875\n",
      "Iter 75520, Minibatch Loss= 0.505800, Training Accuracy= 0.85938\n",
      "Iter 76800, Minibatch Loss= 0.508218, Training Accuracy= 0.78846\n",
      "Iter 78080, Minibatch Loss= 0.568429, Training Accuracy= 0.70312\n",
      "Iter 79360, Minibatch Loss= 0.563939, Training Accuracy= 0.75000\n",
      "Iter 80640, Minibatch Loss= 0.485073, Training Accuracy= 0.85938\n",
      "Iter 81920, Minibatch Loss= 0.492134, Training Accuracy= 0.78846\n",
      "Iter 83200, Minibatch Loss= 0.560049, Training Accuracy= 0.70312\n",
      "Iter 84480, Minibatch Loss= 0.554476, Training Accuracy= 0.75781\n",
      "Iter 85760, Minibatch Loss= 0.468672, Training Accuracy= 0.85938\n",
      "Iter 87040, Minibatch Loss= 0.481825, Training Accuracy= 0.78846\n",
      "Iter 88320, Minibatch Loss= 0.554585, Training Accuracy= 0.71875\n",
      "Iter 89600, Minibatch Loss= 0.548359, Training Accuracy= 0.75781\n",
      "Iter 90880, Minibatch Loss= 0.456557, Training Accuracy= 0.85938\n",
      "Iter 92160, Minibatch Loss= 0.475636, Training Accuracy= 0.78846\n",
      "Iter 93440, Minibatch Loss= 0.551019, Training Accuracy= 0.71094\n",
      "Iter 94720, Minibatch Loss= 0.544481, Training Accuracy= 0.75781\n",
      "Iter 96000, Minibatch Loss= 0.447698, Training Accuracy= 0.85938\n",
      "Iter 97280, Minibatch Loss= 0.471865, Training Accuracy= 0.78846\n",
      "Iter 98560, Minibatch Loss= 0.548398, Training Accuracy= 0.71094\n",
      "Iter 99840, Minibatch Loss= 0.541808, Training Accuracy= 0.75781\n",
      "Iter 101120, Minibatch Loss= 0.441024, Training Accuracy= 0.85938\n",
      "Iter 102400, Minibatch Loss= 0.469415, Training Accuracy= 0.78846\n",
      "Iter 103680, Minibatch Loss= 0.546157, Training Accuracy= 0.72656\n",
      "Iter 104960, Minibatch Loss= 0.539712, Training Accuracy= 0.76562\n",
      "Iter 106240, Minibatch Loss= 0.435764, Training Accuracy= 0.84375\n",
      "Iter 107520, Minibatch Loss= 0.467699, Training Accuracy= 0.78846\n",
      "Iter 108800, Minibatch Loss= 0.544038, Training Accuracy= 0.72656\n",
      "Iter 110080, Minibatch Loss= 0.537882, Training Accuracy= 0.76562\n",
      "Iter 111360, Minibatch Loss= 0.431428, Training Accuracy= 0.84375\n",
      "Iter 112640, Minibatch Loss= 0.466411, Training Accuracy= 0.78846\n",
      "Iter 113920, Minibatch Loss= 0.541961, Training Accuracy= 0.72656\n",
      "Iter 115200, Minibatch Loss= 0.536178, Training Accuracy= 0.76562\n",
      "Iter 116480, Minibatch Loss= 0.427715, Training Accuracy= 0.84375\n",
      "Iter 117760, Minibatch Loss= 0.465381, Training Accuracy= 0.78846\n",
      "Iter 119040, Minibatch Loss= 0.539918, Training Accuracy= 0.72656\n",
      "Iter 120320, Minibatch Loss= 0.534541, Training Accuracy= 0.76562\n",
      "Iter 121600, Minibatch Loss= 0.424438, Training Accuracy= 0.84375\n",
      "Iter 122880, Minibatch Loss= 0.464508, Training Accuracy= 0.78846\n",
      "Iter 124160, Minibatch Loss= 0.537925, Training Accuracy= 0.72656\n",
      "Iter 125440, Minibatch Loss= 0.532948, Training Accuracy= 0.76562\n",
      "Iter 126720, Minibatch Loss= 0.421478, Training Accuracy= 0.84375\n",
      "Iter 128000, Minibatch Loss= 0.463731, Training Accuracy= 0.78846\n",
      "Iter 129280, Minibatch Loss= 0.535997, Training Accuracy= 0.72656\n",
      "Iter 130560, Minibatch Loss= 0.531388, Training Accuracy= 0.76562\n",
      "Iter 131840, Minibatch Loss= 0.418760, Training Accuracy= 0.84375\n",
      "Iter 133120, Minibatch Loss= 0.463010, Training Accuracy= 0.78846\n",
      "Iter 134400, Minibatch Loss= 0.534144, Training Accuracy= 0.73438\n",
      "Iter 135680, Minibatch Loss= 0.529855, Training Accuracy= 0.76562\n",
      "Iter 136960, Minibatch Loss= 0.416233, Training Accuracy= 0.85156\n",
      "Iter 138240, Minibatch Loss= 0.462323, Training Accuracy= 0.78846\n",
      "Iter 139520, Minibatch Loss= 0.532365, Training Accuracy= 0.73438\n",
      "Iter 140800, Minibatch Loss= 0.528346, Training Accuracy= 0.75781\n",
      "Iter 142080, Minibatch Loss= 0.413861, Training Accuracy= 0.85156\n",
      "Iter 143360, Minibatch Loss= 0.461655, Training Accuracy= 0.78846\n",
      "Iter 144640, Minibatch Loss= 0.530656, Training Accuracy= 0.73438\n",
      "Iter 145920, Minibatch Loss= 0.526857, Training Accuracy= 0.75781\n",
      "Iter 147200, Minibatch Loss= 0.411622, Training Accuracy= 0.85156\n",
      "Iter 148480, Minibatch Loss= 0.460999, Training Accuracy= 0.78846\n",
      "Iter 149760, Minibatch Loss= 0.529008, Training Accuracy= 0.73438\n",
      "Iter 151040, Minibatch Loss= 0.525385, Training Accuracy= 0.75781\n",
      "Iter 152320, Minibatch Loss= 0.409495, Training Accuracy= 0.85156\n",
      "Iter 153600, Minibatch Loss= 0.460349, Training Accuracy= 0.78846\n",
      "Iter 154880, Minibatch Loss= 0.527414, Training Accuracy= 0.73438\n",
      "Iter 156160, Minibatch Loss= 0.523928, Training Accuracy= 0.75781\n",
      "Iter 157440, Minibatch Loss= 0.407469, Training Accuracy= 0.85938\n",
      "Iter 158720, Minibatch Loss= 0.459701, Training Accuracy= 0.78846\n",
      "Iter 160000, Minibatch Loss= 0.525864, Training Accuracy= 0.73438\n",
      "Iter 161280, Minibatch Loss= 0.522483, Training Accuracy= 0.75781\n",
      "Iter 162560, Minibatch Loss= 0.405530, Training Accuracy= 0.85938\n",
      "Iter 163840, Minibatch Loss= 0.459054, Training Accuracy= 0.77885\n",
      "Iter 165120, Minibatch Loss= 0.524350, Training Accuracy= 0.74219\n",
      "Iter 166400, Minibatch Loss= 0.521048, Training Accuracy= 0.75781\n",
      "Iter 167680, Minibatch Loss= 0.403671, Training Accuracy= 0.85938\n",
      "Iter 168960, Minibatch Loss= 0.458404, Training Accuracy= 0.77885\n",
      "Iter 170240, Minibatch Loss= 0.522863, Training Accuracy= 0.74219\n",
      "Iter 171520, Minibatch Loss= 0.519621, Training Accuracy= 0.75781\n",
      "Iter 172800, Minibatch Loss= 0.401884, Training Accuracy= 0.85938\n",
      "Iter 174080, Minibatch Loss= 0.457748, Training Accuracy= 0.77885\n",
      "Iter 175360, Minibatch Loss= 0.521398, Training Accuracy= 0.74219\n",
      "Iter 176640, Minibatch Loss= 0.518200, Training Accuracy= 0.75781\n",
      "Iter 177920, Minibatch Loss= 0.400162, Training Accuracy= 0.85938\n",
      "Iter 179200, Minibatch Loss= 0.457085, Training Accuracy= 0.77885\n",
      "Iter 180480, Minibatch Loss= 0.519948, Training Accuracy= 0.74219\n",
      "Iter 181760, Minibatch Loss= 0.516785, Training Accuracy= 0.75781\n",
      "Iter 183040, Minibatch Loss= 0.398499, Training Accuracy= 0.85938\n",
      "Iter 184320, Minibatch Loss= 0.456411, Training Accuracy= 0.77885\n",
      "Iter 185600, Minibatch Loss= 0.518509, Training Accuracy= 0.74219\n",
      "Iter 186880, Minibatch Loss= 0.515372, Training Accuracy= 0.75781\n",
      "Iter 188160, Minibatch Loss= 0.396891, Training Accuracy= 0.85938\n",
      "Iter 189440, Minibatch Loss= 0.455723, Training Accuracy= 0.77885\n",
      "Iter 190720, Minibatch Loss= 0.517075, Training Accuracy= 0.74219\n",
      "Iter 192000, Minibatch Loss= 0.513961, Training Accuracy= 0.75781\n",
      "Iter 193280, Minibatch Loss= 0.395332, Training Accuracy= 0.85938\n",
      "Iter 194560, Minibatch Loss= 0.455019, Training Accuracy= 0.77885\n",
      "Iter 195840, Minibatch Loss= 0.515643, Training Accuracy= 0.74219\n",
      "Iter 197120, Minibatch Loss= 0.512549, Training Accuracy= 0.75781\n",
      "Iter 198400, Minibatch Loss= 0.393818, Training Accuracy= 0.85938\n",
      "Iter 199680, Minibatch Loss= 0.454297, Training Accuracy= 0.76923\n",
      "Iter 200960, Minibatch Loss= 0.514210, Training Accuracy= 0.74219\n",
      "Iter 202240, Minibatch Loss= 0.511135, Training Accuracy= 0.76562\n",
      "Iter 203520, Minibatch Loss= 0.392347, Training Accuracy= 0.85938\n",
      "Iter 204800, Minibatch Loss= 0.453552, Training Accuracy= 0.76923\n",
      "Iter 206080, Minibatch Loss= 0.512772, Training Accuracy= 0.74219\n",
      "Iter 207360, Minibatch Loss= 0.509716, Training Accuracy= 0.76562\n",
      "Iter 208640, Minibatch Loss= 0.390913, Training Accuracy= 0.85938\n",
      "Iter 209920, Minibatch Loss= 0.452784, Training Accuracy= 0.76923\n",
      "Iter 211200, Minibatch Loss= 0.511327, Training Accuracy= 0.74219\n",
      "Iter 212480, Minibatch Loss= 0.508291, Training Accuracy= 0.77344\n",
      "Iter 213760, Minibatch Loss= 0.389515, Training Accuracy= 0.85938\n",
      "Iter 215040, Minibatch Loss= 0.451988, Training Accuracy= 0.76923\n",
      "Iter 216320, Minibatch Loss= 0.509871, Training Accuracy= 0.74219\n",
      "Iter 217600, Minibatch Loss= 0.506855, Training Accuracy= 0.77344\n",
      "Iter 218880, Minibatch Loss= 0.388148, Training Accuracy= 0.85938\n",
      "Iter 220160, Minibatch Loss= 0.451164, Training Accuracy= 0.76923\n",
      "Iter 221440, Minibatch Loss= 0.508401, Training Accuracy= 0.74219\n",
      "Iter 222720, Minibatch Loss= 0.505408, Training Accuracy= 0.77344\n",
      "Iter 224000, Minibatch Loss= 0.386810, Training Accuracy= 0.85938\n",
      "Iter 225280, Minibatch Loss= 0.450307, Training Accuracy= 0.76923\n",
      "Iter 226560, Minibatch Loss= 0.506916, Training Accuracy= 0.74219\n",
      "Iter 227840, Minibatch Loss= 0.503946, Training Accuracy= 0.77344\n",
      "Iter 229120, Minibatch Loss= 0.385498, Training Accuracy= 0.85938\n",
      "Iter 230400, Minibatch Loss= 0.449418, Training Accuracy= 0.76923\n",
      "Iter 231680, Minibatch Loss= 0.505410, Training Accuracy= 0.74219\n",
      "Iter 232960, Minibatch Loss= 0.502465, Training Accuracy= 0.77344\n",
      "Iter 234240, Minibatch Loss= 0.384209, Training Accuracy= 0.85938\n",
      "Iter 235520, Minibatch Loss= 0.448492, Training Accuracy= 0.76923\n",
      "Iter 236800, Minibatch Loss= 0.503882, Training Accuracy= 0.74219\n",
      "Iter 238080, Minibatch Loss= 0.500962, Training Accuracy= 0.77344\n",
      "Iter 239360, Minibatch Loss= 0.382940, Training Accuracy= 0.85938\n",
      "Iter 240640, Minibatch Loss= 0.447529, Training Accuracy= 0.76923\n",
      "Iter 241920, Minibatch Loss= 0.502328, Training Accuracy= 0.74219\n",
      "Iter 243200, Minibatch Loss= 0.499435, Training Accuracy= 0.77344\n",
      "Iter 244480, Minibatch Loss= 0.381687, Training Accuracy= 0.85938\n",
      "Iter 245760, Minibatch Loss= 0.446527, Training Accuracy= 0.76923\n",
      "Iter 247040, Minibatch Loss= 0.500745, Training Accuracy= 0.74219\n",
      "Iter 248320, Minibatch Loss= 0.497879, Training Accuracy= 0.77344\n",
      "Iter 249600, Minibatch Loss= 0.380449, Training Accuracy= 0.85938\n",
      "Iter 250880, Minibatch Loss= 0.445484, Training Accuracy= 0.76923\n",
      "Iter 252160, Minibatch Loss= 0.499129, Training Accuracy= 0.74219\n",
      "Iter 253440, Minibatch Loss= 0.496290, Training Accuracy= 0.77344\n",
      "Iter 254720, Minibatch Loss= 0.379221, Training Accuracy= 0.85938\n",
      "Iter 256000, Minibatch Loss= 0.444398, Training Accuracy= 0.76923\n",
      "Iter 257280, Minibatch Loss= 0.497477, Training Accuracy= 0.74219\n",
      "Iter 258560, Minibatch Loss= 0.494664, Training Accuracy= 0.77344\n",
      "Iter 259840, Minibatch Loss= 0.378001, Training Accuracy= 0.85938\n",
      "Iter 261120, Minibatch Loss= 0.443268, Training Accuracy= 0.76923\n",
      "Iter 262400, Minibatch Loss= 0.495785, Training Accuracy= 0.74219\n",
      "Iter 263680, Minibatch Loss= 0.492999, Training Accuracy= 0.77344\n",
      "Iter 264960, Minibatch Loss= 0.376785, Training Accuracy= 0.85938\n",
      "Iter 266240, Minibatch Loss= 0.442091, Training Accuracy= 0.76923\n",
      "Iter 267520, Minibatch Loss= 0.494050, Training Accuracy= 0.74219\n",
      "Iter 268800, Minibatch Loss= 0.491290, Training Accuracy= 0.77344\n",
      "Iter 270080, Minibatch Loss= 0.375569, Training Accuracy= 0.85156\n",
      "Iter 271360, Minibatch Loss= 0.440868, Training Accuracy= 0.76923\n",
      "Iter 272640, Minibatch Loss= 0.492267, Training Accuracy= 0.74219\n",
      "Iter 273920, Minibatch Loss= 0.489533, Training Accuracy= 0.77344\n",
      "Iter 275200, Minibatch Loss= 0.374351, Training Accuracy= 0.85156\n",
      "Iter 276480, Minibatch Loss= 0.439596, Training Accuracy= 0.76923\n",
      "Iter 277760, Minibatch Loss= 0.490435, Training Accuracy= 0.74219\n",
      "Iter 279040, Minibatch Loss= 0.487724, Training Accuracy= 0.77344\n",
      "Iter 280320, Minibatch Loss= 0.373127, Training Accuracy= 0.84375\n",
      "Iter 281600, Minibatch Loss= 0.438273, Training Accuracy= 0.76923\n",
      "Iter 282880, Minibatch Loss= 0.488551, Training Accuracy= 0.74219\n",
      "Iter 284160, Minibatch Loss= 0.485862, Training Accuracy= 0.78125\n",
      "Iter 285440, Minibatch Loss= 0.371892, Training Accuracy= 0.84375\n",
      "Iter 286720, Minibatch Loss= 0.436898, Training Accuracy= 0.76923\n",
      "Iter 288000, Minibatch Loss= 0.486612, Training Accuracy= 0.74219\n",
      "Iter 289280, Minibatch Loss= 0.483942, Training Accuracy= 0.77344\n",
      "Iter 290560, Minibatch Loss= 0.370644, Training Accuracy= 0.84375\n",
      "Iter 291840, Minibatch Loss= 0.435470, Training Accuracy= 0.76923\n",
      "Iter 293120, Minibatch Loss= 0.484616, Training Accuracy= 0.74219\n",
      "Iter 294400, Minibatch Loss= 0.481962, Training Accuracy= 0.78906\n",
      "Iter 295680, Minibatch Loss= 0.369380, Training Accuracy= 0.84375\n",
      "Iter 296960, Minibatch Loss= 0.433987, Training Accuracy= 0.76923\n",
      "Iter 298240, Minibatch Loss= 0.482563, Training Accuracy= 0.74219\n",
      "Iter 299520, Minibatch Loss= 0.479921, Training Accuracy= 0.79688\n",
      "Iter 300800, Minibatch Loss= 0.368096, Training Accuracy= 0.84375\n",
      "Iter 302080, Minibatch Loss= 0.432447, Training Accuracy= 0.76923\n",
      "Iter 303360, Minibatch Loss= 0.480454, Training Accuracy= 0.74219\n",
      "Iter 304640, Minibatch Loss= 0.477818, Training Accuracy= 0.79688\n",
      "Iter 305920, Minibatch Loss= 0.366790, Training Accuracy= 0.84375\n",
      "Iter 307200, Minibatch Loss= 0.430847, Training Accuracy= 0.76923\n",
      "Iter 308480, Minibatch Loss= 0.478289, Training Accuracy= 0.74219\n",
      "Iter 309760, Minibatch Loss= 0.475651, Training Accuracy= 0.79688\n",
      "Iter 311040, Minibatch Loss= 0.365460, Training Accuracy= 0.84375\n",
      "Iter 312320, Minibatch Loss= 0.429186, Training Accuracy= 0.76923\n",
      "Iter 313600, Minibatch Loss= 0.476072, Training Accuracy= 0.75000\n",
      "Iter 314880, Minibatch Loss= 0.473420, Training Accuracy= 0.79688\n",
      "Iter 316160, Minibatch Loss= 0.364104, Training Accuracy= 0.84375\n",
      "Iter 317440, Minibatch Loss= 0.427460, Training Accuracy= 0.76923\n",
      "Iter 318720, Minibatch Loss= 0.473804, Training Accuracy= 0.74219\n",
      "Iter 320000, Minibatch Loss= 0.471127, Training Accuracy= 0.79688\n",
      "Iter 321280, Minibatch Loss= 0.362722, Training Accuracy= 0.84375\n",
      "Iter 322560, Minibatch Loss= 0.425669, Training Accuracy= 0.76923\n",
      "Iter 323840, Minibatch Loss= 0.471493, Training Accuracy= 0.74219\n",
      "Iter 325120, Minibatch Loss= 0.468771, Training Accuracy= 0.79688\n",
      "Iter 326400, Minibatch Loss= 0.361313, Training Accuracy= 0.84375\n",
      "Iter 327680, Minibatch Loss= 0.423807, Training Accuracy= 0.77885\n",
      "Iter 328960, Minibatch Loss= 0.469143, Training Accuracy= 0.74219\n",
      "Iter 330240, Minibatch Loss= 0.466354, Training Accuracy= 0.79688\n",
      "Iter 331520, Minibatch Loss= 0.359880, Training Accuracy= 0.84375\n",
      "Iter 332800, Minibatch Loss= 0.421873, Training Accuracy= 0.77885\n",
      "Iter 334080, Minibatch Loss= 0.466763, Training Accuracy= 0.74219\n",
      "Iter 335360, Minibatch Loss= 0.463879, Training Accuracy= 0.79688\n",
      "Iter 336640, Minibatch Loss= 0.358424, Training Accuracy= 0.84375\n",
      "Iter 337920, Minibatch Loss= 0.419863, Training Accuracy= 0.77885\n",
      "Iter 339200, Minibatch Loss= 0.464359, Training Accuracy= 0.74219\n",
      "Iter 340480, Minibatch Loss= 0.461345, Training Accuracy= 0.79688\n",
      "Iter 341760, Minibatch Loss= 0.356949, Training Accuracy= 0.85156\n",
      "Iter 343040, Minibatch Loss= 0.417775, Training Accuracy= 0.76923\n",
      "Iter 344320, Minibatch Loss= 0.461942, Training Accuracy= 0.75000\n",
      "Iter 345600, Minibatch Loss= 0.458756, Training Accuracy= 0.79688\n",
      "Iter 346880, Minibatch Loss= 0.355457, Training Accuracy= 0.85156\n",
      "Iter 348160, Minibatch Loss= 0.415605, Training Accuracy= 0.77885\n",
      "Iter 349440, Minibatch Loss= 0.459519, Training Accuracy= 0.75781\n",
      "Iter 350720, Minibatch Loss= 0.456111, Training Accuracy= 0.79688\n",
      "Iter 352000, Minibatch Loss= 0.353954, Training Accuracy= 0.85156\n",
      "Iter 353280, Minibatch Loss= 0.413352, Training Accuracy= 0.77885\n",
      "Iter 354560, Minibatch Loss= 0.457100, Training Accuracy= 0.78125\n",
      "Iter 355840, Minibatch Loss= 0.453414, Training Accuracy= 0.79688\n",
      "Iter 357120, Minibatch Loss= 0.352444, Training Accuracy= 0.85156\n",
      "Iter 358400, Minibatch Loss= 0.411012, Training Accuracy= 0.77885\n",
      "Iter 359680, Minibatch Loss= 0.454692, Training Accuracy= 0.78906\n",
      "Iter 360960, Minibatch Loss= 0.450664, Training Accuracy= 0.80469\n",
      "Iter 362240, Minibatch Loss= 0.350932, Training Accuracy= 0.85156\n",
      "Iter 363520, Minibatch Loss= 0.408586, Training Accuracy= 0.77885\n",
      "Iter 364800, Minibatch Loss= 0.452302, Training Accuracy= 0.78906\n",
      "Iter 366080, Minibatch Loss= 0.447865, Training Accuracy= 0.80469\n",
      "Iter 367360, Minibatch Loss= 0.349421, Training Accuracy= 0.85156\n",
      "Iter 368640, Minibatch Loss= 0.406073, Training Accuracy= 0.78846\n",
      "Iter 369920, Minibatch Loss= 0.449934, Training Accuracy= 0.78906\n",
      "Iter 371200, Minibatch Loss= 0.445016, Training Accuracy= 0.80469\n",
      "Iter 372480, Minibatch Loss= 0.347917, Training Accuracy= 0.85156\n",
      "Iter 373760, Minibatch Loss= 0.403473, Training Accuracy= 0.79808\n",
      "Iter 375040, Minibatch Loss= 0.447592, Training Accuracy= 0.78906\n",
      "Iter 376320, Minibatch Loss= 0.442120, Training Accuracy= 0.79688\n",
      "Iter 377600, Minibatch Loss= 0.346422, Training Accuracy= 0.85938\n",
      "Iter 378880, Minibatch Loss= 0.400787, Training Accuracy= 0.79808\n",
      "Iter 380160, Minibatch Loss= 0.445275, Training Accuracy= 0.79688\n",
      "Iter 381440, Minibatch Loss= 0.439179, Training Accuracy= 0.79688\n",
      "Iter 382720, Minibatch Loss= 0.344938, Training Accuracy= 0.85938\n",
      "Iter 384000, Minibatch Loss= 0.398016, Training Accuracy= 0.79808\n",
      "Iter 385280, Minibatch Loss= 0.442982, Training Accuracy= 0.81250\n",
      "Iter 386560, Minibatch Loss= 0.436195, Training Accuracy= 0.79688\n",
      "Iter 387840, Minibatch Loss= 0.343465, Training Accuracy= 0.85938\n",
      "Iter 389120, Minibatch Loss= 0.395162, Training Accuracy= 0.80769\n",
      "Iter 390400, Minibatch Loss= 0.440707, Training Accuracy= 0.81250\n",
      "Iter 391680, Minibatch Loss= 0.433168, Training Accuracy= 0.79688\n",
      "Iter 392960, Minibatch Loss= 0.342002, Training Accuracy= 0.85938\n",
      "Iter 394240, Minibatch Loss= 0.392227, Training Accuracy= 0.80769\n",
      "Iter 395520, Minibatch Loss= 0.438445, Training Accuracy= 0.81250\n",
      "Iter 396800, Minibatch Loss= 0.430102, Training Accuracy= 0.80469\n",
      "Iter 398080, Minibatch Loss= 0.340547, Training Accuracy= 0.85938\n",
      "Iter 399360, Minibatch Loss= 0.389212, Training Accuracy= 0.80769\n",
      "Iter 400640, Minibatch Loss= 0.436187, Training Accuracy= 0.81250\n",
      "Iter 401920, Minibatch Loss= 0.426996, Training Accuracy= 0.80469\n",
      "Iter 403200, Minibatch Loss= 0.339096, Training Accuracy= 0.85938\n",
      "Iter 404480, Minibatch Loss= 0.386120, Training Accuracy= 0.80769\n",
      "Iter 405760, Minibatch Loss= 0.433922, Training Accuracy= 0.81250\n",
      "Iter 407040, Minibatch Loss= 0.423851, Training Accuracy= 0.80469\n",
      "Iter 408320, Minibatch Loss= 0.337643, Training Accuracy= 0.85938\n",
      "Iter 409600, Minibatch Loss= 0.382952, Training Accuracy= 0.80769\n",
      "Iter 410880, Minibatch Loss= 0.431642, Training Accuracy= 0.82031\n",
      "Iter 412160, Minibatch Loss= 0.420667, Training Accuracy= 0.80469\n",
      "Iter 413440, Minibatch Loss= 0.336181, Training Accuracy= 0.85938\n",
      "Iter 414720, Minibatch Loss= 0.379708, Training Accuracy= 0.80769\n",
      "Iter 416000, Minibatch Loss= 0.429337, Training Accuracy= 0.81250\n",
      "Iter 417280, Minibatch Loss= 0.417441, Training Accuracy= 0.79688\n",
      "Iter 418560, Minibatch Loss= 0.334704, Training Accuracy= 0.85938\n",
      "Iter 419840, Minibatch Loss= 0.376389, Training Accuracy= 0.80769\n",
      "Iter 421120, Minibatch Loss= 0.426995, Training Accuracy= 0.82812\n",
      "Iter 422400, Minibatch Loss= 0.414172, Training Accuracy= 0.81250\n",
      "Iter 423680, Minibatch Loss= 0.333203, Training Accuracy= 0.86719\n",
      "Iter 424960, Minibatch Loss= 0.372995, Training Accuracy= 0.80769\n",
      "Iter 426240, Minibatch Loss= 0.424609, Training Accuracy= 0.84375\n",
      "Iter 427520, Minibatch Loss= 0.410855, Training Accuracy= 0.81250\n",
      "Iter 428800, Minibatch Loss= 0.331669, Training Accuracy= 0.86719\n",
      "Iter 430080, Minibatch Loss= 0.369527, Training Accuracy= 0.80769\n",
      "Iter 431360, Minibatch Loss= 0.422167, Training Accuracy= 0.84375\n",
      "Iter 432640, Minibatch Loss= 0.407487, Training Accuracy= 0.80469\n",
      "Iter 433920, Minibatch Loss= 0.330094, Training Accuracy= 0.87500\n",
      "Iter 435200, Minibatch Loss= 0.365987, Training Accuracy= 0.80769\n",
      "Iter 436480, Minibatch Loss= 0.419657, Training Accuracy= 0.84375\n",
      "Iter 437760, Minibatch Loss= 0.404066, Training Accuracy= 0.80469\n",
      "Iter 439040, Minibatch Loss= 0.328465, Training Accuracy= 0.86719\n",
      "Iter 440320, Minibatch Loss= 0.362381, Training Accuracy= 0.81731\n",
      "Iter 441600, Minibatch Loss= 0.417063, Training Accuracy= 0.84375\n",
      "Iter 442880, Minibatch Loss= 0.400589, Training Accuracy= 0.80469\n",
      "Iter 444160, Minibatch Loss= 0.326770, Training Accuracy= 0.85938\n",
      "Iter 445440, Minibatch Loss= 0.358718, Training Accuracy= 0.81731\n",
      "Iter 446720, Minibatch Loss= 0.414361, Training Accuracy= 0.83594\n",
      "Iter 448000, Minibatch Loss= 0.397061, Training Accuracy= 0.80469\n",
      "Iter 449280, Minibatch Loss= 0.324990, Training Accuracy= 0.85938\n",
      "Iter 450560, Minibatch Loss= 0.355016, Training Accuracy= 0.81731\n",
      "Iter 451840, Minibatch Loss= 0.411510, Training Accuracy= 0.83594\n",
      "Iter 453120, Minibatch Loss= 0.393489, Training Accuracy= 0.81250\n",
      "Iter 454400, Minibatch Loss= 0.323098, Training Accuracy= 0.85938\n",
      "Iter 455680, Minibatch Loss= 0.351304, Training Accuracy= 0.81731\n",
      "Iter 456960, Minibatch Loss= 0.408449, Training Accuracy= 0.82031\n",
      "Iter 458240, Minibatch Loss= 0.389891, Training Accuracy= 0.81250\n",
      "Iter 459520, Minibatch Loss= 0.321054, Training Accuracy= 0.85938\n",
      "Iter 460800, Minibatch Loss= 0.347632, Training Accuracy= 0.81731\n",
      "Iter 462080, Minibatch Loss= 0.405075, Training Accuracy= 0.82031\n",
      "Iter 463360, Minibatch Loss= 0.386302, Training Accuracy= 0.81250\n",
      "Iter 464640, Minibatch Loss= 0.318792, Training Accuracy= 0.85938\n",
      "Iter 465920, Minibatch Loss= 0.344084, Training Accuracy= 0.81731\n",
      "Iter 467200, Minibatch Loss= 0.401224, Training Accuracy= 0.82031\n",
      "Iter 468480, Minibatch Loss= 0.382778, Training Accuracy= 0.82031\n",
      "Iter 469760, Minibatch Loss= 0.316209, Training Accuracy= 0.85938\n",
      "Iter 471040, Minibatch Loss= 0.340798, Training Accuracy= 0.81731\n",
      "Iter 472320, Minibatch Loss= 0.396633, Training Accuracy= 0.82031\n",
      "Iter 473600, Minibatch Loss= 0.379408, Training Accuracy= 0.82812\n",
      "Iter 474880, Minibatch Loss= 0.313143, Training Accuracy= 0.86719\n",
      "Iter 476160, Minibatch Loss= 0.338009, Training Accuracy= 0.82692\n",
      "Iter 477440, Minibatch Loss= 0.390886, Training Accuracy= 0.82812\n",
      "Iter 478720, Minibatch Loss= 0.376308, Training Accuracy= 0.83594\n",
      "Iter 480000, Minibatch Loss= 0.309349, Training Accuracy= 0.87500\n",
      "Iter 481280, Minibatch Loss= 0.336126, Training Accuracy= 0.83654\n",
      "Iter 482560, Minibatch Loss= 0.383353, Training Accuracy= 0.82812\n",
      "Iter 483840, Minibatch Loss= 0.373548, Training Accuracy= 0.84375\n",
      "Iter 485120, Minibatch Loss= 0.304509, Training Accuracy= 0.87500\n",
      "Iter 486400, Minibatch Loss= 0.335883, Training Accuracy= 0.82692\n",
      "Iter 487680, Minibatch Loss= 0.373212, Training Accuracy= 0.83594\n",
      "Iter 488960, Minibatch Loss= 0.370761, Training Accuracy= 0.83594\n",
      "Iter 490240, Minibatch Loss= 0.298433, Training Accuracy= 0.88281\n",
      "Iter 491520, Minibatch Loss= 0.338794, Training Accuracy= 0.81731\n",
      "Iter 492800, Minibatch Loss= 0.360123, Training Accuracy= 0.85938\n",
      "Iter 494080, Minibatch Loss= 0.365590, Training Accuracy= 0.82812\n",
      "Iter 495360, Minibatch Loss= 0.292545, Training Accuracy= 0.89062\n",
      "Iter 496640, Minibatch Loss= 0.349263, Training Accuracy= 0.81731\n",
      "Iter 497920, Minibatch Loss= 0.348295, Training Accuracy= 0.85156\n",
      "Iter 499200, Minibatch Loss= 0.354581, Training Accuracy= 0.84375\n",
      "Iter 500480, Minibatch Loss= 0.293739, Training Accuracy= 0.87500\n",
      "Iter 501760, Minibatch Loss= 0.361754, Training Accuracy= 0.81731\n",
      "Iter 503040, Minibatch Loss= 0.343001, Training Accuracy= 0.85156\n",
      "Iter 504320, Minibatch Loss= 0.347653, Training Accuracy= 0.84375\n",
      "Iter 505600, Minibatch Loss= 0.292391, Training Accuracy= 0.87500\n",
      "Iter 506880, Minibatch Loss= 0.360405, Training Accuracy= 0.81731\n",
      "Iter 508160, Minibatch Loss= 0.337952, Training Accuracy= 0.85156\n",
      "Iter 509440, Minibatch Loss= 0.341555, Training Accuracy= 0.84375\n",
      "Iter 510720, Minibatch Loss= 0.290736, Training Accuracy= 0.87500\n",
      "Iter 512000, Minibatch Loss= 0.358573, Training Accuracy= 0.81731\n",
      "Iter 513280, Minibatch Loss= 0.332924, Training Accuracy= 0.85156\n",
      "Iter 514560, Minibatch Loss= 0.335504, Training Accuracy= 0.84375\n",
      "Iter 515840, Minibatch Loss= 0.289038, Training Accuracy= 0.87500\n",
      "Iter 517120, Minibatch Loss= 0.356179, Training Accuracy= 0.81731\n",
      "Iter 518400, Minibatch Loss= 0.327856, Training Accuracy= 0.85938\n",
      "Iter 519680, Minibatch Loss= 0.329374, Training Accuracy= 0.84375\n",
      "Iter 520960, Minibatch Loss= 0.287410, Training Accuracy= 0.88281\n",
      "Iter 522240, Minibatch Loss= 0.353344, Training Accuracy= 0.81731\n",
      "Iter 523520, Minibatch Loss= 0.322708, Training Accuracy= 0.85938\n",
      "Iter 524800, Minibatch Loss= 0.323128, Training Accuracy= 0.84375\n",
      "Iter 526080, Minibatch Loss= 0.285865, Training Accuracy= 0.87500\n",
      "Iter 527360, Minibatch Loss= 0.350095, Training Accuracy= 0.81731\n",
      "Iter 528640, Minibatch Loss= 0.317446, Training Accuracy= 0.85938\n",
      "Iter 529920, Minibatch Loss= 0.316755, Training Accuracy= 0.84375\n",
      "Iter 531200, Minibatch Loss= 0.284368, Training Accuracy= 0.87500\n",
      "Iter 532480, Minibatch Loss= 0.346435, Training Accuracy= 0.81731\n",
      "Iter 533760, Minibatch Loss= 0.312045, Training Accuracy= 0.85938\n",
      "Iter 535040, Minibatch Loss= 0.310259, Training Accuracy= 0.85156\n",
      "Iter 536320, Minibatch Loss= 0.282840, Training Accuracy= 0.87500\n",
      "Iter 537600, Minibatch Loss= 0.342373, Training Accuracy= 0.81731\n",
      "Iter 538880, Minibatch Loss= 0.306496, Training Accuracy= 0.85938\n",
      "Iter 540160, Minibatch Loss= 0.303641, Training Accuracy= 0.85156\n",
      "Iter 541440, Minibatch Loss= 0.281158, Training Accuracy= 0.87500\n",
      "Iter 542720, Minibatch Loss= 0.337925, Training Accuracy= 0.81731\n",
      "Iter 544000, Minibatch Loss= 0.300809, Training Accuracy= 0.85938\n",
      "Iter 545280, Minibatch Loss= 0.296909, Training Accuracy= 0.85156\n",
      "Iter 546560, Minibatch Loss= 0.279168, Training Accuracy= 0.87500\n",
      "Iter 547840, Minibatch Loss= 0.333109, Training Accuracy= 0.81731\n",
      "Iter 549120, Minibatch Loss= 0.295012, Training Accuracy= 0.85938\n",
      "Iter 550400, Minibatch Loss= 0.290065, Training Accuracy= 0.85156\n",
      "Iter 551680, Minibatch Loss= 0.276686, Training Accuracy= 0.87500\n",
      "Iter 552960, Minibatch Loss= 0.327967, Training Accuracy= 0.81731\n",
      "Iter 554240, Minibatch Loss= 0.289148, Training Accuracy= 0.85938\n",
      "Iter 555520, Minibatch Loss= 0.283105, Training Accuracy= 0.85156\n",
      "Iter 556800, Minibatch Loss= 0.273488, Training Accuracy= 0.87500\n",
      "Iter 558080, Minibatch Loss= 0.322798, Training Accuracy= 0.82692\n",
      "Iter 559360, Minibatch Loss= 0.283245, Training Accuracy= 0.86719\n",
      "Iter 560640, Minibatch Loss= 0.275967, Training Accuracy= 0.85938\n",
      "Iter 561920, Minibatch Loss= 0.269250, Training Accuracy= 0.87500\n",
      "Iter 563200, Minibatch Loss= 0.321255, Training Accuracy= 0.82692\n",
      "Iter 564480, Minibatch Loss= 0.276761, Training Accuracy= 0.86719\n",
      "Iter 565760, Minibatch Loss= 0.267852, Training Accuracy= 0.87500\n",
      "Iter 567040, Minibatch Loss= 0.253079, Training Accuracy= 0.88281\n",
      "Iter 568320, Minibatch Loss= 0.406634, Training Accuracy= 0.80769\n",
      "Iter 569600, Minibatch Loss= 0.263765, Training Accuracy= 0.89062\n",
      "Iter 570880, Minibatch Loss= 0.316955, Training Accuracy= 0.85156\n",
      "Iter 572160, Minibatch Loss= 0.305208, Training Accuracy= 0.88281\n",
      "Iter 573440, Minibatch Loss= 0.220793, Training Accuracy= 0.88462\n",
      "Iter 574720, Minibatch Loss= 0.276701, Training Accuracy= 0.90625\n",
      "Iter 576000, Minibatch Loss= 0.338769, Training Accuracy= 0.82812\n",
      "Iter 577280, Minibatch Loss= 0.331855, Training Accuracy= 0.86719\n",
      "Iter 578560, Minibatch Loss= 0.214906, Training Accuracy= 0.87500\n",
      "Iter 579840, Minibatch Loss= 0.262139, Training Accuracy= 0.91406\n",
      "Iter 581120, Minibatch Loss= 0.255451, Training Accuracy= 0.88281\n",
      "Iter 582400, Minibatch Loss= 0.191006, Training Accuracy= 0.92969\n",
      "Iter 583680, Minibatch Loss= 0.243053, Training Accuracy= 0.85577\n",
      "Iter 584960, Minibatch Loss= 0.258769, Training Accuracy= 0.91406\n",
      "Iter 586240, Minibatch Loss= 0.256600, Training Accuracy= 0.88281\n",
      "Iter 587520, Minibatch Loss= 0.189992, Training Accuracy= 0.92969\n",
      "Iter 588800, Minibatch Loss= 0.201850, Training Accuracy= 0.91346\n",
      "Iter 590080, Minibatch Loss= 0.241204, Training Accuracy= 0.87500\n",
      "Iter 591360, Minibatch Loss= 0.252892, Training Accuracy= 0.87500\n",
      "Iter 592640, Minibatch Loss= 0.193154, Training Accuracy= 0.92969\n",
      "Iter 593920, Minibatch Loss= 0.195513, Training Accuracy= 0.89423\n",
      "Iter 595200, Minibatch Loss= 0.235377, Training Accuracy= 0.92188\n",
      "Iter 596480, Minibatch Loss= 0.217325, Training Accuracy= 0.90625\n",
      "Iter 597760, Minibatch Loss= 0.382443, Training Accuracy= 0.85938\n",
      "Iter 599040, Minibatch Loss= 0.196399, Training Accuracy= 0.89423\n",
      "Iter 600320, Minibatch Loss= 0.236788, Training Accuracy= 0.92969\n",
      "Iter 601600, Minibatch Loss= 0.218418, Training Accuracy= 0.89844\n",
      "Iter 602880, Minibatch Loss= 0.182348, Training Accuracy= 0.94531\n",
      "Iter 604160, Minibatch Loss= 0.201083, Training Accuracy= 0.90385\n",
      "Iter 605440, Minibatch Loss= 0.421177, Training Accuracy= 0.75000\n",
      "Iter 606720, Minibatch Loss= 0.217163, Training Accuracy= 0.92188\n",
      "Iter 608000, Minibatch Loss= 0.178283, Training Accuracy= 0.95312\n",
      "Iter 609280, Minibatch Loss= 0.179886, Training Accuracy= 0.93269\n",
      "Iter 610560, Minibatch Loss= 0.213140, Training Accuracy= 0.92969\n",
      "Iter 611840, Minibatch Loss= 0.201740, Training Accuracy= 0.93750\n",
      "Iter 613120, Minibatch Loss= 1.065825, Training Accuracy= 0.71875\n",
      "Iter 614400, Minibatch Loss= 0.183524, Training Accuracy= 0.93269\n",
      "Iter 615680, Minibatch Loss= 0.219126, Training Accuracy= 0.93750\n",
      "Iter 616960, Minibatch Loss= 0.200445, Training Accuracy= 0.92969\n",
      "Iter 618240, Minibatch Loss= 0.173640, Training Accuracy= 0.94531\n",
      "Iter 619520, Minibatch Loss= 0.169590, Training Accuracy= 0.93269\n",
      "Iter 620800, Minibatch Loss= 0.201965, Training Accuracy= 0.92188\n",
      "Iter 622080, Minibatch Loss= 0.192753, Training Accuracy= 0.93750\n",
      "Iter 623360, Minibatch Loss= 0.716040, Training Accuracy= 0.83594\n",
      "Iter 624640, Minibatch Loss= 0.172520, Training Accuracy= 0.93269\n",
      "Iter 625920, Minibatch Loss= 0.208137, Training Accuracy= 0.93750\n",
      "Iter 627200, Minibatch Loss= 0.190473, Training Accuracy= 0.93750\n",
      "Iter 628480, Minibatch Loss= 0.166328, Training Accuracy= 0.95312\n",
      "Iter 629760, Minibatch Loss= 0.158147, Training Accuracy= 0.95192\n",
      "Iter 631040, Minibatch Loss= 0.192629, Training Accuracy= 0.92969\n",
      "Iter 632320, Minibatch Loss= 0.178340, Training Accuracy= 0.93750\n",
      "Iter 633600, Minibatch Loss= 0.178340, Training Accuracy= 0.93750\n",
      "Iter 634880, Minibatch Loss= 0.173854, Training Accuracy= 0.90385\n",
      "Iter 636160, Minibatch Loss= 0.186668, Training Accuracy= 0.92969\n",
      "Iter 637440, Minibatch Loss= 0.171118, Training Accuracy= 0.94531\n",
      "Iter 638720, Minibatch Loss= 0.188676, Training Accuracy= 0.91406\n",
      "Iter 640000, Minibatch Loss= 0.197719, Training Accuracy= 0.90385\n",
      "Iter 641280, Minibatch Loss= 0.199926, Training Accuracy= 0.92969\n",
      "Iter 642560, Minibatch Loss= 0.180401, Training Accuracy= 0.92969\n",
      "Iter 643840, Minibatch Loss= 0.156329, Training Accuracy= 0.96875\n",
      "Iter 645120, Minibatch Loss= 0.144647, Training Accuracy= 0.98077\n",
      "Iter 646400, Minibatch Loss= 0.181570, Training Accuracy= 0.95312\n",
      "Iter 647680, Minibatch Loss= 0.164355, Training Accuracy= 0.93750\n",
      "Iter 648960, Minibatch Loss= 0.150657, Training Accuracy= 0.96875\n",
      "Iter 650240, Minibatch Loss= 0.141375, Training Accuracy= 0.96154\n",
      "Iter 651520, Minibatch Loss= 0.172115, Training Accuracy= 0.92969\n",
      "Iter 652800, Minibatch Loss= 0.155863, Training Accuracy= 0.94531\n",
      "Iter 654080, Minibatch Loss= 0.151752, Training Accuracy= 0.95312\n",
      "Iter 655360, Minibatch Loss= 0.148018, Training Accuracy= 0.92308\n",
      "Iter 656640, Minibatch Loss= 0.261757, Training Accuracy= 0.82812\n",
      "Iter 657920, Minibatch Loss= 0.182600, Training Accuracy= 0.92188\n",
      "Iter 659200, Minibatch Loss= 0.151573, Training Accuracy= 0.96875\n",
      "Iter 660480, Minibatch Loss= 0.138915, Training Accuracy= 0.98077\n",
      "Iter 661760, Minibatch Loss= 0.174563, Training Accuracy= 0.95312\n",
      "Iter 663040, Minibatch Loss= 0.156835, Training Accuracy= 0.93750\n",
      "Iter 664320, Minibatch Loss= 0.141597, Training Accuracy= 0.97656\n",
      "Iter 665600, Minibatch Loss= 0.127805, Training Accuracy= 0.98077\n",
      "Iter 666880, Minibatch Loss= 0.162491, Training Accuracy= 0.95312\n",
      "Iter 668160, Minibatch Loss= 0.145320, Training Accuracy= 0.93750\n",
      "Iter 669440, Minibatch Loss= 0.136922, Training Accuracy= 0.97656\n",
      "Iter 670720, Minibatch Loss= 0.125813, Training Accuracy= 0.98077\n",
      "Iter 672000, Minibatch Loss= 0.155032, Training Accuracy= 0.96094\n",
      "Iter 673280, Minibatch Loss= 0.137668, Training Accuracy= 0.95312\n",
      "Iter 674560, Minibatch Loss= 0.135381, Training Accuracy= 0.97656\n",
      "Iter 675840, Minibatch Loss= 0.132932, Training Accuracy= 0.95192\n",
      "Iter 677120, Minibatch Loss= 0.170119, Training Accuracy= 0.96875\n",
      "Iter 678400, Minibatch Loss= 0.142050, Training Accuracy= 0.95312\n",
      "Iter 679680, Minibatch Loss= 0.132918, Training Accuracy= 0.97656\n",
      "Iter 680960, Minibatch Loss= 0.117386, Training Accuracy= 0.98077\n",
      "Iter 682240, Minibatch Loss= 0.148859, Training Accuracy= 0.96094\n",
      "Iter 683520, Minibatch Loss= 0.132865, Training Accuracy= 0.95312\n",
      "Iter 684800, Minibatch Loss= 0.128962, Training Accuracy= 0.97656\n",
      "Iter 686080, Minibatch Loss= 0.115683, Training Accuracy= 0.98077\n",
      "Iter 687360, Minibatch Loss= 0.142643, Training Accuracy= 0.96875\n",
      "Iter 688640, Minibatch Loss= 0.127060, Training Accuracy= 0.95312\n",
      "Iter 689920, Minibatch Loss= 0.126427, Training Accuracy= 0.97656\n",
      "Iter 691200, Minibatch Loss= 0.113781, Training Accuracy= 0.98077\n",
      "Iter 692480, Minibatch Loss= 0.137843, Training Accuracy= 0.97656\n",
      "Iter 693760, Minibatch Loss= 0.122705, Training Accuracy= 0.95312\n",
      "Iter 695040, Minibatch Loss= 0.123174, Training Accuracy= 0.97656\n",
      "Iter 696320, Minibatch Loss= 0.108553, Training Accuracy= 0.98077\n",
      "Iter 697600, Minibatch Loss= 0.133406, Training Accuracy= 0.97656\n",
      "Iter 698880, Minibatch Loss= 0.119195, Training Accuracy= 0.94531\n",
      "Iter 700160, Minibatch Loss= 0.120146, Training Accuracy= 0.97656\n",
      "Iter 701440, Minibatch Loss= 0.103576, Training Accuracy= 0.98077\n",
      "Iter 702720, Minibatch Loss= 0.129489, Training Accuracy= 0.97656\n",
      "Iter 704000, Minibatch Loss= 0.116215, Training Accuracy= 0.94531\n",
      "Iter 705280, Minibatch Loss= 0.117586, Training Accuracy= 0.97656\n",
      "Iter 706560, Minibatch Loss= 0.099741, Training Accuracy= 0.98077\n",
      "Iter 707840, Minibatch Loss= 0.126063, Training Accuracy= 0.97656\n",
      "Iter 709120, Minibatch Loss= 0.113601, Training Accuracy= 0.95312\n",
      "Iter 710400, Minibatch Loss= 0.115420, Training Accuracy= 0.97656\n",
      "Iter 711680, Minibatch Loss= 0.096657, Training Accuracy= 0.98077\n",
      "Iter 712960, Minibatch Loss= 0.122997, Training Accuracy= 0.97656\n",
      "Iter 714240, Minibatch Loss= 0.111257, Training Accuracy= 0.95312\n",
      "Iter 715520, Minibatch Loss= 0.113537, Training Accuracy= 0.97656\n",
      "Iter 716800, Minibatch Loss= 0.094018, Training Accuracy= 0.98077\n",
      "Iter 718080, Minibatch Loss= 0.120177, Training Accuracy= 0.97656\n",
      "Iter 719360, Minibatch Loss= 0.109123, Training Accuracy= 0.95312\n",
      "Iter 720640, Minibatch Loss= 0.111850, Training Accuracy= 0.97656\n",
      "Iter 721920, Minibatch Loss= 0.091643, Training Accuracy= 0.98077\n",
      "Iter 723200, Minibatch Loss= 0.117521, Training Accuracy= 0.98438\n",
      "Iter 724480, Minibatch Loss= 0.107157, Training Accuracy= 0.95312\n",
      "Iter 725760, Minibatch Loss= 0.110296, Training Accuracy= 0.97656\n",
      "Iter 727040, Minibatch Loss= 0.089427, Training Accuracy= 0.98077\n",
      "Iter 728320, Minibatch Loss= 0.114965, Training Accuracy= 0.98438\n",
      "Iter 729600, Minibatch Loss= 0.105336, Training Accuracy= 0.95312\n",
      "Iter 730880, Minibatch Loss= 0.108837, Training Accuracy= 0.97656\n",
      "Iter 732160, Minibatch Loss= 0.087325, Training Accuracy= 0.98077\n",
      "Iter 733440, Minibatch Loss= 0.112478, Training Accuracy= 0.98438\n",
      "Iter 734720, Minibatch Loss= 0.103637, Training Accuracy= 0.95312\n",
      "Iter 736000, Minibatch Loss= 0.107448, Training Accuracy= 0.97656\n",
      "Iter 737280, Minibatch Loss= 0.085330, Training Accuracy= 0.98077\n",
      "Iter 738560, Minibatch Loss= 0.110057, Training Accuracy= 0.98438\n",
      "Iter 739840, Minibatch Loss= 0.102045, Training Accuracy= 0.95312\n",
      "Iter 741120, Minibatch Loss= 0.106118, Training Accuracy= 0.97656\n",
      "Iter 742400, Minibatch Loss= 0.083448, Training Accuracy= 0.98077\n",
      "Iter 743680, Minibatch Loss= 0.107711, Training Accuracy= 0.98438\n",
      "Iter 744960, Minibatch Loss= 0.100546, Training Accuracy= 0.95312\n",
      "Iter 746240, Minibatch Loss= 0.104837, Training Accuracy= 0.97656\n",
      "Iter 747520, Minibatch Loss= 0.081683, Training Accuracy= 0.98077\n",
      "Iter 748800, Minibatch Loss= 0.105454, Training Accuracy= 0.98438\n",
      "Iter 750080, Minibatch Loss= 0.099126, Training Accuracy= 0.95312\n",
      "Iter 751360, Minibatch Loss= 0.103599, Training Accuracy= 0.97656\n",
      "Iter 752640, Minibatch Loss= 0.080040, Training Accuracy= 0.98077\n",
      "Iter 753920, Minibatch Loss= 0.103295, Training Accuracy= 0.98438\n",
      "Iter 755200, Minibatch Loss= 0.097778, Training Accuracy= 0.95312\n",
      "Iter 756480, Minibatch Loss= 0.102400, Training Accuracy= 0.97656\n",
      "Iter 757760, Minibatch Loss= 0.078520, Training Accuracy= 0.98077\n",
      "Iter 759040, Minibatch Loss= 0.101240, Training Accuracy= 0.98438\n",
      "Iter 760320, Minibatch Loss= 0.096492, Training Accuracy= 0.95312\n",
      "Iter 761600, Minibatch Loss= 0.101235, Training Accuracy= 0.98438\n",
      "Iter 762880, Minibatch Loss= 0.077123, Training Accuracy= 0.98077\n",
      "Iter 764160, Minibatch Loss= 0.099299, Training Accuracy= 0.98438\n",
      "Iter 765440, Minibatch Loss= 0.095262, Training Accuracy= 0.95312\n",
      "Iter 766720, Minibatch Loss= 0.100101, Training Accuracy= 0.98438\n",
      "Iter 768000, Minibatch Loss= 0.075844, Training Accuracy= 0.98077\n",
      "Iter 769280, Minibatch Loss= 0.097479, Training Accuracy= 0.98438\n",
      "Iter 770560, Minibatch Loss= 0.094083, Training Accuracy= 0.95312\n",
      "Iter 771840, Minibatch Loss= 0.098997, Training Accuracy= 0.98438\n",
      "Iter 773120, Minibatch Loss= 0.074679, Training Accuracy= 0.98077\n",
      "Iter 774400, Minibatch Loss= 0.095791, Training Accuracy= 0.98438\n",
      "Iter 775680, Minibatch Loss= 0.092948, Training Accuracy= 0.96094\n",
      "Iter 776960, Minibatch Loss= 0.097921, Training Accuracy= 0.98438\n",
      "Iter 778240, Minibatch Loss= 0.073620, Training Accuracy= 0.98077\n",
      "Iter 779520, Minibatch Loss= 0.094244, Training Accuracy= 0.98438\n",
      "Iter 780800, Minibatch Loss= 0.091855, Training Accuracy= 0.96094\n",
      "Iter 782080, Minibatch Loss= 0.096871, Training Accuracy= 0.98438\n",
      "Iter 783360, Minibatch Loss= 0.072657, Training Accuracy= 0.98077\n",
      "Iter 784640, Minibatch Loss= 0.092846, Training Accuracy= 0.98438\n",
      "Iter 785920, Minibatch Loss= 0.090799, Training Accuracy= 0.96094\n",
      "Iter 787200, Minibatch Loss= 0.095846, Training Accuracy= 0.98438\n",
      "Iter 788480, Minibatch Loss= 0.071777, Training Accuracy= 0.99038\n",
      "Iter 789760, Minibatch Loss= 0.091597, Training Accuracy= 0.98438\n",
      "Iter 791040, Minibatch Loss= 0.089777, Training Accuracy= 0.96094\n",
      "Iter 792320, Minibatch Loss= 0.094846, Training Accuracy= 0.98438\n",
      "Iter 793600, Minibatch Loss= 0.070967, Training Accuracy= 0.99038\n",
      "Iter 794880, Minibatch Loss= 0.090492, Training Accuracy= 0.98438\n",
      "Iter 796160, Minibatch Loss= 0.088788, Training Accuracy= 0.96094\n",
      "Iter 797440, Minibatch Loss= 0.093870, Training Accuracy= 0.98438\n",
      "Iter 798720, Minibatch Loss= 0.070216, Training Accuracy= 0.99038\n",
      "Iter 800000, Minibatch Loss= 0.089510, Training Accuracy= 0.98438\n",
      "Iter 801280, Minibatch Loss= 0.087828, Training Accuracy= 0.96094\n",
      "Iter 802560, Minibatch Loss= 0.092918, Training Accuracy= 0.98438\n",
      "Iter 803840, Minibatch Loss= 0.069512, Training Accuracy= 0.99038\n",
      "Iter 805120, Minibatch Loss= 0.088632, Training Accuracy= 0.98438\n",
      "Iter 806400, Minibatch Loss= 0.086897, Training Accuracy= 0.96094\n",
      "Iter 807680, Minibatch Loss= 0.091989, Training Accuracy= 0.98438\n",
      "Iter 808960, Minibatch Loss= 0.068845, Training Accuracy= 0.99038\n",
      "Iter 810240, Minibatch Loss= 0.087832, Training Accuracy= 0.98438\n",
      "Iter 811520, Minibatch Loss= 0.085994, Training Accuracy= 0.96094\n",
      "Iter 812800, Minibatch Loss= 0.091081, Training Accuracy= 0.98438\n",
      "Iter 814080, Minibatch Loss= 0.068213, Training Accuracy= 0.99038\n",
      "Iter 815360, Minibatch Loss= 0.087078, Training Accuracy= 0.98438\n",
      "Iter 816640, Minibatch Loss= 0.085118, Training Accuracy= 0.96094\n",
      "Iter 817920, Minibatch Loss= 0.090196, Training Accuracy= 0.98438\n",
      "Iter 819200, Minibatch Loss= 0.067608, Training Accuracy= 0.99038\n",
      "Iter 820480, Minibatch Loss= 0.086353, Training Accuracy= 0.98438\n",
      "Iter 821760, Minibatch Loss= 0.084267, Training Accuracy= 0.96094\n",
      "Iter 823040, Minibatch Loss= 0.089331, Training Accuracy= 0.98438\n",
      "Iter 824320, Minibatch Loss= 0.067030, Training Accuracy= 0.99038\n",
      "Iter 825600, Minibatch Loss= 0.085626, Training Accuracy= 0.98438\n",
      "Iter 826880, Minibatch Loss= 0.083442, Training Accuracy= 0.96094\n",
      "Iter 828160, Minibatch Loss= 0.088485, Training Accuracy= 0.99219\n",
      "Iter 829440, Minibatch Loss= 0.066472, Training Accuracy= 0.99038\n",
      "Iter 830720, Minibatch Loss= 0.084903, Training Accuracy= 0.98438\n",
      "Iter 832000, Minibatch Loss= 0.082641, Training Accuracy= 0.96094\n",
      "Iter 833280, Minibatch Loss= 0.087659, Training Accuracy= 0.99219\n",
      "Iter 834560, Minibatch Loss= 0.065942, Training Accuracy= 0.99038\n",
      "Iter 835840, Minibatch Loss= 0.084081, Training Accuracy= 0.98438\n",
      "Iter 837120, Minibatch Loss= 0.081863, Training Accuracy= 0.96094\n",
      "Iter 838400, Minibatch Loss= 0.086851, Training Accuracy= 0.99219\n",
      "Iter 839680, Minibatch Loss= 0.065412, Training Accuracy= 0.99038\n",
      "Iter 840960, Minibatch Loss= 0.083358, Training Accuracy= 0.98438\n",
      "Iter 842240, Minibatch Loss= 0.081109, Training Accuracy= 0.96094\n",
      "Iter 843520, Minibatch Loss= 0.086058, Training Accuracy= 0.99219\n",
      "Iter 844800, Minibatch Loss= 0.064943, Training Accuracy= 0.99038\n",
      "Iter 846080, Minibatch Loss= 0.082157, Training Accuracy= 0.98438\n",
      "Iter 847360, Minibatch Loss= 0.080374, Training Accuracy= 0.96094\n",
      "Iter 848640, Minibatch Loss= 0.085281, Training Accuracy= 0.99219\n",
      "Iter 849920, Minibatch Loss= 0.064390, Training Accuracy= 0.99038\n",
      "Iter 851200, Minibatch Loss= 0.081582, Training Accuracy= 0.98438\n",
      "Iter 852480, Minibatch Loss= 0.079665, Training Accuracy= 0.96094\n",
      "Iter 853760, Minibatch Loss= 0.084518, Training Accuracy= 0.99219\n",
      "Iter 855040, Minibatch Loss= 0.063932, Training Accuracy= 0.99038\n",
      "Iter 856320, Minibatch Loss= 0.080245, Training Accuracy= 0.98438\n",
      "Iter 857600, Minibatch Loss= 0.078974, Training Accuracy= 0.96094\n",
      "Iter 858880, Minibatch Loss= 0.083766, Training Accuracy= 0.99219\n",
      "Iter 860160, Minibatch Loss= 0.063454, Training Accuracy= 0.99038\n",
      "Iter 861440, Minibatch Loss= 0.078866, Training Accuracy= 0.98438\n",
      "Iter 862720, Minibatch Loss= 0.078306, Training Accuracy= 0.96094\n",
      "Iter 864000, Minibatch Loss= 0.083025, Training Accuracy= 0.99219\n",
      "Iter 865280, Minibatch Loss= 0.062931, Training Accuracy= 0.99038\n",
      "Iter 866560, Minibatch Loss= 0.077101, Training Accuracy= 0.98438\n",
      "Iter 867840, Minibatch Loss= 0.077662, Training Accuracy= 0.96094\n",
      "Iter 869120, Minibatch Loss= 0.082284, Training Accuracy= 0.99219\n",
      "Iter 870400, Minibatch Loss= 0.062190, Training Accuracy= 0.99038\n",
      "Iter 871680, Minibatch Loss= 0.072806, Training Accuracy= 0.98438\n",
      "Iter 872960, Minibatch Loss= 0.077111, Training Accuracy= 0.96094\n",
      "Iter 874240, Minibatch Loss= 0.081316, Training Accuracy= 0.99219\n",
      "Iter 875520, Minibatch Loss= 0.052156, Training Accuracy= 0.99038\n",
      "Iter 876800, Minibatch Loss= 0.072186, Training Accuracy= 0.98438\n",
      "Iter 878080, Minibatch Loss= 0.077090, Training Accuracy= 0.96094\n",
      "Iter 879360, Minibatch Loss= 0.080046, Training Accuracy= 0.99219\n",
      "Iter 880640, Minibatch Loss= 0.049706, Training Accuracy= 0.99038\n",
      "Iter 881920, Minibatch Loss= 0.072708, Training Accuracy= 0.98438\n",
      "Iter 883200, Minibatch Loss= 0.076631, Training Accuracy= 0.96094\n",
      "Iter 884480, Minibatch Loss= 0.079239, Training Accuracy= 0.99219\n",
      "Iter 885760, Minibatch Loss= 0.051500, Training Accuracy= 0.99038\n",
      "Iter 887040, Minibatch Loss= 0.068565, Training Accuracy= 0.98438\n",
      "Iter 888320, Minibatch Loss= 0.075915, Training Accuracy= 0.96094\n",
      "Iter 889600, Minibatch Loss= 0.078928, Training Accuracy= 0.99219\n",
      "Iter 890880, Minibatch Loss= 0.109735, Training Accuracy= 0.97115\n",
      "Iter 892160, Minibatch Loss= 0.102768, Training Accuracy= 0.96875\n",
      "Iter 893440, Minibatch Loss= 0.092485, Training Accuracy= 0.95312\n",
      "Iter 894720, Minibatch Loss= 0.078916, Training Accuracy= 0.98438\n",
      "Iter 896000, Minibatch Loss= 0.067174, Training Accuracy= 0.98077\n",
      "Iter 897280, Minibatch Loss= 0.081684, Training Accuracy= 0.98438\n",
      "Iter 898560, Minibatch Loss= 0.086598, Training Accuracy= 0.95312\n",
      "Iter 899840, Minibatch Loss= 0.077767, Training Accuracy= 0.98438\n",
      "Iter 901120, Minibatch Loss= 0.063223, Training Accuracy= 0.98077\n",
      "Iter 902400, Minibatch Loss= 0.077421, Training Accuracy= 0.98438\n",
      "Iter 903680, Minibatch Loss= 0.084211, Training Accuracy= 0.95312\n",
      "Iter 904960, Minibatch Loss= 0.077139, Training Accuracy= 0.98438\n",
      "Iter 906240, Minibatch Loss= 0.060068, Training Accuracy= 0.98077\n",
      "Iter 907520, Minibatch Loss= 0.074427, Training Accuracy= 0.98438\n",
      "Iter 908800, Minibatch Loss= 0.082430, Training Accuracy= 0.95312\n",
      "Iter 910080, Minibatch Loss= 0.076574, Training Accuracy= 0.98438\n",
      "Iter 911360, Minibatch Loss= 0.057356, Training Accuracy= 0.98077\n",
      "Iter 912640, Minibatch Loss= 0.072130, Training Accuracy= 0.98438\n",
      "Iter 913920, Minibatch Loss= 0.080971, Training Accuracy= 0.95312\n",
      "Iter 915200, Minibatch Loss= 0.076051, Training Accuracy= 0.98438\n",
      "Iter 916480, Minibatch Loss= 0.054959, Training Accuracy= 0.98077\n",
      "Iter 917760, Minibatch Loss= 0.070302, Training Accuracy= 0.98438\n",
      "Iter 919040, Minibatch Loss= 0.079719, Training Accuracy= 0.95312\n",
      "Iter 920320, Minibatch Loss= 0.075560, Training Accuracy= 0.98438\n",
      "Iter 921600, Minibatch Loss= 0.052816, Training Accuracy= 0.98077\n",
      "Iter 922880, Minibatch Loss= 0.068821, Training Accuracy= 0.98438\n",
      "Iter 924160, Minibatch Loss= 0.078613, Training Accuracy= 0.95312\n",
      "Iter 925440, Minibatch Loss= 0.075089, Training Accuracy= 0.98438\n",
      "Iter 926720, Minibatch Loss= 0.050894, Training Accuracy= 0.98077\n",
      "Iter 928000, Minibatch Loss= 0.067613, Training Accuracy= 0.98438\n",
      "Iter 929280, Minibatch Loss= 0.077616, Training Accuracy= 0.95312\n",
      "Iter 930560, Minibatch Loss= 0.074626, Training Accuracy= 0.98438\n",
      "Iter 931840, Minibatch Loss= 0.049166, Training Accuracy= 0.98077\n",
      "Iter 933120, Minibatch Loss= 0.066627, Training Accuracy= 0.98438\n",
      "Iter 934400, Minibatch Loss= 0.076705, Training Accuracy= 0.95312\n",
      "Iter 935680, Minibatch Loss= 0.074164, Training Accuracy= 0.98438\n",
      "Iter 936960, Minibatch Loss= 0.047613, Training Accuracy= 0.99038\n",
      "Iter 938240, Minibatch Loss= 0.065829, Training Accuracy= 0.98438\n",
      "Iter 939520, Minibatch Loss= 0.075862, Training Accuracy= 0.96094\n",
      "Iter 940800, Minibatch Loss= 0.073696, Training Accuracy= 0.98438\n",
      "Iter 942080, Minibatch Loss= 0.046213, Training Accuracy= 0.99038\n",
      "Iter 943360, Minibatch Loss= 0.065196, Training Accuracy= 0.98438\n",
      "Iter 944640, Minibatch Loss= 0.075079, Training Accuracy= 0.96094\n",
      "Iter 945920, Minibatch Loss= 0.073222, Training Accuracy= 0.98438\n",
      "Iter 947200, Minibatch Loss= 0.044948, Training Accuracy= 0.99038\n",
      "Iter 948480, Minibatch Loss= 0.064718, Training Accuracy= 0.97656\n",
      "Iter 949760, Minibatch Loss= 0.074346, Training Accuracy= 0.96094\n",
      "Iter 951040, Minibatch Loss= 0.072741, Training Accuracy= 0.98438\n",
      "Iter 952320, Minibatch Loss= 0.043801, Training Accuracy= 0.99038\n",
      "Iter 953600, Minibatch Loss= 0.064392, Training Accuracy= 0.98438\n",
      "Iter 954880, Minibatch Loss= 0.073658, Training Accuracy= 0.96094\n",
      "Iter 956160, Minibatch Loss= 0.072257, Training Accuracy= 0.98438\n",
      "Iter 957440, Minibatch Loss= 0.042756, Training Accuracy= 0.99038\n",
      "Iter 958720, Minibatch Loss= 0.064217, Training Accuracy= 0.98438\n",
      "Iter 960000, Minibatch Loss= 0.073010, Training Accuracy= 0.96094\n",
      "Iter 961280, Minibatch Loss= 0.071770, Training Accuracy= 0.99219\n",
      "Iter 962560, Minibatch Loss= 0.041800, Training Accuracy= 0.99038\n",
      "Iter 963840, Minibatch Loss= 0.064201, Training Accuracy= 0.98438\n",
      "Iter 965120, Minibatch Loss= 0.072398, Training Accuracy= 0.96094\n",
      "Iter 966400, Minibatch Loss= 0.071284, Training Accuracy= 0.99219\n",
      "Iter 967680, Minibatch Loss= 0.040922, Training Accuracy= 0.99038\n",
      "Iter 968960, Minibatch Loss= 0.064350, Training Accuracy= 0.98438\n",
      "Iter 970240, Minibatch Loss= 0.071819, Training Accuracy= 0.96875\n",
      "Iter 971520, Minibatch Loss= 0.070801, Training Accuracy= 0.99219\n",
      "Iter 972800, Minibatch Loss= 0.040110, Training Accuracy= 0.99038\n",
      "Iter 974080, Minibatch Loss= 0.064673, Training Accuracy= 0.98438\n",
      "Iter 975360, Minibatch Loss= 0.071270, Training Accuracy= 0.96875\n",
      "Iter 976640, Minibatch Loss= 0.070323, Training Accuracy= 0.99219\n",
      "Iter 977920, Minibatch Loss= 0.039359, Training Accuracy= 0.99038\n",
      "Iter 979200, Minibatch Loss= 0.065175, Training Accuracy= 0.98438\n",
      "Iter 980480, Minibatch Loss= 0.070748, Training Accuracy= 0.96875\n",
      "Iter 981760, Minibatch Loss= 0.069851, Training Accuracy= 0.99219\n",
      "Iter 983040, Minibatch Loss= 0.038662, Training Accuracy= 0.99038\n",
      "Iter 984320, Minibatch Loss= 0.065861, Training Accuracy= 0.98438\n",
      "Iter 985600, Minibatch Loss= 0.070251, Training Accuracy= 0.96875\n",
      "Iter 986880, Minibatch Loss= 0.069388, Training Accuracy= 0.99219\n",
      "Iter 988160, Minibatch Loss= 0.038017, Training Accuracy= 0.99038\n",
      "Iter 989440, Minibatch Loss= 0.066724, Training Accuracy= 0.98438\n",
      "Iter 990720, Minibatch Loss= 0.069775, Training Accuracy= 0.96875\n",
      "Iter 992000, Minibatch Loss= 0.068935, Training Accuracy= 0.99219\n",
      "Iter 993280, Minibatch Loss= 0.037428, Training Accuracy= 0.99038\n",
      "Iter 994560, Minibatch Loss= 0.067748, Training Accuracy= 0.98438\n",
      "Iter 995840, Minibatch Loss= 0.069318, Training Accuracy= 0.96875\n",
      "Iter 997120, Minibatch Loss= 0.068493, Training Accuracy= 0.99219\n",
      "Iter 998400, Minibatch Loss= 0.036907, Training Accuracy= 0.99038\n",
      "Iter 999680, Minibatch Loss= 0.068896, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.962\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "A Dynamic Recurrent Neural Network (LSTM) implementation example using\n",
    "TensorFlow library. This example is using a toy dataset to classify linear\n",
    "sequences. The generated sequences have variable length.\n",
    "\n",
    "Long Short Term Memory paper: http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf\n",
    "\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "# ====================\n",
    "#  TOY DATA GENERATOR\n",
    "# ====================\n",
    "class ToySequenceData(object):\n",
    "    \"\"\" Generate sequence of data with dynamic length.\n",
    "    This class generate samples for training:\n",
    "    - Class 0: linear sequences (i.e. [0, 1, 2, 3,...])\n",
    "    - Class 1: random sequences (i.e. [1, 3, 10, 7,...])\n",
    "\n",
    "    NOTICE:\n",
    "    We have to pad each sequence to reach 'max_seq_len' for TensorFlow\n",
    "    consistency (we cannot feed a numpy array with inconsistent\n",
    "    dimensions). The dynamic calculation will then be perform thanks to\n",
    "    'seqlen' attribute that records every actual sequence length.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_samples=1000, max_seq_len=20, min_seq_len=3,\n",
    "                 max_value=1000):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.seqlen = []\n",
    "        for i in range(n_samples):\n",
    "            # Random sequence length\n",
    "            len = random.randint(min_seq_len, max_seq_len)\n",
    "            # Monitor sequence length for TensorFlow dynamic calculation\n",
    "            self.seqlen.append(len)\n",
    "            # Add a random or linear int sequence (50% prob)\n",
    "            if random.random() < .5:\n",
    "                # Generate a linear sequence\n",
    "                rand_start = random.randint(0, max_value - len)\n",
    "                s = [[float(i)/max_value] for i in\n",
    "                     range(rand_start, rand_start + len)]\n",
    "                # Pad sequence for dimension consistency\n",
    "                s += [[0.] for i in range(max_seq_len - len)]\n",
    "                self.data.append(s)\n",
    "                self.labels.append([1., 0.])\n",
    "            else:\n",
    "                # Generate a random sequence\n",
    "                s = [[float(random.randint(0, max_value))/max_value]\n",
    "                     for i in range(len)]\n",
    "                # Pad sequence for dimension consistency\n",
    "                s += [[0.] for i in range(max_seq_len - len)]\n",
    "                self.data.append(s)\n",
    "                self.labels.append([0., 1.])\n",
    "        self.batch_id = 0\n",
    "\n",
    "    def next(self, batch_size):\n",
    "        \"\"\" Return a batch of data. When dataset end is reached, start over.\n",
    "        \"\"\"\n",
    "        if self.batch_id == len(self.data):\n",
    "            self.batch_id = 0\n",
    "        batch_data = (self.data[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        batch_labels = (self.labels[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        batch_seqlen = (self.seqlen[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        self.batch_id = min(self.batch_id + batch_size, len(self.data))\n",
    "        return batch_data, batch_labels, batch_seqlen\n",
    "\n",
    "\n",
    "# ==========\n",
    "#   MODEL\n",
    "# ==========\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_iters = 1000000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "seq_max_len = 20 # Sequence max length\n",
    "n_hidden = 64 # hidden layer num of features\n",
    "n_classes = 2 # linear sequence or not\n",
    "\n",
    "trainset = ToySequenceData(n_samples=1000, max_seq_len=seq_max_len)\n",
    "testset = ToySequenceData(n_samples=500, max_seq_len=seq_max_len)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, seq_max_len, 1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "# A placeholder for indicating each sequence length\n",
    "seqlen = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def dynamicRNN(x, seqlen, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Permuting batch_size and n_steps\n",
    "    x = tf.transpose(x, [1, 0, 2])\n",
    "    # Reshaping to (n_steps*batch_size, n_input)\n",
    "    x = tf.reshape(x, [-1, 1])\n",
    "    # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.split(0, seq_max_len, x)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "\n",
    "    # Get lstm cell output, providing 'sequence_length' will perform dynamic\n",
    "    # calculation.\n",
    "    outputs, states = tf.nn.rnn(lstm_cell, x, dtype=tf.float32,\n",
    "                                sequence_length=seqlen)\n",
    "\n",
    "    # When performing dynamic calculation, we must retrieve the last\n",
    "    # dynamically computed output, i.e., if a sequence length is 10, we need\n",
    "    # to retrieve the 10th output.\n",
    "    # However TensorFlow doesn't support advanced indexing yet, so we build\n",
    "    # a custom op that for each sample in batch size, get its length and\n",
    "    # get the corresponding relevant output.\n",
    "\n",
    "    # 'outputs' is a list of output at every timestep, we pack them in a Tensor\n",
    "    # and change back dimension to [batch_size, n_step, n_input]\n",
    "    outputs = tf.pack(outputs)\n",
    "    outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "\n",
    "    # Hack to build the indexing and retrieve the right output.\n",
    "    batch_size = tf.shape(outputs)[0]\n",
    "    # Start indices for each sample\n",
    "    index = tf.range(0, batch_size) * seq_max_len + (seqlen - 1)\n",
    "    # Indexing\n",
    "    outputs = tf.gather(tf.reshape(outputs, [-1, n_hidden]), index)\n",
    "\n",
    "    # Linear activation, using outputs computed above\n",
    "    return tf.matmul(outputs, weights['out']) + biases['out']\n",
    "\n",
    "pred = dynamicRNN(x, seqlen, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y, batch_seqlen = trainset.next(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       seqlen: batch_seqlen})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y,\n",
    "                                                seqlen: batch_seqlen})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y,\n",
    "                                             seqlen: batch_seqlen})\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    test_data = testset.data\n",
    "    test_label = testset.labels\n",
    "    test_seqlen = testset.seqlen\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: test_data, y: test_label,\n",
    "                                      seqlen: test_seqlen}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dynamicRNN(x, seqlen, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Permuting batch_size and n_steps\n",
    "    x = tf.transpose(x, [1, 0, 2])\n",
    "    # Reshaping to (n_steps*batch_size, n_input)\n",
    "    x = tf.reshape(x, [-1, 1])\n",
    "    # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.split(0, seq_max_len, x)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "\n",
    "    # Get lstm cell output, providing 'sequence_length' will perform dynamic\n",
    "    # calculation.\n",
    "    outputs, states = tf.nn.rnn(lstm_cell, x, dtype=tf.float32,\n",
    "                                sequence_length=seqlen)\n",
    "\n",
    "    # When performing dynamic calculation, we must retrieve the last\n",
    "    # dynamically computed output, i.e., if a sequence length is 10, we need\n",
    "    # to retrieve the 10th output.\n",
    "    # However TensorFlow doesn't support advanced indexing yet, so we build\n",
    "    # a custom op that for each sample in batch size, get its length and\n",
    "    # get the corresponding relevant output.\n",
    "\n",
    "    # 'outputs' is a list of output at every timestep, we pack them in a Tensor\n",
    "    # and change back dimension to [batch_size, n_step, n_input]\n",
    "    outputs = tf.pack(outputs)\n",
    "    outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "\n",
    "    # Hack to build the indexing and retrieve the right output.\n",
    "    batch_size = tf.shape(outputs)[0]\n",
    "    # Start indices for each sample\n",
    "    index = tf.range(0, batch_size) * seq_max_len + (seqlen - 1)\n",
    "    # Indexing\n",
    "    outputs = tf.gather(tf.reshape(outputs, [-1, n_hidden]), index)\n",
    "\n",
    "    # Linear activation, using outputs computed above\n",
    "    return tf.matmul(outputs, weights['out']) + biases['out']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
