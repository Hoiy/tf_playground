{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "NROWS = 1000\n",
    "n_input = 50\n",
    "\n",
    "title_vec = pd.read_csv('hn_title_vec.csv', header=None, nrows=NROWS)\n",
    "title_vec.rename(columns={0: 'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "origin = pd.read_csv('/Users/Shared/data/HN_posts_year_to_Sep_26_2016.csv')\n",
    "origin = origin[['id', 'num_points']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence_length = pd.read_csv('sentence_length.csv', header=None, )\n",
    "sentence_length.rename(columns={0: 'id', 1:'length'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.merge(title_vec, origin, how='inner', on=['id'])\n",
    "data = pd.merge(data, sentence_length, how='inner', on=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GOOD_THRESHOLD = 3\n",
    "\n",
    "data['good'] = data['num_points'].apply(lambda x: 1 if x >= GOOD_THRESHOLD else 0)\n",
    "#data['good'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.drop(['id', 'num_points', 'good'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(NROWS):\n",
    "    for j in range(data.iloc[i]['length'].astype(int) * n_input + 1, data.shape[1]):\n",
    "        data.set_value(i, j, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = data[list(range(1,data.shape[1]))]\n",
    "seq_len = data['length']\n",
    "seq_max_len = train.shape[1] // n_input\n",
    "#train = data.sample(frac=0.8)\n",
    "#test = data.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "\n",
    "n_hidden = 100 # hidden layer num of features\n",
    "n_classes = 50 # linear sequence or not\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, seq_max_len * n_input])\n",
    "seqlen = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'encode': tf.Variable(tf.random_normal([n_hidden, n_classes])),\n",
    "    'decode': tf.Variable(tf.random_normal([n_hidden, n_input]))\n",
    "}\n",
    "biases = {\n",
    "    'encode': tf.Variable(tf.random_normal([n_classes])),\n",
    "    'decode': tf.Variable(tf.random_normal([n_input]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1 = tf.reshape(x, [-1, seq_max_len, n_input])\n",
    "x1 = tf.nn.l2_normalize(x1, 2)\n",
    "\n",
    "\n",
    "# Permuting batch_size and n_steps, (n_step, batch_size, n_input)\n",
    "#x1 = tf.transpose(x1, [1, 0, 2])\n",
    "# Reshaping to (n_steps*batch_size, n_input)\n",
    "#x2 = tf.reshape(x1, [-1, n_input])\n",
    "# Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "#x3 = tf.split(0, seq_max_len, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_1:0\", shape=(?,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(seqlen)\n",
    "with tf.variable_scope('encode'):\n",
    "    encoder_cell = tf.nn.rnn_cell.LSTMCell(n_hidden)\n",
    "    encoded, encode_states = tf.nn.dynamic_rnn(encoder_cell, x1, dtype=tf.float32, sequence_length=seqlen)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ones = tf.fill(tf.shape(seqlen), 1)\n",
    "#e1 = tf.gather_nd(encoded, tf.subtract(seqlen, ones))\n",
    "#batch_encoded = tf.matmul(e1, weights['encode']) + biases['encode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('decode'):\n",
    "    decoder_cell = tf.nn.rnn_cell.LSTMCell(n_hidden)\n",
    "    decoder_input = tf.tile(encode_states.h, [1, seq_max_len])\n",
    "    decoder_input = tf.reshape(decoder_input, [-1, seq_max_len, n_classes])\n",
    "    decoded, decode_states = tf.nn.dynamic_rnn(decoder_cell, decoder_input, dtype=tf.float32, sequence_length=seqlen)\n",
    "    \n",
    "    d1 = tf.gather_nd(decoded, tf.subtract(seqlen, ones))\n",
    "    batch_decoded = tf.matmul(d1, weights['decode']) + biases['decode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# decoded: n_step list of (batch_size, n_input)\n",
    "# y: (n_step*batch_size, n_input)\n",
    "#y = tf.concat(0, decoded)\n",
    "\n",
    "# y2: (n_step, batch_size, n_input)\n",
    "#y2 = tf.reshape(y, [seq_max_len, -1, n_input])\n",
    "\n",
    "# y3: (batch_size, n_step, n_input)\n",
    "#y3 = tf.transpose(y2, [1, 0, 2])\n",
    "\n",
    "y3 = tf.nn.l2_normalize(decoded, 2)\n",
    "y3 = tf.reshape(y3, [-1, seq_max_len* n_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.square(tf.sub(y3, x)))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "epouch = 100\n",
    "display_step = 10;\n",
    "batch_size = 1;\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(epouch):\n",
    "        for j in range(NROWS // batch_size):\n",
    "        #for j in range(len(train)):\n",
    "            #feed = train.iloc[j].as_matrix().reshape(1, seq_max_len, n_input)\n",
    "            #feed = train.as_matrix().reshape(NROWS, seq_max_len, n_input)\n",
    "            feed = train.iloc[range(j*batch_size, (j+1)*batch_size)].as_matrix()\n",
    "            slen = seq_len[j*batch_size: (j+1)*batch_size]\n",
    "            sess.run(optimizer, feed_dict={x: feed, seqlen: slen})\n",
    "            if j % display_step == 0:\n",
    "                loss = sess.run(cost, feed_dict={x: feed, seqlen: slen})\n",
    "                print(\"Epouch\" + str(i) + \", step\" + str(j) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss))\n",
    "                enc = sess.run(encode_states, feed_dict={x: feed, seqlen: slen})\n",
    "                out = sess.run(y3, feed_dict={x: feed, seqlen: slen})\n",
    "                print(feed)\n",
    "                print(enc.h)\n",
    "                print(out)\n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
