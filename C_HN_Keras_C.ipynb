{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"./data/HN/HN_posts_year_to_Sep_26_2016.csv\", parse_dates=['created_at'])\n",
    "data = data[[\"id\", \"title\", \"created_at\", \"num_points\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: Loading Glove Model\n",
      "End: Loaded 2195884 rows.\n"
     ]
    }
   ],
   "source": [
    "from DataLoader import GloVe\n",
    "import numpy as np\n",
    "\n",
    "WORD_DIM = 300\n",
    "glove = GloVe.load2('./data/GloVe/glove.840B.{}d.txt'.format(WORD_DIM), WORD_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Dimension: 300\n",
      "Embedding Symbols: 2195887\n",
      "Index to symbol: [(0, '!'), (1, '!!'), (2, '!!!'), (3, '!!!!'), (4, '!!!!!'), (5, '!!!!!!'), (6, '!!!!!!!'), (7, '!!!!!!!!'), (8, '!!!!!!!!!'), (9, '!!!!!!!!!!')]\n"
     ]
    }
   ],
   "source": [
    "# emb: Symbol to float32 of fixed DIMENSION\n",
    "# Create an index mapping, index to symbol, symbol to index\n",
    "\n",
    "class Embedding:\n",
    "    def __init__(self, emb, verbose = False):\n",
    "        # assert emb is dictionary and each entry has same dimension\n",
    "        self.emb = emb\n",
    "        self.dim = len(self.emb[list(self.emb.keys())[0]])\n",
    "        self.emb['<UNK>'] = [0. for i in range(self.dim)]\n",
    "        self.emb['<PAD>'] = [1. for i in range(self.dim)]\n",
    "        self.emb['<GO>'] = [-1. for i in range(self.dim)]\n",
    "        \n",
    "        self.build_dicts()\n",
    "        \n",
    "        if verbose:\n",
    "            self.describe()\n",
    "        \n",
    "    def describe(self):\n",
    "        print('Embedding Dimension: {}'.format(self.dim))\n",
    "        print('Embedding Symbols: {}'.format(len(self.emb)))\n",
    "        print('Index to symbol: {}'.format([(i, self.idx2Sym[i]) for i in range(10)]))\n",
    "        \n",
    "    def getIndex(self, symbol):\n",
    "        if symbol in self.sym2Idx:\n",
    "            return self.sym2Idx[symbol]\n",
    "        else:\n",
    "            return self.sym2Idx['<UNK>']\n",
    "\n",
    "    def getEmb(self, symbol):\n",
    "        return self.emb[self.idx2Sym[self.getIndex(symbol)]]\n",
    "    \n",
    "    def getSymbols(self, indices):\n",
    "        return [self.idx2Sym[idx] for idx in indices]\n",
    "\n",
    "    def getNumpyArray(self):\n",
    "        return np.array([self.emb[self.idx2Sym[idx]] for idx in range(len(self.emb))])\n",
    "    \n",
    "    def build_dicts(self):\n",
    "        self.sym2Idx = {}\n",
    "        index = 0\n",
    "        for key in sorted(self.emb.keys()):\n",
    "            self.sym2Idx[key] = index\n",
    "            index += 1\n",
    "            \n",
    "        self.idx2Sym = { v:k for k, v in self.sym2Idx.items()}\n",
    "\n",
    "glove_emb = Embedding(glove, verbose=True)\n",
    "glove_np = glove_emb.getNumpyArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "GOOD_THRESHOLD = 100\n",
    "MAX_SEQUENCE_LENGTH = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "title = data[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from TextPreprocess.Tokenizer.RegExp import tokenize\n",
    "\n",
    "def preprocessStrings(strings):\n",
    "    return [[glove_emb.getIndex(token.lower()) for token in tokenize(string)] for string in strings]\n",
    "\n",
    "def prepareData(df):        \n",
    "    num_points = data[\"num_points\"].values\n",
    "\n",
    "    #dayofweek = data['created_at'].dt.dayofweek.values[:,np.newaxis]\n",
    "    #hour = data['created_at'].dt.hour.values[:,np.newaxis]\n",
    "    #month = data['created_at'].dt.month.values[:,np.newaxis]\n",
    "    #day = data['created_at'].dt.day.values[:,np.newaxis]\n",
    "    \n",
    "    #dayofweek = dayofweek / dayofweek.max() \n",
    "    #hour = hour / hour.max()\n",
    "    #month = month / month.max()\n",
    "    #day = day / day.max()\n",
    "    \n",
    "    y_train = np.zeros((len(num_points), 2), dtype=int)\n",
    "    y_original = np.zeros((len(num_points)), dtype=int)\n",
    "    for i in range(0, len(num_points)):\n",
    "        y_train[i, 1] = int(num_points[i] >= GOOD_THRESHOLD)\n",
    "        y_train[i, 0] = int(num_points[i] < GOOD_THRESHOLD)\n",
    "        y_original[i] = int(num_points[i] >= GOOD_THRESHOLD)\n",
    "        \n",
    "    sequences = preprocessStrings(data[\"title\"])\n",
    "    x_train = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    \n",
    "    #x_train_expand = np.zeros((x_train.shape[0], x_train.shape[1] * EMBEDDING_DIM))\n",
    "    #for i in range(0, x_train.shape[0]):\n",
    "    #    for j in range(0, x_train.shape[1]):\n",
    "    #        x_train_expand[i][j*EMBEDDING_DIM:(j+1)*EMBEDDING_DIM] = embedding_matrix[x_train[i][j]]\n",
    "            \n",
    "    \n",
    "    #X = np.hstack((x_train_expand, dayofweek, hour, month, day))\n",
    "    return x_train, y_train, y_original\n",
    "    #return X, y_train, y_original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'title', 'created_at', 'num_points'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(293119, 60)\n"
     ]
    }
   ],
   "source": [
    "X_full, _, y_full = prepareData(data)\n",
    "#x_train, y_train, y2_train = prepareData(train)\n",
    "#x_test, y_test, y2_test = prepareData(test)\n",
    "\n",
    "print(X_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Convolution1D, MaxPooling1D, Dense, Flatten, Dropout, Embedding,BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_shape=(5,)))\n",
    "    model.add(Dense(1, activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy', 'precision'])\n",
    "    return model\n",
    "    \n",
    "\n",
    "def create_baseline(dropout=0, branching=5):\n",
    "    embedding_layer = Embedding(glove_np.shape[0],\n",
    "                            glove_np.shape[1],\n",
    "                            weights=[glove_np],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    \n",
    "    #print(embedded_sequences)\n",
    "    #x = Convolution1D(300, branching)(embedded_sequences)\n",
    "    #x = Convolution1D(300, branching)(x)\n",
    "    #x = Convolution1D(300, branching)(x)\n",
    "    #x = Convolution1D(300, branching)(x)\n",
    "    #x = Convolution1D(300, branching)(x)\n",
    "    #x = Convolution1D(300, branching)(x)\n",
    "    #x = Convolution1D(300, branching)(x)\n",
    "    #x = Convolution1D(300, branching)(x)\n",
    "    \n",
    "    #x = MaxPooling1D()(x)\n",
    "    #x = Dropout(dropout)(x)\n",
    "    \n",
    "    \"\"\"\n",
    "    x = Convolution1D(800, 2, activation='relu')(x)\n",
    "    x = MaxPooling1D()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    x = Flatten()(embedded_sequences)\n",
    "    \n",
    "    x = Dense(3000, activation='tanh')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    \n",
    "    x = Dense(1500, activation='tanh')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    \n",
    "    x = Dense(750, activation='tanh')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    \n",
    "    preds = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping('val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 24.400259965337955}\n"
     ]
    }
   ],
   "source": [
    "# w_x * c_x / (w_y * c_y) = 1, w_y = c_x / c_y if w_x = 1\n",
    "\n",
    "class_weight = {\n",
    "    0: 1,\n",
    "    1: (len(y_full) - sum(y_full)) / sum(y_full)\n",
    "}\n",
    "\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-71f36e0146e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mBRANCHING\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDROPOUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBRANCHING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m model.fit(\n\u001b[1;32m      9\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_full\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-157ecf10f59c>\u001b[0m in \u001b[0;36mcreate_baseline\u001b[0;34m(dropout, branching)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranching\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     embedding_layer = Embedding(glove.shape[0],\n\u001b[0m\u001b[1;32m     17\u001b[0m                             \u001b[0mglove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                             \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglove_np\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "DROPOUT = 0.1\n",
    "BRANCHING = 4\n",
    "\n",
    "model = create_baseline(DROPOUT, BRANCHING)\n",
    "model.fit(\n",
    "    x = X_full,\n",
    "    y = y_full,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    epochs=200, \n",
    "    validation_split=0.2,\n",
    "    shuffle=True, \n",
    "    class_weight=class_weight\n",
    "    ,verbose=0, callbacks=[TQDMNotebookCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
