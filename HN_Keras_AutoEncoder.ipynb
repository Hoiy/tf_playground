{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "NROWS = 100000\n",
    "n_input = 50\n",
    "\n",
    "data = pd.read_csv('hn_title_norm_vec.csv', nrows=NROWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_data = data.drop(labels=['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = clean_data.sample(frac=0.8)\n",
    "test = clean_data.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 1200)\n",
      "(20000, 1200)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_np = train.as_matrix()\n",
    "test_np = test.as_matrix()\n",
    "print(train_np.shape)\n",
    "print(test_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 2/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 3/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 4/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 5/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 6/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 7/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 8/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 9/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 10/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 11/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 12/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 13/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 14/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 15/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 16/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 17/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 18/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 19/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 20/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 21/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 22/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 23/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 24/50\n",
      "80000/80000 [==============================] - 9s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 25/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 26/50\n",
      "80000/80000 [==============================] - 9s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 27/50\n",
      "80000/80000 [==============================] - 9s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 28/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 29/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 30/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 31/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 32/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 33/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 34/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 35/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 36/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 37/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 38/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 39/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 40/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 41/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 42/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 43/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 44/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 45/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 46/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 47/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 48/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 49/50\n",
      "80000/80000 [==============================] - 8s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 50/50\n",
      "80000/80000 [==============================] - 9s - loss: 0.0046 - val_loss: 0.0046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12bda8ba8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 1  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_title = Input(shape=(train_np.shape[1],))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "#encoded_0 = Dense(1200, activation='tanh')(input_title)\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_title)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "#decoded_0 = Dense(1200, activation='tanh')(encoded)\n",
    "decoded = Dense(train_np.shape[1], activation='tanh')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_title, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_title, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder.fit(train_np, train_np,\n",
    "                nb_epoch=50,\n",
    "                batch_size=1000,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_np, test_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] (1, 1200)\n",
      "[[-0.34407094]] (1, 1)\n",
      "b [  5.04688178e-05  -9.16062127e-05  -7.42504126e-05   6.98399817e-05\n",
      "  -9.92970381e-05  -8.90867523e-05  -2.41209600e-05   9.59809549e-05\n",
      "  -4.70681080e-05   9.31996256e-05   6.43376916e-05  -2.61820242e-05\n",
      "   7.26967301e-06  -7.98481506e-06   1.40485063e-04  -9.43329651e-05\n",
      "   1.98467005e-05  -5.33907514e-05  -1.22291647e-04   5.94479206e-05\n",
      "   6.46285262e-05  -5.86524729e-05   6.44965185e-05   3.13518711e-07\n",
      "   5.57013300e-05   1.88413498e-04   9.82349011e-05   7.65935783e-06\n",
      "  -1.02457256e-04  -1.08079857e-05   4.01063939e-04  -1.13337808e-06\n",
      "  -6.05598689e-05  -5.97166763e-05  -6.65440384e-05   3.51400813e-05\n",
      "  -3.81440914e-05  -1.77962374e-05   2.15161594e-06   4.82048308e-05\n",
      "   2.85141226e-07   2.08568949e-07  -6.18531412e-05   6.53392126e-05\n",
      "  -2.04716180e-05  -4.44934784e-07   4.77662361e-05   7.33822380e-05\n",
      "   2.92813610e-07  -6.51880619e-05] (1, 1200)\n",
      "7.68228955283e-09\n"
     ]
    }
   ],
   "source": [
    "i0 = train_np[0:1]\n",
    "print('a', i0[0][23*50:24*50], i0.shape)\n",
    "\n",
    "e0 = encoder.predict(i0)\n",
    "print(e0, e0.shape)\n",
    "\n",
    "o0 = decoder.predict(e0)\n",
    "print('b', o0[0][23*50:24*50], o0.shape)\n",
    "\n",
    "print(np.sum(np.square(i0[0][23*50:24*50] - o0[0][23*50:24*50])) / 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
